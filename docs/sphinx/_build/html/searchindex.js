Search.setIndex({"docnames": ["_autosummary/nlptest", "_autosummary/nlptest.augmentation", "_autosummary/nlptest.augmentation.fix_robustness", "_autosummary/nlptest.augmentation.fix_robustness.AugmentRobustness", "_autosummary/nlptest.augmentation.fix_robustness.BaseAugmentaion", "_autosummary/nlptest.datahandler", "_autosummary/nlptest.datahandler.datasource", "_autosummary/nlptest.datahandler.datasource.CSVDataset", "_autosummary/nlptest.datahandler.datasource.ConllDataset", "_autosummary/nlptest.datahandler.datasource.DataFactory", "_autosummary/nlptest.datahandler.datasource.JSONDataset", "_autosummary/nlptest.datahandler.format", "_autosummary/nlptest.datahandler.format.BaseFormatter", "_autosummary/nlptest.datahandler.format.Formatter", "_autosummary/nlptest.datahandler.format.NEROutputFormatter", "_autosummary/nlptest.datahandler.format.SequenceClassificationOutputFormatter", "_autosummary/nlptest.modelhandler", "_autosummary/nlptest.modelhandler.jsl_modelhandler", "_autosummary/nlptest.modelhandler.jsl_modelhandler.PretrainedModelForNER", "_autosummary/nlptest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification", "_autosummary/nlptest.modelhandler.modelhandler", "_autosummary/nlptest.modelhandler.modelhandler.ModelFactory", "_autosummary/nlptest.modelhandler.spacy_modelhandler", "_autosummary/nlptest.modelhandler.spacy_modelhandler.PretrainedModelForNER", "_autosummary/nlptest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification", "_autosummary/nlptest.modelhandler.transformers_modelhandler", "_autosummary/nlptest.modelhandler.transformers_modelhandler.PretrainedModelForNER", "_autosummary/nlptest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification", "_autosummary/nlptest.nlptest", "_autosummary/nlptest.nlptest.Harness", "_autosummary/nlptest.testrunner", "_autosummary/nlptest.testrunner.RobustnessTestRunner", "_autosummary/nlptest.testrunner.TestRunner", "_autosummary/nlptest.transform", "_autosummary/nlptest.transform.AccuracyTestFactory", "_autosummary/nlptest.transform.BiasTestFactory", "_autosummary/nlptest.transform.FairnessTestFactory", "_autosummary/nlptest.transform.ITests", "_autosummary/nlptest.transform.RepresentationTestFactory", "_autosummary/nlptest.transform.RobustnessTestFactory", "_autosummary/nlptest.transform.TestFactory", "_autosummary/nlptest.transform.accuracy", "_autosummary/nlptest.transform.accuracy.BaseAccuracy", "_autosummary/nlptest.transform.accuracy.MinF1Score", "_autosummary/nlptest.transform.accuracy.MinMacroF1Score", "_autosummary/nlptest.transform.accuracy.MinMicroF1Score", "_autosummary/nlptest.transform.accuracy.MinPrecisionScore", "_autosummary/nlptest.transform.accuracy.MinRecallScore", "_autosummary/nlptest.transform.accuracy.MinWeightedF1Score", "_autosummary/nlptest.transform.bias", "_autosummary/nlptest.transform.bias.BaseBias", "_autosummary/nlptest.transform.bias.CountryEconomicBias", "_autosummary/nlptest.transform.bias.EthnicityNameBias", "_autosummary/nlptest.transform.bias.GenderPronounBias", "_autosummary/nlptest.transform.bias.ReligionBias", "_autosummary/nlptest.transform.fairness", "_autosummary/nlptest.transform.fairness.BaseFairness", "_autosummary/nlptest.transform.fairness.MaxGenderF1Score", "_autosummary/nlptest.transform.fairness.MinGenderF1Score", "_autosummary/nlptest.transform.fairness.get_gendered_data", "_autosummary/nlptest.transform.perturbation", "_autosummary/nlptest.transform.perturbation.AddContext", "_autosummary/nlptest.transform.perturbation.AddContraction", "_autosummary/nlptest.transform.perturbation.AddPunctuation", "_autosummary/nlptest.transform.perturbation.AddTypo", "_autosummary/nlptest.transform.perturbation.BasePerturbation", "_autosummary/nlptest.transform.perturbation.ConvertAccent", "_autosummary/nlptest.transform.perturbation.GenderPronounBias", "_autosummary/nlptest.transform.perturbation.LowerCase", "_autosummary/nlptest.transform.perturbation.PerturbationFactory", "_autosummary/nlptest.transform.perturbation.StripPunctuation", "_autosummary/nlptest.transform.perturbation.SwapCohyponyms", "_autosummary/nlptest.transform.perturbation.SwapEntities", "_autosummary/nlptest.transform.perturbation.TitleCase", "_autosummary/nlptest.transform.perturbation.UpperCase", "_autosummary/nlptest.transform.perturbation.get_cohyponyms_wordnet", "_autosummary/nlptest.transform.representation", "_autosummary/nlptest.transform.representation.BaseRepresentation", "_autosummary/nlptest.transform.representation.CountryEconomicRepresentation", "_autosummary/nlptest.transform.representation.EthnicityRepresentation", "_autosummary/nlptest.transform.representation.GenderRepresentation", "_autosummary/nlptest.transform.representation.LabelRepresentation", "_autosummary/nlptest.transform.representation.ReligionRepresentation", "_autosummary/nlptest.transform.robustness", "_autosummary/nlptest.transform.robustness.AddContext", "_autosummary/nlptest.transform.robustness.AddContraction", "_autosummary/nlptest.transform.robustness.AddPunctuation", "_autosummary/nlptest.transform.robustness.AddTypo", "_autosummary/nlptest.transform.robustness.BaseRobustness", "_autosummary/nlptest.transform.robustness.ConvertAccent", "_autosummary/nlptest.transform.robustness.LowerCase", "_autosummary/nlptest.transform.robustness.StripPunctuation", "_autosummary/nlptest.transform.robustness.SwapCohyponyms", "_autosummary/nlptest.transform.robustness.SwapEntities", "_autosummary/nlptest.transform.robustness.TitleCase", "_autosummary/nlptest.transform.robustness.UpperCase", "_autosummary/nlptest.transform.robustness.get_cohyponyms_wordnet", "_autosummary/nlptest.transform.utils", "_autosummary/nlptest.transform.utils.check_name", "_autosummary/nlptest.transform.utils.create_terminology", "_autosummary/nlptest.transform.utils.get_country_economic_representation_dict", "_autosummary/nlptest.transform.utils.get_entity_representation_proportions", "_autosummary/nlptest.transform.utils.get_ethnicity_representation_dict", "_autosummary/nlptest.transform.utils.get_label_representation_dict", "_autosummary/nlptest.transform.utils.get_religion_name_representation_dict", "_autosummary/nlptest.transform.utils.get_substitution_names", "_autosummary/nlptest.utils", "_autosummary/nlptest.utils.custom_types", "_autosummary/nlptest.utils.custom_types.AccuracyOutput", "_autosummary/nlptest.utils.custom_types.MaxScoreOutput", "_autosummary/nlptest.utils.custom_types.MinScoreOutput", "_autosummary/nlptest.utils.custom_types.NEROutput", "_autosummary/nlptest.utils.custom_types.NERPrediction", "_autosummary/nlptest.utils.custom_types.Sample", "_autosummary/nlptest.utils.custom_types.SequenceClassificationOutput", "_autosummary/nlptest.utils.custom_types.SequenceLabel", "_autosummary/nlptest.utils.custom_types.Span", "_autosummary/nlptest.utils.custom_types.Transformation", "_autosummary/nlptest.utils.gender_classifier", "_autosummary/nlptest.utils.gender_classifier.GenderClassifier", "_autosummary/nlptest.utils.lib_manager", "_autosummary/nlptest.utils.lib_manager.try_import_lib", "getting_started/index", "index", "user_guide/index"], "filenames": ["_autosummary/nlptest.rst", "_autosummary/nlptest.augmentation.rst", "_autosummary/nlptest.augmentation.fix_robustness.rst", "_autosummary/nlptest.augmentation.fix_robustness.AugmentRobustness.rst", "_autosummary/nlptest.augmentation.fix_robustness.BaseAugmentaion.rst", "_autosummary/nlptest.datahandler.rst", "_autosummary/nlptest.datahandler.datasource.rst", "_autosummary/nlptest.datahandler.datasource.CSVDataset.rst", "_autosummary/nlptest.datahandler.datasource.ConllDataset.rst", "_autosummary/nlptest.datahandler.datasource.DataFactory.rst", "_autosummary/nlptest.datahandler.datasource.JSONDataset.rst", "_autosummary/nlptest.datahandler.format.rst", "_autosummary/nlptest.datahandler.format.BaseFormatter.rst", "_autosummary/nlptest.datahandler.format.Formatter.rst", "_autosummary/nlptest.datahandler.format.NEROutputFormatter.rst", "_autosummary/nlptest.datahandler.format.SequenceClassificationOutputFormatter.rst", "_autosummary/nlptest.modelhandler.rst", "_autosummary/nlptest.modelhandler.jsl_modelhandler.rst", "_autosummary/nlptest.modelhandler.jsl_modelhandler.PretrainedModelForNER.rst", "_autosummary/nlptest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification.rst", "_autosummary/nlptest.modelhandler.modelhandler.rst", "_autosummary/nlptest.modelhandler.modelhandler.ModelFactory.rst", "_autosummary/nlptest.modelhandler.spacy_modelhandler.rst", "_autosummary/nlptest.modelhandler.spacy_modelhandler.PretrainedModelForNER.rst", "_autosummary/nlptest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification.rst", "_autosummary/nlptest.modelhandler.transformers_modelhandler.rst", "_autosummary/nlptest.modelhandler.transformers_modelhandler.PretrainedModelForNER.rst", "_autosummary/nlptest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification.rst", "_autosummary/nlptest.nlptest.rst", "_autosummary/nlptest.nlptest.Harness.rst", "_autosummary/nlptest.testrunner.rst", "_autosummary/nlptest.testrunner.RobustnessTestRunner.rst", "_autosummary/nlptest.testrunner.TestRunner.rst", "_autosummary/nlptest.transform.rst", "_autosummary/nlptest.transform.AccuracyTestFactory.rst", "_autosummary/nlptest.transform.BiasTestFactory.rst", "_autosummary/nlptest.transform.FairnessTestFactory.rst", "_autosummary/nlptest.transform.ITests.rst", "_autosummary/nlptest.transform.RepresentationTestFactory.rst", "_autosummary/nlptest.transform.RobustnessTestFactory.rst", "_autosummary/nlptest.transform.TestFactory.rst", "_autosummary/nlptest.transform.accuracy.rst", "_autosummary/nlptest.transform.accuracy.BaseAccuracy.rst", "_autosummary/nlptest.transform.accuracy.MinF1Score.rst", "_autosummary/nlptest.transform.accuracy.MinMacroF1Score.rst", "_autosummary/nlptest.transform.accuracy.MinMicroF1Score.rst", "_autosummary/nlptest.transform.accuracy.MinPrecisionScore.rst", "_autosummary/nlptest.transform.accuracy.MinRecallScore.rst", "_autosummary/nlptest.transform.accuracy.MinWeightedF1Score.rst", "_autosummary/nlptest.transform.bias.rst", "_autosummary/nlptest.transform.bias.BaseBias.rst", "_autosummary/nlptest.transform.bias.CountryEconomicBias.rst", "_autosummary/nlptest.transform.bias.EthnicityNameBias.rst", "_autosummary/nlptest.transform.bias.GenderPronounBias.rst", "_autosummary/nlptest.transform.bias.ReligionBias.rst", "_autosummary/nlptest.transform.fairness.rst", "_autosummary/nlptest.transform.fairness.BaseFairness.rst", "_autosummary/nlptest.transform.fairness.MaxGenderF1Score.rst", "_autosummary/nlptest.transform.fairness.MinGenderF1Score.rst", "_autosummary/nlptest.transform.fairness.get_gendered_data.rst", "_autosummary/nlptest.transform.perturbation.rst", "_autosummary/nlptest.transform.perturbation.AddContext.rst", "_autosummary/nlptest.transform.perturbation.AddContraction.rst", "_autosummary/nlptest.transform.perturbation.AddPunctuation.rst", "_autosummary/nlptest.transform.perturbation.AddTypo.rst", "_autosummary/nlptest.transform.perturbation.BasePerturbation.rst", "_autosummary/nlptest.transform.perturbation.ConvertAccent.rst", "_autosummary/nlptest.transform.perturbation.GenderPronounBias.rst", "_autosummary/nlptest.transform.perturbation.LowerCase.rst", "_autosummary/nlptest.transform.perturbation.PerturbationFactory.rst", "_autosummary/nlptest.transform.perturbation.StripPunctuation.rst", "_autosummary/nlptest.transform.perturbation.SwapCohyponyms.rst", "_autosummary/nlptest.transform.perturbation.SwapEntities.rst", "_autosummary/nlptest.transform.perturbation.TitleCase.rst", "_autosummary/nlptest.transform.perturbation.UpperCase.rst", "_autosummary/nlptest.transform.perturbation.get_cohyponyms_wordnet.rst", "_autosummary/nlptest.transform.representation.rst", "_autosummary/nlptest.transform.representation.BaseRepresentation.rst", "_autosummary/nlptest.transform.representation.CountryEconomicRepresentation.rst", "_autosummary/nlptest.transform.representation.EthnicityRepresentation.rst", "_autosummary/nlptest.transform.representation.GenderRepresentation.rst", "_autosummary/nlptest.transform.representation.LabelRepresentation.rst", "_autosummary/nlptest.transform.representation.ReligionRepresentation.rst", "_autosummary/nlptest.transform.robustness.rst", "_autosummary/nlptest.transform.robustness.AddContext.rst", "_autosummary/nlptest.transform.robustness.AddContraction.rst", "_autosummary/nlptest.transform.robustness.AddPunctuation.rst", "_autosummary/nlptest.transform.robustness.AddTypo.rst", "_autosummary/nlptest.transform.robustness.BaseRobustness.rst", "_autosummary/nlptest.transform.robustness.ConvertAccent.rst", "_autosummary/nlptest.transform.robustness.LowerCase.rst", "_autosummary/nlptest.transform.robustness.StripPunctuation.rst", "_autosummary/nlptest.transform.robustness.SwapCohyponyms.rst", "_autosummary/nlptest.transform.robustness.SwapEntities.rst", "_autosummary/nlptest.transform.robustness.TitleCase.rst", "_autosummary/nlptest.transform.robustness.UpperCase.rst", "_autosummary/nlptest.transform.robustness.get_cohyponyms_wordnet.rst", "_autosummary/nlptest.transform.utils.rst", "_autosummary/nlptest.transform.utils.check_name.rst", "_autosummary/nlptest.transform.utils.create_terminology.rst", "_autosummary/nlptest.transform.utils.get_country_economic_representation_dict.rst", "_autosummary/nlptest.transform.utils.get_entity_representation_proportions.rst", "_autosummary/nlptest.transform.utils.get_ethnicity_representation_dict.rst", "_autosummary/nlptest.transform.utils.get_label_representation_dict.rst", "_autosummary/nlptest.transform.utils.get_religion_name_representation_dict.rst", "_autosummary/nlptest.transform.utils.get_substitution_names.rst", "_autosummary/nlptest.utils.rst", "_autosummary/nlptest.utils.custom_types.rst", "_autosummary/nlptest.utils.custom_types.AccuracyOutput.rst", "_autosummary/nlptest.utils.custom_types.MaxScoreOutput.rst", "_autosummary/nlptest.utils.custom_types.MinScoreOutput.rst", "_autosummary/nlptest.utils.custom_types.NEROutput.rst", "_autosummary/nlptest.utils.custom_types.NERPrediction.rst", "_autosummary/nlptest.utils.custom_types.Sample.rst", "_autosummary/nlptest.utils.custom_types.SequenceClassificationOutput.rst", "_autosummary/nlptest.utils.custom_types.SequenceLabel.rst", "_autosummary/nlptest.utils.custom_types.Span.rst", "_autosummary/nlptest.utils.custom_types.Transformation.rst", "_autosummary/nlptest.utils.gender_classifier.rst", "_autosummary/nlptest.utils.gender_classifier.GenderClassifier.rst", "_autosummary/nlptest.utils.lib_manager.rst", "_autosummary/nlptest.utils.lib_manager.try_import_lib.rst", "getting_started/index.rst", "index.rst", "user_guide/index.rst"], "titles": ["nlptest", "nlptest.augmentation", "nlptest.augmentation.fix_robustness", "nlptest.augmentation.fix_robustness.AugmentRobustness", "nlptest.augmentation.fix_robustness.BaseAugmentaion", "nlptest.datahandler", "nlptest.datahandler.datasource", "nlptest.datahandler.datasource.CSVDataset", "nlptest.datahandler.datasource.ConllDataset", "nlptest.datahandler.datasource.DataFactory", "nlptest.datahandler.datasource.JSONDataset", "nlptest.datahandler.format", "nlptest.datahandler.format.BaseFormatter", "nlptest.datahandler.format.Formatter", "nlptest.datahandler.format.NEROutputFormatter", "nlptest.datahandler.format.SequenceClassificationOutputFormatter", "nlptest.modelhandler", "nlptest.modelhandler.jsl_modelhandler", "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForNER", "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification", "nlptest.modelhandler.modelhandler", "nlptest.modelhandler.modelhandler.ModelFactory", "nlptest.modelhandler.spacy_modelhandler", "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForNER", "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification", "nlptest.modelhandler.transformers_modelhandler", "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForNER", "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification", "nlptest.nlptest", "nlptest.nlptest.Harness", "nlptest.testrunner", "nlptest.testrunner.RobustnessTestRunner", "nlptest.testrunner.TestRunner", "nlptest.transform", "nlptest.transform.AccuracyTestFactory", "nlptest.transform.BiasTestFactory", "nlptest.transform.FairnessTestFactory", "nlptest.transform.ITests", "nlptest.transform.RepresentationTestFactory", "nlptest.transform.RobustnessTestFactory", "nlptest.transform.TestFactory", "nlptest.transform.accuracy", "nlptest.transform.accuracy.BaseAccuracy", "nlptest.transform.accuracy.MinF1Score", "nlptest.transform.accuracy.MinMacroF1Score", "nlptest.transform.accuracy.MinMicroF1Score", "nlptest.transform.accuracy.MinPrecisionScore", "nlptest.transform.accuracy.MinRecallScore", "nlptest.transform.accuracy.MinWeightedF1Score", "nlptest.transform.bias", "nlptest.transform.bias.BaseBias", "nlptest.transform.bias.CountryEconomicBias", "nlptest.transform.bias.EthnicityNameBias", "nlptest.transform.bias.GenderPronounBias", "nlptest.transform.bias.ReligionBias", "nlptest.transform.fairness", "nlptest.transform.fairness.BaseFairness", "nlptest.transform.fairness.MaxGenderF1Score", "nlptest.transform.fairness.MinGenderF1Score", "nlptest.transform.fairness.get_gendered_data", "nlptest.transform.perturbation", "nlptest.transform.perturbation.AddContext", "nlptest.transform.perturbation.AddContraction", "nlptest.transform.perturbation.AddPunctuation", "nlptest.transform.perturbation.AddTypo", "nlptest.transform.perturbation.BasePerturbation", "nlptest.transform.perturbation.ConvertAccent", "nlptest.transform.perturbation.GenderPronounBias", "nlptest.transform.perturbation.LowerCase", "nlptest.transform.perturbation.PerturbationFactory", "nlptest.transform.perturbation.StripPunctuation", "nlptest.transform.perturbation.SwapCohyponyms", "nlptest.transform.perturbation.SwapEntities", "nlptest.transform.perturbation.TitleCase", "nlptest.transform.perturbation.UpperCase", "nlptest.transform.perturbation.get_cohyponyms_wordnet", "nlptest.transform.representation", "nlptest.transform.representation.BaseRepresentation", "nlptest.transform.representation.CountryEconomicRepresentation", "nlptest.transform.representation.EthnicityRepresentation", "nlptest.transform.representation.GenderRepresentation", "nlptest.transform.representation.LabelRepresentation", "nlptest.transform.representation.ReligionRepresentation", "nlptest.transform.robustness", "nlptest.transform.robustness.AddContext", "nlptest.transform.robustness.AddContraction", "nlptest.transform.robustness.AddPunctuation", "nlptest.transform.robustness.AddTypo", "nlptest.transform.robustness.BaseRobustness", "nlptest.transform.robustness.ConvertAccent", "nlptest.transform.robustness.LowerCase", "nlptest.transform.robustness.StripPunctuation", "nlptest.transform.robustness.SwapCohyponyms", "nlptest.transform.robustness.SwapEntities", "nlptest.transform.robustness.TitleCase", "nlptest.transform.robustness.UpperCase", "nlptest.transform.robustness.get_cohyponyms_wordnet", "nlptest.transform.utils", "nlptest.transform.utils.check_name", "nlptest.transform.utils.create_terminology", "nlptest.transform.utils.get_country_economic_representation_dict", "nlptest.transform.utils.get_entity_representation_proportions", "nlptest.transform.utils.get_ethnicity_representation_dict", "nlptest.transform.utils.get_label_representation_dict", "nlptest.transform.utils.get_religion_name_representation_dict", "nlptest.transform.utils.get_substitution_names", "nlptest.utils", "nlptest.utils.custom_types", "nlptest.utils.custom_types.AccuracyOutput", "nlptest.utils.custom_types.MaxScoreOutput", "nlptest.utils.custom_types.MinScoreOutput", "nlptest.utils.custom_types.NEROutput", "nlptest.utils.custom_types.NERPrediction", "nlptest.utils.custom_types.Sample", "nlptest.utils.custom_types.SequenceClassificationOutput", "nlptest.utils.custom_types.SequenceLabel", "nlptest.utils.custom_types.Span", "nlptest.utils.custom_types.Transformation", "nlptest.utils.gender_classifier", "nlptest.utils.gender_classifier.GenderClassifier", "nlptest.utils.lib_manager", "nlptest.utils.lib_manager.try_import_lib", "Quick Start", "Welcome to the docs page for NLP Test!", "User Guide"], "terms": {"index": [71, 92], "modul": [0, 1, 5, 16, 33, 106], "search": [], "page": [], "thi": [4, 12, 13, 14, 15, 29, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 123, 124], "can": [3, 122, 124], "quick": [], "refer": 122, "how": [3, 122], "set": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "up": [122, 123], "your": 122, "environ": 122, "let": [], "": [], "creat": [9, 40, 43, 44, 45, 46, 47, 48, 99, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 122], "new": [3, 29, 39, 71, 72, 92, 93, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 122], "manag": 122, "all": [19, 24, 29, 31, 34, 35, 36, 38, 39, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 122], "depend": 122, "Then": 122, "we": [113, 122], "nlptest": [122, 123], "packag": 122, "pip": 122, "now": 122, "you": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 122], "should": [3, 4, 12, 14, 15, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 122], "readi": 122, "jupyt": 122, "notebook": 122, "run": [29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 122, 123], "also": 122, "python": 122, "spark": [31, 32, 122], "from": [3, 7, 8, 10, 19, 21, 24, 27, 29, 37, 40, 52, 70, 71, 72, 91, 92, 93, 99, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 122], "pypi": 122, "releas": 122, "n": 122, "3": 122, "8": 122, "y": 122, "activ": 122, "c": 122, "python3": 122, "sourc": 122, "bin": 122, "get": [34, 35, 36, 38, 39, 105, 122, 123], "start": [61, 84, 116], "nlp": [18, 19, 29, 124], "test": [3, 21, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 57, 69, 77, 78, 79, 80, 81, 82, 100, 102, 103, 104, 108, 109, 110, 124], "cheat": [], "sheet": [], "instal": [], "The": [3, 9, 12, 13, 14, 15, 29, 40, 42, 43, 44, 45, 46, 47, 48, 50, 56, 57, 58, 77, 78, 79, 80, 81, 82, 88, 100, 102, 103, 104, 113, 122, 124], "follow": [3, 122, 123], "us": [13, 14, 15, 21, 29, 61, 62, 64, 66, 75, 84, 85, 87, 89, 96, 113, 122, 123], "import": [122, 124], "har": [3, 122], "object": [7, 8, 9, 10, 13, 14, 15, 21, 29, 31, 32, 34, 35, 36, 38, 39, 40, 69, 113, 119, 122], "h": 122, "ner": [18, 19, 23, 26, 27, 111, 113, 122], "model": [18, 19, 21, 23, 24, 26, 27, 29, 31, 32, 34, 35, 36, 38, 39, 40, 42, 56, 57, 58, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 122], "dslim": 122, "bert": 122, "base": [3, 4, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 21, 23, 24, 26, 27, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 122], "hub": [18, 19, 21, 29, 122], "transform": [26, 27, 31, 32, 113, 122], "gener": [29, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 122], "report": [3, 29, 122], "case": [29, 122], "virtualenv": 122, "conda": 122, "user": [], "guid": [], "i": [3, 4, 9, 13, 18, 19, 21, 29, 39, 63, 68, 70, 73, 74, 75, 78, 79, 81, 82, 86, 90, 91, 94, 95, 96, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 124], "an": [3, 29, 37, 42, 50, 56, 57, 58, 77, 88, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 124], "overview": 124, "explain": 124, "featur": 124, "depth": 124, "document": [14, 124], "found": [75, 96, 124], "titl": [], "For": 124, "more": 124, "explan": 124, "pleas": 124, "check": [18, 19, 51, 52, 53, 54, 67, 124], "websit": 124, "http": [], "org": [], "list": [3, 7, 8, 9, 18, 21, 23, 24, 26, 27, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 46, 47, 50, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 99, 100, 102, 103, 104, 105, 111, 113, 114], "class": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119], "function": [55, 60, 83, 97, 105, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 120], "method": [3, 4, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 21, 23, 24, 26, 27, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119], "extend": [], "data": [3, 4, 7, 8, 9, 10, 29, 31, 32, 40, 42, 43, 44, 45, 46, 47, 48, 50, 56, 57, 58, 59, 71, 72, 77, 78, 79, 80, 81, 82, 88, 92, 93, 100, 102, 103, 104, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "rst": [], "obj": [], "displai": [], "py": 113, "type": [3, 4, 8, 9, 12, 13, 14, 15, 18, 19, 21, 23, 24, 26, 27, 29, 31, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 53, 56, 57, 58, 67, 77, 78, 79, 80, 81, 82, 88, 100, 101, 102, 103, 104, 111, 113, 114], "short_nam": [], "arg": [13, 18, 19, 23, 24, 27], "endif": [], "return_annot": [], "overload": 113, "length": [], "endfor": [], "show": [], "inherit": [], "autoapi_opt": [], "link_obj": [], "loop": [], "last": [], "diagram": [], "autoapi": [], "full_nam": [], "part": [], "1": [78, 79, 81, 82], "privat": [], "member": [], "docstr": [], "indent": [], "visible_class": [], "selectattr": [], "els": [75, 96], "rejectattr": [], "klass": [], "render": [], "visible_attribut": [], "attribut": [7, 18, 19, 21, 24, 26, 27, 29, 34, 35, 36, 38, 39, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "visible_method": [], "name": [18, 23, 26, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 56, 57, 58, 71, 72, 77, 78, 79, 81, 82, 88, 92, 93, 105], "valu": [34, 35, 36, 38, 39, 42, 43, 44, 45, 46, 47, 48, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "none": [3, 4, 7, 8, 9, 10, 14, 15, 27, 29, 31, 32, 34, 35, 36, 38, 39, 61, 63, 66, 69, 70, 71, 72, 84, 86, 89, 91, 92, 93, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119], "annot": [], "string": [3, 12, 13, 14, 15, 23, 27, 53, 63, 67, 68, 70, 73, 74, 75, 86, 90, 91, 94, 95, 96, 99, 111, 114], "splitlin": [], "count": [], "multilin": [], "width": [], "truncat": [], "100": [], "sphinx_vers": [], "2": 99, "properti": [24, 27, 113], "method_typ": [], "nest": [], "pars": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "block": [], "subpackag": [], "visible_subpackag": [], "toctre": [], "titlesonli": [], "maxdepth": [], "endblock": [], "submodul": [], "visible_submodul": [], "content": [], "visible_children": [], "children": [], "elif": [], "equalto": [], "visible_funct": [], "summari": [], "scope": [], "id": 14, "obj_item": [], "0": 3, "api": 124, "baseaugmentaion": 3, "abstract": [4, 12, 15, 32, 37, 42, 50, 56, 77, 80, 88], "techniqu": 4, "fix": [3, 4], "implement": [4, 12, 14, 15, 42, 43, 44, 45, 46, 47, 48, 50, 56, 57, 58, 77, 78, 79, 80, 81, 82, 88], "child": 4, "perform": [3, 4, 13, 18, 19, 21, 23, 24, 26, 27, 29, 34, 35, 36, 38, 39, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "oper": [4, 113], "return": [3, 4, 7, 8, 9, 12, 13, 14, 15, 18, 19, 21, 23, 24, 26, 27, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 61, 63, 64, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 99, 100, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "notimplementederror": [4, 12, 14, 15], "rais": [4, 12, 13, 14, 15, 21, 29, 78, 79, 81, 82, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "augmentrobust": 29, "task": [3, 7, 8, 9, 21, 29, 111, 113, 114], "h_report": 3, "config": [3, 29, 43, 44, 45, 46, 47, 48, 61, 78, 79, 81, 82, 84, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "max_prop": 3, "5": 3, "A": [3, 14, 18, 21, 23, 26, 29, 34, 35, 36, 37, 38, 39, 40, 42, 50, 56, 77, 88], "specifi": [3, 13, 21, 40, 78, 79, 81, 82, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "histor": 3, "result": [3, 13, 29, 31, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 78, 79, 81, 82, 113], "str": [3, 7, 8, 9, 10, 18, 19, 21, 23, 24, 26, 27, 29, 37, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 61, 62, 63, 66, 67, 70, 71, 72, 75, 77, 78, 79, 81, 82, 84, 85, 86, 88, 89, 91, 92, 93, 96, 99, 111, 112, 113, 114, 115, 116], "indic": 3, "being": 3, "dict": [3, 29, 34, 35, 36, 38, 39, 40, 66, 72, 89, 93, 99, 100, 101, 102, 103, 104, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "dictionari": [3, 29, 34, 35, 36, 38, 39, 40, 61, 62, 66, 72, 84, 85, 89, 93, 99, 100, 101, 102, 103, 104, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "contain": [3, 14, 15, 29, 31, 32, 100, 101, 102, 103, 104], "configur": [3, 29, 123], "paramet": [3, 7, 8, 9, 10, 12, 13, 14, 15, 21, 23, 24, 26, 27, 29, 31, 32, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 67, 70, 71, 72, 75, 77, 78, 79, 80, 81, 82, 88, 91, 92, 93, 96, 99, 100, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "panda": [3, 99], "datafram": [3, 29, 32, 99], "float": [3, 108, 109, 110, 112, 115], "maximum": [3, 57], "proport": [3, 78, 79, 81, 82, 101], "improv": 3, "suggest": 3, "default": [3, 29, 39, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "__init__": [3, 4, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 21, 23, 24, 26, 27, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119], "self": [3, 77], "initi": [3, 7, 8, 9, 10, 21, 29, 31, 32, 39], "instanc": [3, 9, 18, 19, 29, 39, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "myclass": 3, "sampl": [3, 7, 8, 13, 14, 15, 31, 32, 34, 35, 36, 38, 39, 40, 42, 43, 46, 47, 50, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 100, 102, 103, 104], "prop": 3, "calcul": 3, "given": [3, 21, 29, 34, 35, 36, 38, 39, 40, 43, 44, 45, 46, 47, 48, 57, 58], "input_path": [3, 29], "output_path": [3, 29], "inplac": [3, 29], "bool": [3, 18, 19, 23, 24, 26, 27, 29, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "fals": [3, 19, 24, 27, 29, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "appli": [3, 51, 52, 53, 54, 63, 64, 67, 68, 70, 73, 74, 86, 87, 90, 91, 94, 95, 113], "perturb": [3, 51, 52, 53, 54, 89, 113], "input": [3, 13, 14, 15, 18, 19, 21, 23, 24, 26, 27, 29, 34, 35, 36, 38, 39, 42, 50, 56, 57, 58, 61, 62, 66, 75, 77, 78, 79, 80, 81, 82, 84, 85, 88, 89, 96, 100, 102, 103, 104, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "recommend": 3, "path": [3, 7, 8, 9, 10, 18, 19, 21, 23, 24, 26, 27, 29], "file": [3, 7, 8, 9, 10, 29], "save": [3, 29], "option": [3, 13, 19, 23, 24, 26, 27, 29, 39, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "If": [3, 13, 21, 29, 78, 79, 81, 82, 113], "true": [3, 42, 43, 44, 45, 46, 47, 48, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "modifi": [3, 29], "place": 3, "otherwis": 3, "ar": [3, 29, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "add": [3, 63, 64, 70, 86, 87, 91, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "ani": [3, 42, 43, 44, 45, 46, 47, 48, 50, 56, 58, 77, 80, 88, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "categori": [3, 40, 113], "includ": [3, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "pass": [3, 13, 29, 71, 72, 92, 93, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "rate": 3, "minimum": [3, 43, 44, 45, 46, 47, 48, 58], "column": [3, 29, 99], "each": [3, 40, 101, 113], "test_typ": [3, 40, 113], "ratio": 3, "divid": 3, "proportion_increas": 3, "much": 3, "increas": 3, "reach": 3, "datafactori": 29, "file_path": [7, 8, 9, 10], "factori": [9, 21, 40], "dataset": [7, 8, 9, 10, 29, 34, 35, 36, 38, 39, 52], "respons": 9, "correct": [9, 113], "extens": 9, "load": [7, 8, 9, 10, 18, 19, 21, 23, 24, 26, 27, 29], "text": [9, 18, 19, 21, 23, 24, 26, 27, 31, 99, 113, 114], "conlldataset": [], "handl": [7, 8, 10], "conll": [8, 12, 13, 14, 15, 29], "subclass": [7, 8, 10, 12, 13, 14, 15, 31, 43, 44, 45, 46, 47, 48, 57, 58, 78, 79, 81, 82], "_idataset": [7, 8, 10], "load_data": [7, 8, 10], "util": [], "custom_typ": [12, 14, 15], "sentenc": [8, 51, 52, 53, 54, 61, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 74, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 113], "jsondataset": [], "json": [10, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "csvdataset": [], "csv": [7, 12, 13, 14, 15], "baseformatt": [13, 14, 15], "defin": [12, 13, 37], "formatt": [12, 14, 15], "static": [12, 15, 18, 19, 40, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 58, 61, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 74, 77, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95], "to_csv": [12, 13, 14, 15], "to_conl": [12, 13, 14, 15], "convert": [12, 13, 14, 15, 61, 62, 66, 84, 85, 89, 99, 111, 114], "custom": [12, 13, 14, 15, 21], "represent": [12, 14, 15, 38, 100, 101, 102, 103, 104, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "between": 13, "differ": [13, 29, 37, 40], "output": [13, 19, 42, 50, 56, 57, 58, 77, 88, 108, 109, 110, 111, 114], "convers": [13, 61, 62, 66, 84, 85, 89], "appropri": 13, "select": 13, "expect": 13, "argument": [13, 14, 15, 23, 26, 27, 29, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "either": [13, 21, 31, 32], "posit": 13, "kwarg": [13, 18, 19, 21, 23, 24, 26, 27], "keyword": [13, 23, 26, 27, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "nameerror": 13, "sequenceclassificationoutputformatt": [], "sequenceclassificationoutput": [15, 19, 21, 24, 27], "repres": [14, 15, 31, 32, 34, 35, 36, 38, 39], "delimit": [14, 15], "charact": [14, 15], "neroutputformatt": [], "neroutput": [14, 18, 21, 23, 26, 113], "temp_id": 14, "temporari": 14, "group": [14, 23, 26, 27], "entiti": [14, 18, 23, 26, 27, 71, 72, 92, 93, 99, 101], "pretrainedmodelforn": [], "nlu": [], "nlupipelin": [18, 19], "sparknlp": [18, 19, 21, 31, 32], "pretrain": [18, 19, 23, 24, 26], "pretrainedpipelin": [18, 19], "lightpipelin": [18, 19], "pyspark": [], "ml": [], "pipelinemodel": [18, 19], "overrid": [], "load_model": [18, 19, 21, 23, 24, 26, 27], "predict": [18, 19, 21, 23, 24, 26, 27, 31, 42, 43, 44, 45, 46, 47, 48, 99, 111, 113, 114], "classmethod": [18, 21, 23, 26, 27, 29, 34, 35, 36, 37, 38, 39, 40, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "local": [18, 19, 21], "recogn": [18, 23, 26], "predict_raw": [18, 21, 23, 24, 26, 27], "label": [18, 19, 23, 24, 26, 27, 71, 72, 81, 92, 93, 99, 103, 115], "is_ner_annot": 18, "model_inst": [18, 19], "support": [18, 19, 21, 34, 35, 36, 38, 39, 113], "pretrainedmodelfortextclassif": [], "return_all_scor": [19, 24, 27], "score": [19, 24, 43, 44, 45, 46, 47, 48, 57, 58, 108, 109, 110, 112, 115], "classif": [19, 24, 27, 114], "is_classifi": 19, "classifi": [19, 24], "modelfactori": [29, 31, 32, 34, 35, 36, 38, 39, 40, 42], "instanti": 21, "disk": 21, "spaci": [21, 23, 24, 31, 32], "pipelin": [23, 24, 26, 27], "addit": [23, 26, 27], "group_ent": [23, 26], "form": [23, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "huggingfac": [21, 26], "evalu": [29, 31, 32, 77, 78, 79, 80, 81, 82, 100, 102, 103, 104], "testcas": [29, 31, 32], "when": [29, 75, 96], "store": [29, 113], "_testcas": 29, "generated_result": 29, "pd": [29, 32], "overal": 29, "everi": 29, "textcas": 29, "labelwis": 29, "metric": 29, "augment": [29, 71, 92], "locat": 29, "whether": [29, 113], "directli": 29, "call": [29, 113], "valueerror": [21, 29, 78, 79, 81, 82], "pass_rat": 29, "minimum_pass_r": 29, "have": [29, 63, 86], "unexpect": 29, "note": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "exampl": 29, "train": 29, "augmented_train": 29, "after": [29, 34, 35, 36, 38, 39], "save_dir": 29, "reus": 29, "later": 29, "folder": 29, "save_testcas": 29, "path_to_fil": 29, "pickl": 29, "modelhandl": [], "previous": 29, "need": [29, 51, 52, 53, 54, 67, 113], "which": [29, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "requir": 29, "previou": 29, "along": 29, "load_testcas": [29, 31, 32], "model_handl": [31, 32], "tupl": [32, 113], "robustnesstestrunn": [], "robust": [31, 34, 35, 36, 38, 39], "both": [31, 61, 84], "origin": [31, 75, 96, 113], "pertub": 31, "one": [31, 71, 72, 92, 93, 113], "baseaccuraci": [43, 44, 45, 46, 47, 48], "measur": [42, 50, 56, 77, 78, 79, 80, 81, 82, 88], "alias_nam": [34, 35, 36, 38, 39, 42, 43, 44, 45, 46, 47, 48, 50, 56, 57, 58, 77, 78, 79, 81, 82, 88], "identifi": [42, 50, 56, 57, 58, 77, 78, 79, 81, 82, 88], "y_true": [42, 43, 44, 45, 46, 47, 48], "y_pred": [42, 43, 44, 45, 46, 47, 48], "evalut": 42, "minprecisionscor": [], "precis": [43, 44, 45, 46, 47], "min_precision_scor": [43, 44, 46, 47], "param": [18, 19, 21, 26, 43, 44, 45, 46, 47, 48, 56, 57, 58, 61, 62, 63, 64, 66, 68, 73, 74, 78, 79, 81, 82, 84, 85, 86, 87, 89, 90, 94, 95], "comput": [43, 44, 45, 46, 47, 48, 57, 58], "f1": [43, 44, 45, 46, 48, 57, 58], "minrecallscor": [], "recal": 47, "minf1scor": [], "minmicrof1scor": [], "minmacrof1scor": [], "minweightedf1scor": [], "weight": 48, "basebia": [51, 52, 53, 54], "genderpronounbia": [], "sample_list": [51, 52, 53, 54, 61, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 74, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95], "pronouns_to_substitut": [53, 67], "pronoun_typ": [53, 67], "replac": [51, 52, 53, 54, 67], "pronoun": [53, 67], "gender": [53, 57, 59, 67], "substitut": [51, 52, 53, 54, 67, 105], "male": [53, 67], "femal": [53, 67], "neutral": [53, 67], "countryeconomicbia": [], "country_names_to_substitut": 51, "chosen_country_nam": 51, "countri": [51, 78, 100], "ethnic": [51, 52, 79, 102], "ethnicitynamebia": [], "names_to_substitut": [52, 54], "chosen_ethnicity_nam": 52, "curat": 52, "unit": 52, "state": [52, 113], "censu": 52, "bureau": 52, "survei": 52, "religionbia": [], "chosen_nam": 54, "religion": [54, 82, 104], "testfactori": [], "test_categori": 40, "map": 40, "correspond": [34, 35, 36, 38, 39, 40, 71, 72, 92, 93, 99, 113], "test_scenario": 40, "avail": [34, 35, 36, 37, 38, 39, 40], "scenario": [34, 35, 36, 37, 38, 39, 40], "test_catgori": 40, "itest": [34, 35, 36, 38, 39], "available_test": [34, 35, 36, 37, 38, 39], "robustnesstestfactori": [], "data_handl": [34, 35, 36, 38, 39, 69], "supported_test": [34, 35, 36, 38, 39], "_data_handl": [34, 35, 36, 38, 39], "kei": [34, 35, 36, 38, 39], "biastestfactori": [], "bia": [35, 67], "representationtestfactori": [], "accuracytestfactori": [], "accuraci": [34, 56, 108, 109, 110], "baseperturb": [61, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 74], "helper": [105, 113], "provid": [71, 92], "standard": [], "wai": 113, "abc": [4, 12, 37, 42, 50, 56, 65, 77, 88], "uppercas": [], "lowercas": [], "titlecas": [], "addpunctu": [], "whitelist": [63, 70, 86, 91], "punctuat": [63, 70, 86, 91], "end": [61, 63, 70, 84, 86, 91, 116], "skip": [63, 70, 86, 91], "strippunctu": [], "isn": [70, 91], "t": [70, 91, 113], "strip": [70, 91], "addtypo": [], "typo": [64, 87], "keyboard": [64, 87], "swap": [64, 71, 72, 87, 92, 93], "introduc": [64, 87], "swapent": [], "terminologi": [71, 72, 92, 93, 99], "extract": [71, 72, 92, 93], "process": [61, 62, 66, 71, 72, 84, 85, 89, 92, 93], "make": [71, 72, 92, 93, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "chang": [71, 72, 92, 93, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "accord": [71, 72, 92, 93, 113], "word": [72, 75, 93, 96, 98, 99, 116], "get_cohyponyms_wordnet": [], "retriev": [75, 96], "co": [75, 96], "hyponym": [75, 96], "wordnet": [75, 96], "hit": [75, 96], "cohyponym": [75, 96], "exist": [75, 96], "swapcohyponym": [], "tag": [71, 92], "convertacc": [], "accent_map": [66, 89], "term": [61, 66, 84, 89], "accent": [66, 89], "addcontext": [], "starting_context": [61, 84], "ending_context": [61, 84], "strategi": [61, 84], "adjust": [61, 84], "where": [61, 84], "context": [61, 84], "token": [61, 84], "ad": [61, 84, 113], "combin": [61, 84], "beg": [61, 84], "randomli": [61, 84], "addcontract": [], "baserepresent": [78, 79, 80, 81, 82], "genderreprest": [], "baserobust": [84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95], "get_substitution_nam": [], "values_list": 105, "create_terminologi": [], "ner_data": 99, "iter": 99, "over": [99, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "iob": 99, "format": 99, "io": 99, "ha": 99, "to_str_list": [111, 114], "ouput": [111, 114], "accuracyoutput": [], "them": 113, "specif": 113, "here": 113, "agnost": 113, "onli": 113, "access": 113, "is_pass": 113, "assess": 113, "expected_result": 113, "actual_result": 113, "same": 113, "regardless": 113, "downstream": 113, "xxxoutput": 113, "__eq__": 113, "variabl": 113, "to_dict": 113, "version": 113, "sort_transform": 113, "v": 113, "valid": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "ensur": 113, "order": 113, "get_aligned_span_pair": 113, "nerpredict": [111, 113], "align": 113, "span": [112, 113, 117], "achiev": 113, "couldn": 113, "other": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "basefair": [57, 58], "mingenderf1scor": [], "min_f1": 58, "maxgenderf1scor": [], "max": 57, "get_gendered_data": [], "split": 59, "fairnesstestfactori": [], "fair": 36, "genderrepresent": [], "ethnicityrepresent": [], "sum": [78, 79, 81, 82], "greater": [78, 79, 81, 82], "than": [78, 79, 81, 82], "labelrepresent": [], "religionrepresent": [], "countryeconomicrepresent": [], "econom": [78, 100], "get_label_representation_dict": [], "inform": [100, 101, 102, 103, 104, 123], "get_country_economic_representation_dict": [], "get_religion_name_representation_dict": [], "get_ethnicity_representation_dict": [], "get_entity_representation_proport": [], "entity_represent": 101, "minscoreoutput": [], "maxscoreoutput": [], "_modelhandl": [18, 19, 23, 24, 26, 27], "infer": [18, 19], "invalid": 29, "handler": [31, 32], "name_list": 98, "basemodel": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "validationerror": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "cannot": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "construct": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "_fields_set": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "setstr": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "__dict__": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "__fields_set__": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "trust": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "pre": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "respect": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "behav": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "extra": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "allow": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "wa": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "sinc": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "copi": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "abstractsetintstr": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "mappingintstrani": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "exclud": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "updat": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "dictstrani": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "deep": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "duplic": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "choos": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "field": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "take": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "preced": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "befor": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "by_alia": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "skip_default": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "exclude_unset": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "exclude_default": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "exclude_non": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "encod": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "callabl": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "models_as_dict": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "dumps_kwarg": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "unicod": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "per": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "suppli": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "dump": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "update_forward_ref": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "localn": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "try": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "forwardref": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "globaln": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "entity_group": 112, "doc_id": 112, "int": [112, 116], "doc_nam": 112, "pos_tag": 112, "chunk_tag": 112, "test_cas": 113, "ignored_predict": 113, "ignor": [113, 117], "becaus": 113, "realigned_span": 113, "charg": 113, "shift": 113, "were": 113, "dure": 113, "realign": 113, "sequencelabel": 114, "original_span": 117, "new_span": 117, "lib": 121, "about": 123, "librari": 123, "user_guid": [], "rtype": 29, "doc": 124, "section": 124}, "objects": {"": [[0, 0, 0, "-", "nlptest"]], "nlptest": [[1, 0, 0, "-", "augmentation"], [5, 0, 0, "-", "datahandler"], [16, 0, 0, "-", "modelhandler"], [28, 0, 0, "-", "nlptest"], [30, 0, 0, "-", "testrunner"], [33, 0, 0, "-", "transform"], [106, 0, 0, "-", "utils"]], "nlptest.augmentation": [[2, 0, 0, "-", "fix_robustness"]], "nlptest.augmentation.fix_robustness": [[3, 1, 1, "", "AugmentRobustness"], [4, 1, 1, "", "BaseAugmentaion"]], "nlptest.augmentation.fix_robustness.AugmentRobustness": [[3, 2, 1, "id0", "__init__"], [3, 3, 1, "", "config"], [3, 2, 1, "id1", "fix"], [3, 3, 1, "", "h_report"], [3, 3, 1, "", "max_prop"], [3, 2, 1, "id2", "suggestions"], [3, 3, 1, "", "task"]], "nlptest.augmentation.fix_robustness.BaseAugmentaion": [[4, 3, 1, "", "None"], [4, 2, 1, "", "__init__"], [4, 2, 1, "id0", "fix"]], "nlptest.datahandler": [[6, 0, 0, "-", "datasource"], [11, 0, 0, "-", "format"]], "nlptest.datahandler.datasource": [[7, 1, 1, "", "CSVDataset"], [8, 1, 1, "", "ConllDataset"], [9, 1, 1, "", "DataFactory"], [10, 1, 1, "", "JSONDataset"]], "nlptest.datahandler.datasource.CSVDataset": [[7, 2, 1, "", "__init__"], [7, 2, 1, "", "load_data"]], "nlptest.datahandler.datasource.ConllDataset": [[8, 2, 1, "", "__init__"], [8, 2, 1, "", "load_data"]], "nlptest.datahandler.datasource.DataFactory": [[9, 2, 1, "", "__init__"], [9, 2, 1, "", "load"]], "nlptest.datahandler.datasource.JSONDataset": [[10, 2, 1, "", "__init__"], [10, 2, 1, "", "load_data"]], "nlptest.datahandler.format": [[12, 1, 1, "", "BaseFormatter"], [13, 1, 1, "", "Formatter"], [14, 1, 1, "", "NEROutputFormatter"], [15, 1, 1, "", "SequenceClassificationOutputFormatter"]], "nlptest.datahandler.format.BaseFormatter": [[12, 2, 1, "", "__init__"], [12, 2, 1, "", "to_conll"], [12, 2, 1, "", "to_csv"]], "nlptest.datahandler.format.Formatter": [[13, 2, 1, "", "__init__"]], "nlptest.datahandler.format.NEROutputFormatter": [[14, 2, 1, "", "__init__"], [14, 2, 1, "", "to_conll"], [14, 2, 1, "", "to_csv"]], "nlptest.datahandler.format.SequenceClassificationOutputFormatter": [[15, 2, 1, "", "__init__"], [15, 2, 1, "", "to_conll"], [15, 2, 1, "", "to_csv"]], "nlptest.modelhandler": [[17, 0, 0, "-", "jsl_modelhandler"], [20, 0, 0, "-", "modelhandler"], [22, 0, 0, "-", "spacy_modelhandler"], [25, 0, 0, "-", "transformers_modelhandler"]], "nlptest.modelhandler.jsl_modelhandler": [[18, 1, 1, "", "PretrainedModelForNER"], [19, 1, 1, "", "PretrainedModelForTextClassification"]], "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForNER": [[18, 2, 1, "", "__init__"], [18, 2, 1, "", "is_ner_annotator"], [18, 2, 1, "", "load_model"], [18, 3, 1, "id0", "model"], [18, 2, 1, "", "predict"], [18, 2, 1, "", "predict_raw"]], "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification": [[19, 2, 1, "", "__init__"], [19, 2, 1, "", "is_classifier"], [19, 2, 1, "", "load_model"], [19, 3, 1, "id0", "model"], [19, 2, 1, "", "predict"]], "nlptest.modelhandler.modelhandler": [[21, 1, 1, "", "ModelFactory"]], "nlptest.modelhandler.modelhandler.ModelFactory": [[21, 2, 1, "", "__init__"], [21, 2, 1, "", "load_model"], [21, 2, 1, "", "predict"], [21, 2, 1, "", "predict_raw"]], "nlptest.modelhandler.spacy_modelhandler": [[23, 1, 1, "", "PretrainedModelForNER"], [24, 1, 1, "", "PretrainedModelForTextClassification"]], "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForNER": [[23, 2, 1, "", "__init__"], [23, 2, 1, "", "load_model"], [23, 2, 1, "", "predict"], [23, 2, 1, "", "predict_raw"]], "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification": [[24, 2, 1, "", "__init__"], [24, 4, 1, "", "labels"], [24, 2, 1, "", "load_model"], [24, 2, 1, "", "predict"], [24, 2, 1, "", "predict_raw"]], "nlptest.modelhandler.transformers_modelhandler": [[26, 1, 1, "", "PretrainedModelForNER"], [27, 1, 1, "", "PretrainedModelForTextClassification"], [25, 3, 1, "", "model"]], "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForNER": [[26, 2, 1, "", "__init__"], [26, 2, 1, "", "load_model"], [26, 3, 1, "id0", "model"], [26, 2, 1, "", "predict"], [26, 2, 1, "", "predict_raw"]], "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification": [[27, 2, 1, "", "__init__"], [27, 4, 1, "", "labels"], [27, 2, 1, "", "load_model"], [27, 3, 1, "", "model"], [27, 2, 1, "", "predict"], [27, 2, 1, "", "predict_raw"]], "nlptest.nlptest": [[29, 1, 1, "", "Harness"]], "nlptest.nlptest.Harness": [[29, 2, 1, "", "__init__"], [29, 2, 1, "", "augment"], [29, 2, 1, "", "configure"], [29, 2, 1, "", "generate"], [29, 2, 1, "", "generated_results"], [29, 2, 1, "", "load"], [29, 2, 1, "", "load_testcases"], [29, 2, 1, "", "report"], [29, 2, 1, "", "run"], [29, 2, 1, "", "save"], [29, 2, 1, "", "save_testcases"], [29, 2, 1, "", "testcases"]], "nlptest.testrunner": [[31, 1, 1, "", "RobustnessTestRunner"], [32, 1, 1, "", "TestRunner"]], "nlptest.testrunner.RobustnessTestRunner": [[31, 2, 1, "", "__init__"], [31, 2, 1, "", "evaluate"]], "nlptest.testrunner.TestRunner": [[32, 2, 1, "", "__init__"], [32, 2, 1, "", "evaluate"]], "nlptest.transform": [[34, 1, 1, "", "AccuracyTestFactory"], [35, 1, 1, "", "BiasTestFactory"], [36, 1, 1, "", "FairnessTestFactory"], [37, 1, 1, "", "ITests"], [38, 1, 1, "", "RepresentationTestFactory"], [39, 1, 1, "", "RobustnessTestFactory"], [40, 1, 1, "", "TestFactory"], [41, 0, 0, "-", "accuracy"], [49, 0, 0, "-", "bias"], [55, 0, 0, "-", "fairness"], [60, 0, 0, "-", "perturbation"], [76, 0, 0, "-", "representation"], [83, 0, 0, "-", "robustness"], [97, 0, 0, "-", "utils"]], "nlptest.transform.AccuracyTestFactory": [[34, 2, 1, "", "__init__"], [34, 3, 1, "", "_data_handler"], [34, 3, 1, "", "alias_name"], [34, 2, 1, "id0", "available_tests"], [34, 3, 1, "", "supported_tests"], [34, 3, 1, "", "tests"], [34, 2, 1, "id1", "transform"]], "nlptest.transform.BiasTestFactory": [[35, 2, 1, "", "__init__"], [35, 3, 1, "", "_data_handler"], [35, 3, 1, "", "alias_name"], [35, 2, 1, "id0", "available_tests"], [35, 3, 1, "", "supported_tests"], [35, 3, 1, "", "tests"], [35, 2, 1, "id1", "transform"]], "nlptest.transform.FairnessTestFactory": [[36, 2, 1, "", "__init__"], [36, 3, 1, "", "_data_handler"], [36, 3, 1, "", "alias_name"], [36, 2, 1, "id0", "available_tests"], [36, 3, 1, "", "supported_tests"], [36, 3, 1, "", "tests"], [36, 2, 1, "id1", "transform"]], "nlptest.transform.ITests": [[37, 2, 1, "", "__init__"], [37, 2, 1, "id0", "available_tests"], [37, 2, 1, "id1", "transform"]], "nlptest.transform.RepresentationTestFactory": [[38, 2, 1, "", "__init__"], [38, 3, 1, "", "_data_handler"], [38, 3, 1, "", "alias_name"], [38, 2, 1, "id0", "available_tests"], [38, 3, 1, "", "supported_tests"], [38, 3, 1, "", "tests"], [38, 2, 1, "id1", "transform"]], "nlptest.transform.RobustnessTestFactory": [[39, 2, 1, "", "__init__"], [39, 3, 1, "", "_data_handler"], [39, 3, 1, "", "alias_name"], [39, 2, 1, "id0", "available_tests"], [39, 3, 1, "", "supported_tests"], [39, 3, 1, "", "tests"], [39, 2, 1, "id1", "transform"]], "nlptest.transform.TestFactory": [[40, 2, 1, "", "__init__"], [40, 2, 1, "", "test_categories"], [40, 2, 1, "", "test_catgories"], [40, 2, 1, "id0", "test_scenarios"], [40, 2, 1, "id1", "transform"]], "nlptest.transform.accuracy": [[42, 1, 1, "", "BaseAccuracy"], [43, 1, 1, "", "MinF1Score"], [44, 1, 1, "", "MinMacroF1Score"], [45, 1, 1, "", "MinMicroF1Score"], [46, 1, 1, "", "MinPrecisionScore"], [47, 1, 1, "", "MinRecallScore"], [48, 1, 1, "", "MinWeightedF1Score"]], "nlptest.transform.accuracy.BaseAccuracy": [[42, 2, 1, "", "__init__"], [42, 3, 1, "", "alias_name"], [42, 2, 1, "", "transform"]], "nlptest.transform.accuracy.MinF1Score": [[43, 2, 1, "", "__init__"], [43, 3, 1, "", "alias_name"], [43, 2, 1, "id0", "transform"]], "nlptest.transform.accuracy.MinMacroF1Score": [[44, 2, 1, "", "__init__"], [44, 3, 1, "", "alias_name"], [44, 2, 1, "id0", "transform"]], "nlptest.transform.accuracy.MinMicroF1Score": [[45, 2, 1, "", "__init__"], [45, 3, 1, "", "alias_name"], [45, 2, 1, "id0", "transform"]], "nlptest.transform.accuracy.MinPrecisionScore": [[46, 2, 1, "", "__init__"], [46, 3, 1, "", "alias_name"], [46, 2, 1, "id0", "transform"]], "nlptest.transform.accuracy.MinRecallScore": [[47, 2, 1, "", "__init__"], [47, 3, 1, "", "alias_name"], [47, 2, 1, "id0", "transform"]], "nlptest.transform.accuracy.MinWeightedF1Score": [[48, 2, 1, "", "__init__"], [48, 3, 1, "", "alias_name"], [48, 2, 1, "id0", "transform"]], "nlptest.transform.bias": [[50, 1, 1, "", "BaseBias"], [51, 1, 1, "", "CountryEconomicBias"], [52, 1, 1, "", "EthnicityNameBias"], [53, 1, 1, "", "GenderPronounBias"], [54, 1, 1, "", "ReligionBias"]], "nlptest.transform.bias.BaseBias": [[50, 2, 1, "", "__init__"], [50, 3, 1, "", "alias_name"], [50, 2, 1, "", "transform"]], "nlptest.transform.bias.CountryEconomicBias": [[51, 2, 1, "", "__init__"], [51, 2, 1, "", "transform"]], "nlptest.transform.bias.EthnicityNameBias": [[52, 2, 1, "", "__init__"], [52, 2, 1, "", "transform"]], "nlptest.transform.bias.GenderPronounBias": [[53, 2, 1, "", "__init__"], [53, 2, 1, "", "transform"]], "nlptest.transform.bias.ReligionBias": [[54, 2, 1, "", "__init__"], [54, 2, 1, "", "transform"]], "nlptest.transform.fairness": [[56, 1, 1, "", "BaseFairness"], [57, 1, 1, "", "MaxGenderF1Score"], [58, 1, 1, "", "MinGenderF1Score"], [59, 5, 1, "", "get_gendered_data"]], "nlptest.transform.fairness.BaseFairness": [[56, 2, 1, "", "__init__"], [56, 3, 1, "", "alias_name"], [56, 2, 1, "", "transform"]], "nlptest.transform.fairness.MaxGenderF1Score": [[57, 2, 1, "", "__init__"], [57, 3, 1, "", "alias_name"], [57, 2, 1, "", "transform"]], "nlptest.transform.fairness.MinGenderF1Score": [[58, 2, 1, "", "__init__"], [58, 3, 1, "", "alias_name"], [58, 2, 1, "", "transform"]], "nlptest.transform.perturbation": [[61, 1, 1, "", "AddContext"], [62, 1, 1, "", "AddContraction"], [63, 1, 1, "", "AddPunctuation"], [64, 1, 1, "", "AddTypo"], [65, 1, 1, "", "BasePerturbation"], [66, 1, 1, "", "ConvertAccent"], [67, 1, 1, "", "GenderPronounBias"], [68, 1, 1, "", "LowerCase"], [69, 1, 1, "", "PerturbationFactory"], [70, 1, 1, "", "StripPunctuation"], [71, 1, 1, "", "SwapCohyponyms"], [72, 1, 1, "", "SwapEntities"], [73, 1, 1, "", "TitleCase"], [74, 1, 1, "", "UpperCase"], [75, 5, 1, "", "get_cohyponyms_wordnet"]], "nlptest.transform.perturbation.AddContext": [[61, 2, 1, "", "__init__"], [61, 2, 1, "", "transform"]], "nlptest.transform.perturbation.AddContraction": [[62, 2, 1, "", "__init__"], [62, 2, 1, "", "transform"]], "nlptest.transform.perturbation.AddPunctuation": [[63, 2, 1, "", "__init__"], [63, 2, 1, "", "transform"]], "nlptest.transform.perturbation.AddTypo": [[64, 2, 1, "", "__init__"], [64, 2, 1, "", "transform"]], "nlptest.transform.perturbation.BasePerturbation": [[65, 2, 1, "", "__init__"]], "nlptest.transform.perturbation.ConvertAccent": [[66, 2, 1, "", "__init__"], [66, 2, 1, "", "transform"]], "nlptest.transform.perturbation.GenderPronounBias": [[67, 2, 1, "", "__init__"], [67, 2, 1, "", "transform"]], "nlptest.transform.perturbation.LowerCase": [[68, 2, 1, "", "__init__"], [68, 2, 1, "", "transform"]], "nlptest.transform.perturbation.PerturbationFactory": [[69, 2, 1, "", "__init__"]], "nlptest.transform.perturbation.StripPunctuation": [[70, 2, 1, "", "__init__"], [70, 2, 1, "", "transform"]], "nlptest.transform.perturbation.SwapCohyponyms": [[71, 2, 1, "", "__init__"], [71, 2, 1, "", "transform"]], "nlptest.transform.perturbation.SwapEntities": [[72, 2, 1, "", "__init__"], [72, 2, 1, "", "transform"]], "nlptest.transform.perturbation.TitleCase": [[73, 2, 1, "", "__init__"], [73, 2, 1, "", "transform"]], "nlptest.transform.perturbation.UpperCase": [[74, 2, 1, "", "__init__"], [74, 2, 1, "", "transform"]], "nlptest.transform.representation": [[77, 1, 1, "", "BaseRepresentation"], [78, 1, 1, "", "CountryEconomicRepresentation"], [79, 1, 1, "", "EthnicityRepresentation"], [80, 1, 1, "", "GenderRepresentation"], [81, 1, 1, "", "LabelRepresentation"], [82, 1, 1, "", "ReligionRepresentation"]], "nlptest.transform.representation.BaseRepresentation": [[77, 2, 1, "", "__init__"], [77, 3, 1, "", "alias_name"], [77, 2, 1, "", "transform"]], "nlptest.transform.representation.CountryEconomicRepresentation": [[78, 2, 1, "", "__init__"], [78, 3, 1, "", "alias_name"], [78, 2, 1, "", "transform"]], "nlptest.transform.representation.EthnicityRepresentation": [[79, 2, 1, "", "__init__"], [79, 3, 1, "", "alias_name"], [79, 2, 1, "", "transform"]], "nlptest.transform.representation.GenderRepresentation": [[80, 2, 1, "", "__init__"], [80, 2, 1, "", "transform"]], "nlptest.transform.representation.LabelRepresentation": [[81, 2, 1, "", "__init__"], [81, 3, 1, "", "alias_name"], [81, 2, 1, "", "transform"]], "nlptest.transform.representation.ReligionRepresentation": [[82, 2, 1, "", "__init__"], [82, 3, 1, "", "alias_name"], [82, 2, 1, "", "transform"]], "nlptest.transform.robustness": [[84, 1, 1, "", "AddContext"], [85, 1, 1, "", "AddContraction"], [86, 1, 1, "", "AddPunctuation"], [87, 1, 1, "", "AddTypo"], [88, 1, 1, "", "BaseRobustness"], [89, 1, 1, "", "ConvertAccent"], [90, 1, 1, "", "LowerCase"], [91, 1, 1, "", "StripPunctuation"], [92, 1, 1, "", "SwapCohyponyms"], [93, 1, 1, "", "SwapEntities"], [94, 1, 1, "", "TitleCase"], [95, 1, 1, "", "UpperCase"], [96, 5, 1, "", "get_cohyponyms_wordnet"]], "nlptest.transform.robustness.AddContext": [[84, 2, 1, "", "__init__"], [84, 2, 1, "", "transform"]], "nlptest.transform.robustness.AddContraction": [[85, 2, 1, "", "__init__"], [85, 2, 1, "", "transform"]], "nlptest.transform.robustness.AddPunctuation": [[86, 2, 1, "", "__init__"], [86, 2, 1, "", "transform"]], "nlptest.transform.robustness.AddTypo": [[87, 2, 1, "", "__init__"], [87, 2, 1, "", "transform"]], "nlptest.transform.robustness.BaseRobustness": [[88, 2, 1, "", "__init__"], [88, 3, 1, "", "alias_name"], [88, 2, 1, "", "transform"]], "nlptest.transform.robustness.ConvertAccent": [[89, 2, 1, "", "__init__"], [89, 2, 1, "", "transform"]], "nlptest.transform.robustness.LowerCase": [[90, 2, 1, "", "__init__"], [90, 2, 1, "", "transform"]], "nlptest.transform.robustness.StripPunctuation": [[91, 2, 1, "", "__init__"], [91, 2, 1, "", "transform"]], "nlptest.transform.robustness.SwapCohyponyms": [[92, 2, 1, "", "__init__"], [92, 2, 1, "", "transform"]], "nlptest.transform.robustness.SwapEntities": [[93, 2, 1, "", "__init__"], [93, 2, 1, "", "transform"]], "nlptest.transform.robustness.TitleCase": [[94, 2, 1, "", "__init__"], [94, 2, 1, "", "transform"]], "nlptest.transform.robustness.UpperCase": [[95, 2, 1, "", "__init__"], [95, 2, 1, "", "transform"]], "nlptest.transform.utils": [[98, 5, 1, "", "check_name"], [99, 5, 1, "", "create_terminology"], [100, 5, 1, "", "get_country_economic_representation_dict"], [101, 5, 1, "", "get_entity_representation_proportions"], [102, 5, 1, "", "get_ethnicity_representation_dict"], [103, 5, 1, "", "get_label_representation_dict"], [104, 5, 1, "", "get_religion_name_representation_dict"], [105, 5, 1, "", "get_substitution_names"]], "nlptest.utils": [[107, 0, 0, "-", "custom_types"], [118, 0, 0, "-", "gender_classifier"], [120, 0, 0, "-", "lib_manager"]], "nlptest.utils.custom_types": [[108, 1, 1, "", "AccuracyOutput"], [109, 1, 1, "", "MaxScoreOutput"], [110, 1, 1, "", "MinScoreOutput"], [111, 1, 1, "", "NEROutput"], [112, 1, 1, "", "NERPrediction"], [113, 1, 1, "", "Sample"], [114, 1, 1, "", "SequenceClassificationOutput"], [115, 1, 1, "", "SequenceLabel"], [116, 1, 1, "", "Span"], [117, 1, 1, "", "Transformation"]], "nlptest.utils.custom_types.AccuracyOutput": [[108, 2, 1, "", "__init__"], [108, 2, 1, "", "construct"], [108, 2, 1, "", "copy"], [108, 2, 1, "", "dict"], [108, 2, 1, "", "json"], [108, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.MaxScoreOutput": [[109, 2, 1, "", "__init__"], [109, 2, 1, "", "construct"], [109, 2, 1, "", "copy"], [109, 2, 1, "", "dict"], [109, 2, 1, "", "json"], [109, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.MinScoreOutput": [[110, 2, 1, "", "__init__"], [110, 2, 1, "", "construct"], [110, 2, 1, "", "copy"], [110, 2, 1, "", "dict"], [110, 2, 1, "", "json"], [110, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.NEROutput": [[111, 2, 1, "", "__init__"], [111, 2, 1, "", "construct"], [111, 2, 1, "", "copy"], [111, 2, 1, "", "dict"], [111, 2, 1, "", "json"], [111, 2, 1, "", "to_str_list"], [111, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.NERPrediction": [[112, 2, 1, "", "__init__"], [112, 2, 1, "", "construct"], [112, 2, 1, "", "copy"], [112, 2, 1, "", "dict"], [112, 2, 1, "", "json"], [112, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.Sample": [[113, 2, 1, "", "__init__"], [113, 2, 1, "", "construct"], [113, 2, 1, "", "copy"], [113, 2, 1, "", "dict"], [113, 2, 1, "", "get_aligned_span_pairs"], [113, 4, 1, "", "ignored_predictions"], [113, 2, 1, "", "json"], [113, 4, 1, "", "realigned_spans"], [113, 2, 1, "", "sort_transformations"], [113, 2, 1, "", "to_dict"], [113, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.SequenceClassificationOutput": [[114, 2, 1, "", "__init__"], [114, 2, 1, "", "construct"], [114, 2, 1, "", "copy"], [114, 2, 1, "", "dict"], [114, 2, 1, "", "json"], [114, 2, 1, "", "to_str_list"], [114, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.SequenceLabel": [[115, 2, 1, "", "__init__"], [115, 2, 1, "", "construct"], [115, 2, 1, "", "copy"], [115, 2, 1, "", "dict"], [115, 2, 1, "", "json"], [115, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.Span": [[116, 2, 1, "", "__init__"], [116, 2, 1, "", "construct"], [116, 2, 1, "", "copy"], [116, 2, 1, "", "dict"], [116, 2, 1, "", "json"], [116, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.Transformation": [[117, 2, 1, "", "__init__"], [117, 2, 1, "", "construct"], [117, 2, 1, "", "copy"], [117, 2, 1, "", "dict"], [117, 2, 1, "", "json"], [117, 2, 1, "", "update_forward_refs"]], "nlptest.utils.gender_classifier": [[119, 1, 1, "", "GenderClassifier"]], "nlptest.utils.gender_classifier.GenderClassifier": [[119, 2, 1, "", "__init__"]], "nlptest.utils.lib_manager": [[121, 5, 1, "", "try_import_lib"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:property", "5": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "property", "Python property"], "5": ["py", "function", "Python function"]}, "titleterms": {"welcom": 123, "nlptest": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121], "": [], "document": [], "indic": [], "tabl": [], "get": [], "start": [122, 123], "nlp": [122, 123], "test": [122, 123], "cheat": [], "sheet": [], "instal": 122, "us": [], "conda": [], "virtualenv": [], "content": [], "quick": [122, 123], "doc": 123, "page": 123, "user": [123, 124], "guid": [123, 124], "api": 123, "refer": [], "modul": [], "augment": [1, 2, 3, 4], "fix_robust": [2, 3, 4], "class": [], "datahandl": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "datasourc": [6, 7, 8, 9, 10], "format": [11, 12, 13, 14, 15], "modelhandl": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "jsl_modelhandl": [17, 18, 19], "spacy_modelhandl": [22, 23, 24], "transformers_modelhandl": [25, 26, 27], "testrunn": [30, 31, 32], "transform": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 117], "accuraci": [41, 42, 43, 44, 45, 46, 47, 48], "bia": [49, 50, 51, 52, 53, 54], "packag": [], "method": [], "paramet": [], "return": [], "attribut": [], "perturb": [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "function": [], "represent": [76, 77, 78, 79, 80, 81, 82], "robust": [83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96], "util": [97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121], "custom_typ": [107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "lib_manag": [120, 121], "fair": [55, 56, 57, 58, 59], "gender_classifi": [118, 119], "augmentrobust": 3, "baseaugmentaion": 4, "csvdataset": 7, "conlldataset": 8, "datafactori": 9, "jsondataset": 10, "baseformatt": 12, "formatt": 13, "neroutputformatt": 14, "sequenceclassificationoutputformatt": 15, "pretrainedmodelforn": [18, 23, 26], "pretrainedmodelfortextclassif": [19, 24, 27], "modelfactori": 21, "har": 29, "robustnesstestrunn": 31, "accuracytestfactori": 34, "biastestfactori": 35, "fairnesstestfactori": 36, "itest": 37, "representationtestfactori": 38, "robustnesstestfactori": 39, "testfactori": 40, "baseaccuraci": 42, "minf1scor": 43, "minmacrof1scor": 44, "minmicrof1scor": 45, "minprecisionscor": 46, "minrecallscor": 47, "minweightedf1scor": 48, "basebia": 50, "countryeconomicbia": 51, "ethnicitynamebia": 52, "genderpronounbia": [53, 67], "religionbia": 54, "basefair": 56, "maxgenderf1scor": 57, "mingenderf1scor": 58, "get_gendered_data": 59, "addcontext": [61, 84], "addcontract": [62, 85], "addpunctu": [63, 86], "addtypo": [64, 87], "baseperturb": 65, "convertacc": [66, 89], "lowercas": [68, 90], "perturbationfactori": 69, "strippunctu": [70, 91], "swapcohyponym": [71, 92], "swapent": [72, 93], "titlecas": [73, 94], "uppercas": [74, 95], "get_cohyponyms_wordnet": [75, 96], "baserepresent": 77, "countryeconomicrepresent": 78, "ethnicityrepresent": 79, "genderrepresent": 80, "labelrepresent": 81, "religionrepresent": 82, "baserobust": 88, "check_nam": 98, "create_terminologi": 99, "get_country_economic_representation_dict": 100, "get_entity_representation_proport": 101, "get_ethnicity_representation_dict": 102, "get_label_representation_dict": 103, "get_religion_name_representation_dict": 104, "get_substitution_nam": 105, "accuracyoutput": 108, "maxscoreoutput": 109, "minscoreoutput": 110, "neroutput": 111, "nerpredict": 112, "sampl": 113, "sequenceclassificationoutput": 114, "sequencelabel": 115, "span": 116, "genderclassifi": 119, "try_import_lib": 121}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"nlptest": [[0, "module-nlptest"]], "nlptest.augmentation": [[1, "module-nlptest.augmentation"]], "nlptest.augmentation.fix_robustness": [[2, "module-nlptest.augmentation.fix_robustness"]], "nlptest.augmentation.fix_robustness.AugmentRobustness": [[3, "nlptest-augmentation-fix-robustness-augmentrobustness"]], "nlptest.augmentation.fix_robustness.BaseAugmentaion": [[4, "nlptest-augmentation-fix-robustness-baseaugmentaion"]], "nlptest.datahandler": [[5, "module-nlptest.datahandler"]], "nlptest.datahandler.datasource": [[6, "module-nlptest.datahandler.datasource"]], "nlptest.datahandler.datasource.CSVDataset": [[7, "nlptest-datahandler-datasource-csvdataset"]], "nlptest.datahandler.datasource.ConllDataset": [[8, "nlptest-datahandler-datasource-conlldataset"]], "nlptest.datahandler.datasource.DataFactory": [[9, "nlptest-datahandler-datasource-datafactory"]], "nlptest.datahandler.datasource.JSONDataset": [[10, "nlptest-datahandler-datasource-jsondataset"]], "nlptest.datahandler.format": [[11, "module-nlptest.datahandler.format"]], "nlptest.datahandler.format.BaseFormatter": [[12, "nlptest-datahandler-format-baseformatter"]], "nlptest.datahandler.format.Formatter": [[13, "nlptest-datahandler-format-formatter"]], "nlptest.datahandler.format.NEROutputFormatter": [[14, "nlptest-datahandler-format-neroutputformatter"]], "nlptest.datahandler.format.SequenceClassificationOutputFormatter": [[15, "nlptest-datahandler-format-sequenceclassificationoutputformatter"]], "nlptest.modelhandler": [[16, "module-nlptest.modelhandler"]], "nlptest.modelhandler.jsl_modelhandler": [[17, "module-nlptest.modelhandler.jsl_modelhandler"]], "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForNER": [[18, "nlptest-modelhandler-jsl-modelhandler-pretrainedmodelforner"]], "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification": [[19, "nlptest-modelhandler-jsl-modelhandler-pretrainedmodelfortextclassification"]], "nlptest.modelhandler.modelhandler": [[20, "module-nlptest.modelhandler.modelhandler"]], "nlptest.modelhandler.modelhandler.ModelFactory": [[21, "nlptest-modelhandler-modelhandler-modelfactory"]], "nlptest.modelhandler.spacy_modelhandler": [[22, "module-nlptest.modelhandler.spacy_modelhandler"]], "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForNER": [[23, "nlptest-modelhandler-spacy-modelhandler-pretrainedmodelforner"]], "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification": [[24, "nlptest-modelhandler-spacy-modelhandler-pretrainedmodelfortextclassification"]], "nlptest.modelhandler.transformers_modelhandler": [[25, "module-nlptest.modelhandler.transformers_modelhandler"]], "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForNER": [[26, "nlptest-modelhandler-transformers-modelhandler-pretrainedmodelforner"]], "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification": [[27, "nlptest-modelhandler-transformers-modelhandler-pretrainedmodelfortextclassification"]], "nlptest.nlptest": [[28, "module-nlptest.nlptest"]], "nlptest.nlptest.Harness": [[29, "nlptest-nlptest-harness"]], "nlptest.testrunner": [[30, "module-nlptest.testrunner"]], "nlptest.testrunner.RobustnessTestRunner": [[31, "nlptest-testrunner-robustnesstestrunner"]], "nlptest.testrunner.TestRunner": [[32, "nlptest-testrunner-testrunner"]], "nlptest.transform": [[33, "module-nlptest.transform"]], "nlptest.transform.AccuracyTestFactory": [[34, "nlptest-transform-accuracytestfactory"]], "nlptest.transform.BiasTestFactory": [[35, "nlptest-transform-biastestfactory"]], "nlptest.transform.FairnessTestFactory": [[36, "nlptest-transform-fairnesstestfactory"]], "nlptest.transform.ITests": [[37, "nlptest-transform-itests"]], "nlptest.transform.RepresentationTestFactory": [[38, "nlptest-transform-representationtestfactory"]], "nlptest.transform.RobustnessTestFactory": [[39, "nlptest-transform-robustnesstestfactory"]], "nlptest.transform.TestFactory": [[40, "nlptest-transform-testfactory"]], "nlptest.transform.accuracy": [[41, "module-nlptest.transform.accuracy"]], "nlptest.transform.accuracy.BaseAccuracy": [[42, "nlptest-transform-accuracy-baseaccuracy"]], "nlptest.transform.accuracy.MinF1Score": [[43, "nlptest-transform-accuracy-minf1score"]], "nlptest.transform.accuracy.MinMacroF1Score": [[44, "nlptest-transform-accuracy-minmacrof1score"]], "nlptest.transform.accuracy.MinMicroF1Score": [[45, "nlptest-transform-accuracy-minmicrof1score"]], "nlptest.transform.accuracy.MinPrecisionScore": [[46, "nlptest-transform-accuracy-minprecisionscore"]], "nlptest.transform.accuracy.MinRecallScore": [[47, "nlptest-transform-accuracy-minrecallscore"]], "nlptest.transform.accuracy.MinWeightedF1Score": [[48, "nlptest-transform-accuracy-minweightedf1score"]], "nlptest.transform.bias": [[49, "module-nlptest.transform.bias"]], "nlptest.transform.bias.BaseBias": [[50, "nlptest-transform-bias-basebias"]], "nlptest.transform.bias.CountryEconomicBias": [[51, "nlptest-transform-bias-countryeconomicbias"]], "nlptest.transform.bias.EthnicityNameBias": [[52, "nlptest-transform-bias-ethnicitynamebias"]], "nlptest.transform.bias.GenderPronounBias": [[53, "nlptest-transform-bias-genderpronounbias"]], "nlptest.transform.bias.ReligionBias": [[54, "nlptest-transform-bias-religionbias"]], "nlptest.transform.fairness": [[55, "module-nlptest.transform.fairness"]], "nlptest.transform.fairness.BaseFairness": [[56, "nlptest-transform-fairness-basefairness"]], "nlptest.transform.fairness.MaxGenderF1Score": [[57, "nlptest-transform-fairness-maxgenderf1score"]], "nlptest.transform.fairness.MinGenderF1Score": [[58, "nlptest-transform-fairness-mingenderf1score"]], "nlptest.transform.fairness.get_gendered_data": [[59, "nlptest-transform-fairness-get-gendered-data"]], "nlptest.transform.perturbation": [[60, "module-nlptest.transform.perturbation"]], "nlptest.transform.perturbation.AddContext": [[61, "nlptest-transform-perturbation-addcontext"]], "nlptest.transform.perturbation.AddContraction": [[62, "nlptest-transform-perturbation-addcontraction"]], "nlptest.transform.perturbation.AddPunctuation": [[63, "nlptest-transform-perturbation-addpunctuation"]], "nlptest.transform.perturbation.AddTypo": [[64, "nlptest-transform-perturbation-addtypo"]], "nlptest.transform.perturbation.BasePerturbation": [[65, "nlptest-transform-perturbation-baseperturbation"]], "nlptest.transform.perturbation.ConvertAccent": [[66, "nlptest-transform-perturbation-convertaccent"]], "nlptest.transform.perturbation.GenderPronounBias": [[67, "nlptest-transform-perturbation-genderpronounbias"]], "nlptest.transform.perturbation.LowerCase": [[68, "nlptest-transform-perturbation-lowercase"]], "nlptest.transform.perturbation.PerturbationFactory": [[69, "nlptest-transform-perturbation-perturbationfactory"]], "nlptest.transform.perturbation.StripPunctuation": [[70, "nlptest-transform-perturbation-strippunctuation"]], "nlptest.transform.perturbation.SwapCohyponyms": [[71, "nlptest-transform-perturbation-swapcohyponyms"]], "nlptest.transform.perturbation.SwapEntities": [[72, "nlptest-transform-perturbation-swapentities"]], "nlptest.transform.perturbation.TitleCase": [[73, "nlptest-transform-perturbation-titlecase"]], "nlptest.transform.perturbation.UpperCase": [[74, "nlptest-transform-perturbation-uppercase"]], "nlptest.transform.perturbation.get_cohyponyms_wordnet": [[75, "nlptest-transform-perturbation-get-cohyponyms-wordnet"]], "nlptest.transform.representation": [[76, "module-nlptest.transform.representation"]], "nlptest.transform.representation.BaseRepresentation": [[77, "nlptest-transform-representation-baserepresentation"]], "nlptest.transform.representation.CountryEconomicRepresentation": [[78, "nlptest-transform-representation-countryeconomicrepresentation"]], "nlptest.transform.representation.EthnicityRepresentation": [[79, "nlptest-transform-representation-ethnicityrepresentation"]], "nlptest.transform.representation.GenderRepresentation": [[80, "nlptest-transform-representation-genderrepresentation"]], "nlptest.transform.representation.LabelRepresentation": [[81, "nlptest-transform-representation-labelrepresentation"]], "nlptest.transform.representation.ReligionRepresentation": [[82, "nlptest-transform-representation-religionrepresentation"]], "nlptest.transform.robustness": [[83, "module-nlptest.transform.robustness"]], "nlptest.transform.robustness.AddContext": [[84, "nlptest-transform-robustness-addcontext"]], "nlptest.transform.robustness.AddContraction": [[85, "nlptest-transform-robustness-addcontraction"]], "nlptest.transform.robustness.AddPunctuation": [[86, "nlptest-transform-robustness-addpunctuation"]], "nlptest.transform.robustness.AddTypo": [[87, "nlptest-transform-robustness-addtypo"]], "nlptest.transform.robustness.BaseRobustness": [[88, "nlptest-transform-robustness-baserobustness"]], "nlptest.transform.robustness.ConvertAccent": [[89, "nlptest-transform-robustness-convertaccent"]], "nlptest.transform.robustness.LowerCase": [[90, "nlptest-transform-robustness-lowercase"]], "nlptest.transform.robustness.StripPunctuation": [[91, "nlptest-transform-robustness-strippunctuation"]], "nlptest.transform.robustness.SwapCohyponyms": [[92, "nlptest-transform-robustness-swapcohyponyms"]], "nlptest.transform.robustness.SwapEntities": [[93, "nlptest-transform-robustness-swapentities"]], "nlptest.transform.robustness.TitleCase": [[94, "nlptest-transform-robustness-titlecase"]], "nlptest.transform.robustness.UpperCase": [[95, "nlptest-transform-robustness-uppercase"]], "nlptest.transform.robustness.get_cohyponyms_wordnet": [[96, "nlptest-transform-robustness-get-cohyponyms-wordnet"]], "nlptest.transform.utils": [[97, "module-nlptest.transform.utils"]], "nlptest.transform.utils.check_name": [[98, "nlptest-transform-utils-check-name"]], "nlptest.transform.utils.create_terminology": [[99, "nlptest-transform-utils-create-terminology"]], "nlptest.transform.utils.get_country_economic_representation_dict": [[100, "nlptest-transform-utils-get-country-economic-representation-dict"]], "nlptest.transform.utils.get_entity_representation_proportions": [[101, "nlptest-transform-utils-get-entity-representation-proportions"]], "nlptest.transform.utils.get_ethnicity_representation_dict": [[102, "nlptest-transform-utils-get-ethnicity-representation-dict"]], "nlptest.transform.utils.get_label_representation_dict": [[103, "nlptest-transform-utils-get-label-representation-dict"]], "nlptest.transform.utils.get_religion_name_representation_dict": [[104, "nlptest-transform-utils-get-religion-name-representation-dict"]], "nlptest.transform.utils.get_substitution_names": [[105, "nlptest-transform-utils-get-substitution-names"]], "nlptest.utils": [[106, "module-nlptest.utils"]], "nlptest.utils.custom_types": [[107, "module-nlptest.utils.custom_types"]], "nlptest.utils.custom_types.AccuracyOutput": [[108, "nlptest-utils-custom-types-accuracyoutput"]], "nlptest.utils.custom_types.MaxScoreOutput": [[109, "nlptest-utils-custom-types-maxscoreoutput"]], "nlptest.utils.custom_types.MinScoreOutput": [[110, "nlptest-utils-custom-types-minscoreoutput"]], "nlptest.utils.custom_types.NEROutput": [[111, "nlptest-utils-custom-types-neroutput"]], "nlptest.utils.custom_types.NERPrediction": [[112, "nlptest-utils-custom-types-nerprediction"]], "nlptest.utils.custom_types.Sample": [[113, "nlptest-utils-custom-types-sample"]], "nlptest.utils.custom_types.SequenceClassificationOutput": [[114, "nlptest-utils-custom-types-sequenceclassificationoutput"]], "nlptest.utils.custom_types.SequenceLabel": [[115, "nlptest-utils-custom-types-sequencelabel"]], "nlptest.utils.custom_types.Span": [[116, "nlptest-utils-custom-types-span"]], "nlptest.utils.custom_types.Transformation": [[117, "nlptest-utils-custom-types-transformation"]], "nlptest.utils.gender_classifier": [[118, "module-nlptest.utils.gender_classifier"]], "nlptest.utils.gender_classifier.GenderClassifier": [[119, "nlptest-utils-gender-classifier-genderclassifier"]], "nlptest.utils.lib_manager": [[120, "module-nlptest.utils.lib_manager"]], "nlptest.utils.lib_manager.try_import_lib": [[121, "nlptest-utils-lib-manager-try-import-lib"]], "Quick Start": [[122, "quick-start"], [123, "quick-start"]], "NLP Test Quick Start": [[122, "nlp-test-quick-start"]], "Installation": [[122, "installation"]], "User Guide": [[124, "user-guide"], [123, "user-guide"]], "Welcome to the docs page for NLP Test!": [[123, "welcome-to-the-docs-page-for-nlp-test"]], "API": [[123, "api"]]}, "indexentries": {}})