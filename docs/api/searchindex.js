Search.setIndex({"docnames": ["autosummary/nlptest", "autosummary/nlptest.augmentation", "autosummary/nlptest.augmentation.AugmentRobustness", "autosummary/nlptest.augmentation.BaseAugmentaion", "autosummary/nlptest.datahandler", "autosummary/nlptest.datahandler.datasource", "autosummary/nlptest.datahandler.datasource.CSVDataset", "autosummary/nlptest.datahandler.datasource.ConllDataset", "autosummary/nlptest.datahandler.datasource.DataFactory", "autosummary/nlptest.datahandler.datasource.JSONDataset", "autosummary/nlptest.datahandler.format", "autosummary/nlptest.datahandler.format.BaseFormatter", "autosummary/nlptest.datahandler.format.Formatter", "autosummary/nlptest.datahandler.format.NEROutputFormatter", "autosummary/nlptest.datahandler.format.SequenceClassificationOutputFormatter", "autosummary/nlptest.modelhandler", "autosummary/nlptest.modelhandler.jsl_modelhandler", "autosummary/nlptest.modelhandler.jsl_modelhandler.PretrainedModelForNER", "autosummary/nlptest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification", "autosummary/nlptest.modelhandler.modelhandler", "autosummary/nlptest.modelhandler.modelhandler.ModelFactory", "autosummary/nlptest.modelhandler.spacy_modelhandler", "autosummary/nlptest.modelhandler.spacy_modelhandler.PretrainedModelForNER", "autosummary/nlptest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification", "autosummary/nlptest.modelhandler.transformers_modelhandler", "autosummary/nlptest.modelhandler.transformers_modelhandler.PretrainedModelForNER", "autosummary/nlptest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification", "autosummary/nlptest.nlptest", "autosummary/nlptest.nlptest.Harness", "autosummary/nlptest.testrunner", "autosummary/nlptest.testrunner.BaseRunner", "autosummary/nlptest.testrunner.TestRunner", "autosummary/nlptest.transform", "autosummary/nlptest.transform.AccuracyTestFactory", "autosummary/nlptest.transform.BiasTestFactory", "autosummary/nlptest.transform.FairnessTestFactory", "autosummary/nlptest.transform.ITests", "autosummary/nlptest.transform.RepresentationTestFactory", "autosummary/nlptest.transform.RobustnessTestFactory", "autosummary/nlptest.transform.TestFactory", "autosummary/nlptest.transform.accuracy", "autosummary/nlptest.transform.accuracy.BaseAccuracy", "autosummary/nlptest.transform.accuracy.MinF1Score", "autosummary/nlptest.transform.accuracy.MinMacroF1Score", "autosummary/nlptest.transform.accuracy.MinMicroF1Score", "autosummary/nlptest.transform.accuracy.MinPrecisionScore", "autosummary/nlptest.transform.accuracy.MinRecallScore", "autosummary/nlptest.transform.accuracy.MinWeightedF1Score", "autosummary/nlptest.transform.bias", "autosummary/nlptest.transform.bias.BaseBias", "autosummary/nlptest.transform.bias.CountryEconomicBias", "autosummary/nlptest.transform.bias.EthnicityNameBias", "autosummary/nlptest.transform.bias.GenderPronounBias", "autosummary/nlptest.transform.bias.ReligionBias", "autosummary/nlptest.transform.fairness", "autosummary/nlptest.transform.fairness.BaseFairness", "autosummary/nlptest.transform.fairness.MaxGenderF1Score", "autosummary/nlptest.transform.fairness.MinGenderF1Score", "autosummary/nlptest.transform.fairness.get_gendered_data", "autosummary/nlptest.transform.representation", "autosummary/nlptest.transform.representation.BaseRepresentation", "autosummary/nlptest.transform.representation.CountryEconomicRepresentation", "autosummary/nlptest.transform.representation.EthnicityRepresentation", "autosummary/nlptest.transform.representation.GenderRepresentation", "autosummary/nlptest.transform.representation.LabelRepresentation", "autosummary/nlptest.transform.representation.ReligionRepresentation", "autosummary/nlptest.transform.robustness", "autosummary/nlptest.transform.robustness.AddContext", "autosummary/nlptest.transform.robustness.AddContraction", "autosummary/nlptest.transform.robustness.AddPunctuation", "autosummary/nlptest.transform.robustness.AddTypo", "autosummary/nlptest.transform.robustness.BaseRobustness", "autosummary/nlptest.transform.robustness.ConvertAccent", "autosummary/nlptest.transform.robustness.LowerCase", "autosummary/nlptest.transform.robustness.StripPunctuation", "autosummary/nlptest.transform.robustness.SwapEntities", "autosummary/nlptest.transform.robustness.TitleCase", "autosummary/nlptest.transform.robustness.UpperCase", "autosummary/nlptest.transform.utils", "autosummary/nlptest.transform.utils.check_name", "autosummary/nlptest.transform.utils.create_terminology", "autosummary/nlptest.transform.utils.get_country_economic_representation_dict", "autosummary/nlptest.transform.utils.get_entity_representation_proportions", "autosummary/nlptest.transform.utils.get_ethnicity_representation_dict", "autosummary/nlptest.transform.utils.get_label_representation_dict", "autosummary/nlptest.transform.utils.get_religion_name_representation_dict", "autosummary/nlptest.transform.utils.get_substitution_names", "autosummary/nlptest.utils", "autosummary/nlptest.utils.custom_types", "autosummary/nlptest.utils.custom_types.helpers", "autosummary/nlptest.utils.custom_types.helpers.Span", "autosummary/nlptest.utils.custom_types.helpers.Transformation", "autosummary/nlptest.utils.custom_types.output", "autosummary/nlptest.utils.custom_types.output.MaxScoreOutput", "autosummary/nlptest.utils.custom_types.output.MinScoreOutput", "autosummary/nlptest.utils.custom_types.output.NEROutput", "autosummary/nlptest.utils.custom_types.output.SequenceClassificationOutput", "autosummary/nlptest.utils.custom_types.predictions", "autosummary/nlptest.utils.custom_types.predictions.NERPrediction", "autosummary/nlptest.utils.custom_types.predictions.SequenceLabel", "autosummary/nlptest.utils.custom_types.sample", "autosummary/nlptest.utils.custom_types.sample.BaseSample", "autosummary/nlptest.utils.custom_types.sample.MaxScoreSample", "autosummary/nlptest.utils.custom_types.sample.MinScoreSample", "autosummary/nlptest.utils.custom_types.sample.NERSample", "autosummary/nlptest.utils.custom_types.sample.SequenceClassificationSample", "autosummary/nlptest.utils.gender_classifier", "autosummary/nlptest.utils.gender_classifier.GenderClassifier", "autosummary/nlptest.utils.lib_manager", "autosummary/nlptest.utils.lib_manager.try_import_lib", "api", "index", "quick_start"], "filenames": ["autosummary/nlptest.rst", "autosummary/nlptest.augmentation.rst", "autosummary/nlptest.augmentation.AugmentRobustness.rst", "autosummary/nlptest.augmentation.BaseAugmentaion.rst", "autosummary/nlptest.datahandler.rst", "autosummary/nlptest.datahandler.datasource.rst", "autosummary/nlptest.datahandler.datasource.CSVDataset.rst", "autosummary/nlptest.datahandler.datasource.ConllDataset.rst", "autosummary/nlptest.datahandler.datasource.DataFactory.rst", "autosummary/nlptest.datahandler.datasource.JSONDataset.rst", "autosummary/nlptest.datahandler.format.rst", "autosummary/nlptest.datahandler.format.BaseFormatter.rst", "autosummary/nlptest.datahandler.format.Formatter.rst", "autosummary/nlptest.datahandler.format.NEROutputFormatter.rst", "autosummary/nlptest.datahandler.format.SequenceClassificationOutputFormatter.rst", "autosummary/nlptest.modelhandler.rst", "autosummary/nlptest.modelhandler.jsl_modelhandler.rst", "autosummary/nlptest.modelhandler.jsl_modelhandler.PretrainedModelForNER.rst", "autosummary/nlptest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification.rst", "autosummary/nlptest.modelhandler.modelhandler.rst", "autosummary/nlptest.modelhandler.modelhandler.ModelFactory.rst", "autosummary/nlptest.modelhandler.spacy_modelhandler.rst", "autosummary/nlptest.modelhandler.spacy_modelhandler.PretrainedModelForNER.rst", "autosummary/nlptest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification.rst", "autosummary/nlptest.modelhandler.transformers_modelhandler.rst", "autosummary/nlptest.modelhandler.transformers_modelhandler.PretrainedModelForNER.rst", "autosummary/nlptest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification.rst", "autosummary/nlptest.nlptest.rst", "autosummary/nlptest.nlptest.Harness.rst", "autosummary/nlptest.testrunner.rst", "autosummary/nlptest.testrunner.BaseRunner.rst", "autosummary/nlptest.testrunner.TestRunner.rst", "autosummary/nlptest.transform.rst", "autosummary/nlptest.transform.AccuracyTestFactory.rst", "autosummary/nlptest.transform.BiasTestFactory.rst", "autosummary/nlptest.transform.FairnessTestFactory.rst", "autosummary/nlptest.transform.ITests.rst", "autosummary/nlptest.transform.RepresentationTestFactory.rst", "autosummary/nlptest.transform.RobustnessTestFactory.rst", "autosummary/nlptest.transform.TestFactory.rst", "autosummary/nlptest.transform.accuracy.rst", "autosummary/nlptest.transform.accuracy.BaseAccuracy.rst", "autosummary/nlptest.transform.accuracy.MinF1Score.rst", "autosummary/nlptest.transform.accuracy.MinMacroF1Score.rst", "autosummary/nlptest.transform.accuracy.MinMicroF1Score.rst", "autosummary/nlptest.transform.accuracy.MinPrecisionScore.rst", "autosummary/nlptest.transform.accuracy.MinRecallScore.rst", "autosummary/nlptest.transform.accuracy.MinWeightedF1Score.rst", "autosummary/nlptest.transform.bias.rst", "autosummary/nlptest.transform.bias.BaseBias.rst", "autosummary/nlptest.transform.bias.CountryEconomicBias.rst", "autosummary/nlptest.transform.bias.EthnicityNameBias.rst", "autosummary/nlptest.transform.bias.GenderPronounBias.rst", "autosummary/nlptest.transform.bias.ReligionBias.rst", "autosummary/nlptest.transform.fairness.rst", "autosummary/nlptest.transform.fairness.BaseFairness.rst", "autosummary/nlptest.transform.fairness.MaxGenderF1Score.rst", "autosummary/nlptest.transform.fairness.MinGenderF1Score.rst", "autosummary/nlptest.transform.fairness.get_gendered_data.rst", "autosummary/nlptest.transform.representation.rst", "autosummary/nlptest.transform.representation.BaseRepresentation.rst", "autosummary/nlptest.transform.representation.CountryEconomicRepresentation.rst", "autosummary/nlptest.transform.representation.EthnicityRepresentation.rst", "autosummary/nlptest.transform.representation.GenderRepresentation.rst", "autosummary/nlptest.transform.representation.LabelRepresentation.rst", "autosummary/nlptest.transform.representation.ReligionRepresentation.rst", "autosummary/nlptest.transform.robustness.rst", "autosummary/nlptest.transform.robustness.AddContext.rst", "autosummary/nlptest.transform.robustness.AddContraction.rst", "autosummary/nlptest.transform.robustness.AddPunctuation.rst", "autosummary/nlptest.transform.robustness.AddTypo.rst", "autosummary/nlptest.transform.robustness.BaseRobustness.rst", "autosummary/nlptest.transform.robustness.ConvertAccent.rst", "autosummary/nlptest.transform.robustness.LowerCase.rst", "autosummary/nlptest.transform.robustness.StripPunctuation.rst", "autosummary/nlptest.transform.robustness.SwapEntities.rst", "autosummary/nlptest.transform.robustness.TitleCase.rst", "autosummary/nlptest.transform.robustness.UpperCase.rst", "autosummary/nlptest.transform.utils.rst", "autosummary/nlptest.transform.utils.check_name.rst", "autosummary/nlptest.transform.utils.create_terminology.rst", "autosummary/nlptest.transform.utils.get_country_economic_representation_dict.rst", "autosummary/nlptest.transform.utils.get_entity_representation_proportions.rst", "autosummary/nlptest.transform.utils.get_ethnicity_representation_dict.rst", "autosummary/nlptest.transform.utils.get_label_representation_dict.rst", "autosummary/nlptest.transform.utils.get_religion_name_representation_dict.rst", "autosummary/nlptest.transform.utils.get_substitution_names.rst", "autosummary/nlptest.utils.rst", "autosummary/nlptest.utils.custom_types.rst", "autosummary/nlptest.utils.custom_types.helpers.rst", "autosummary/nlptest.utils.custom_types.helpers.Span.rst", "autosummary/nlptest.utils.custom_types.helpers.Transformation.rst", "autosummary/nlptest.utils.custom_types.output.rst", "autosummary/nlptest.utils.custom_types.output.MaxScoreOutput.rst", "autosummary/nlptest.utils.custom_types.output.MinScoreOutput.rst", "autosummary/nlptest.utils.custom_types.output.NEROutput.rst", "autosummary/nlptest.utils.custom_types.output.SequenceClassificationOutput.rst", "autosummary/nlptest.utils.custom_types.predictions.rst", "autosummary/nlptest.utils.custom_types.predictions.NERPrediction.rst", "autosummary/nlptest.utils.custom_types.predictions.SequenceLabel.rst", "autosummary/nlptest.utils.custom_types.sample.rst", "autosummary/nlptest.utils.custom_types.sample.BaseSample.rst", "autosummary/nlptest.utils.custom_types.sample.MaxScoreSample.rst", "autosummary/nlptest.utils.custom_types.sample.MinScoreSample.rst", "autosummary/nlptest.utils.custom_types.sample.NERSample.rst", "autosummary/nlptest.utils.custom_types.sample.SequenceClassificationSample.rst", "autosummary/nlptest.utils.gender_classifier.rst", "autosummary/nlptest.utils.gender_classifier.GenderClassifier.rst", "autosummary/nlptest.utils.lib_manager.rst", "autosummary/nlptest.utils.lib_manager.try_import_lib.rst", "api.rst", "index.rst", "quick_start.rst"], "titles": ["nlptest", "nlptest.augmentation", "nlptest.augmentation.AugmentRobustness", "nlptest.augmentation.BaseAugmentaion", "nlptest.datahandler", "nlptest.datahandler.datasource", "nlptest.datahandler.datasource.CSVDataset", "nlptest.datahandler.datasource.ConllDataset", "nlptest.datahandler.datasource.DataFactory", "nlptest.datahandler.datasource.JSONDataset", "nlptest.datahandler.format", "nlptest.datahandler.format.BaseFormatter", "nlptest.datahandler.format.Formatter", "nlptest.datahandler.format.NEROutputFormatter", "nlptest.datahandler.format.SequenceClassificationOutputFormatter", "nlptest.modelhandler", "nlptest.modelhandler.jsl_modelhandler", "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForNER", "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification", "nlptest.modelhandler.modelhandler", "nlptest.modelhandler.modelhandler.ModelFactory", "nlptest.modelhandler.spacy_modelhandler", "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForNER", "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification", "nlptest.modelhandler.transformers_modelhandler", "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForNER", "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification", "nlptest.nlptest", "nlptest.nlptest.Harness", "nlptest.testrunner", "nlptest.testrunner.BaseRunner", "nlptest.testrunner.TestRunner", "nlptest.transform", "nlptest.transform.AccuracyTestFactory", "nlptest.transform.BiasTestFactory", "nlptest.transform.FairnessTestFactory", "nlptest.transform.ITests", "nlptest.transform.RepresentationTestFactory", "nlptest.transform.RobustnessTestFactory", "nlptest.transform.TestFactory", "nlptest.transform.accuracy", "nlptest.transform.accuracy.BaseAccuracy", "nlptest.transform.accuracy.MinF1Score", "nlptest.transform.accuracy.MinMacroF1Score", "nlptest.transform.accuracy.MinMicroF1Score", "nlptest.transform.accuracy.MinPrecisionScore", "nlptest.transform.accuracy.MinRecallScore", "nlptest.transform.accuracy.MinWeightedF1Score", "nlptest.transform.bias", "nlptest.transform.bias.BaseBias", "nlptest.transform.bias.CountryEconomicBias", "nlptest.transform.bias.EthnicityNameBias", "nlptest.transform.bias.GenderPronounBias", "nlptest.transform.bias.ReligionBias", "nlptest.transform.fairness", "nlptest.transform.fairness.BaseFairness", "nlptest.transform.fairness.MaxGenderF1Score", "nlptest.transform.fairness.MinGenderF1Score", "nlptest.transform.fairness.get_gendered_data", "nlptest.transform.representation", "nlptest.transform.representation.BaseRepresentation", "nlptest.transform.representation.CountryEconomicRepresentation", "nlptest.transform.representation.EthnicityRepresentation", "nlptest.transform.representation.GenderRepresentation", "nlptest.transform.representation.LabelRepresentation", "nlptest.transform.representation.ReligionRepresentation", "nlptest.transform.robustness", "nlptest.transform.robustness.AddContext", "nlptest.transform.robustness.AddContraction", "nlptest.transform.robustness.AddPunctuation", "nlptest.transform.robustness.AddTypo", "nlptest.transform.robustness.BaseRobustness", "nlptest.transform.robustness.ConvertAccent", "nlptest.transform.robustness.LowerCase", "nlptest.transform.robustness.StripPunctuation", "nlptest.transform.robustness.SwapEntities", "nlptest.transform.robustness.TitleCase", "nlptest.transform.robustness.UpperCase", "nlptest.transform.utils", "nlptest.transform.utils.check_name", "nlptest.transform.utils.create_terminology", "nlptest.transform.utils.get_country_economic_representation_dict", "nlptest.transform.utils.get_entity_representation_proportions", "nlptest.transform.utils.get_ethnicity_representation_dict", "nlptest.transform.utils.get_label_representation_dict", "nlptest.transform.utils.get_religion_name_representation_dict", "nlptest.transform.utils.get_substitution_names", "nlptest.utils", "nlptest.utils.custom_types", "nlptest.utils.custom_types.helpers", "nlptest.utils.custom_types.helpers.Span", "nlptest.utils.custom_types.helpers.Transformation", "nlptest.utils.custom_types.output", "nlptest.utils.custom_types.output.MaxScoreOutput", "nlptest.utils.custom_types.output.MinScoreOutput", "nlptest.utils.custom_types.output.NEROutput", "nlptest.utils.custom_types.output.SequenceClassificationOutput", "nlptest.utils.custom_types.predictions", "nlptest.utils.custom_types.predictions.NERPrediction", "nlptest.utils.custom_types.predictions.SequenceLabel", "nlptest.utils.custom_types.sample", "nlptest.utils.custom_types.sample.BaseSample", "nlptest.utils.custom_types.sample.MaxScoreSample", "nlptest.utils.custom_types.sample.MinScoreSample", "nlptest.utils.custom_types.sample.NERSample", "nlptest.utils.custom_types.sample.SequenceClassificationSample", "nlptest.utils.gender_classifier", "nlptest.utils.gender_classifier.GenderClassifier", "nlptest.utils.lib_manager", "nlptest.utils.lib_manager.try_import_lib", "&lt;no title&gt;", "NLP Test Documentation", "Quick Start"], "terms": {"1": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112], "0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112], "2": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112], "modul": [0, 4, 15, 32, 87, 88], "class": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107], "task": [2, 6, 7, 8, 20, 28, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 95, 96, 101, 111], "h_report": 2, "config": [2, 28, 42, 43, 44, 45, 46, 47, 61, 62, 63, 64, 65, 67, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "max_prop": 2, "5": 2, "base": [2, 3, 6, 7, 8, 9, 11, 12, 13, 14, 17, 18, 20, 22, 23, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 107, 112], "baseaugmentaion": 2, "A": [2, 13, 17, 20, 22, 25, 28, 33, 34, 35, 36, 37, 38, 39, 41, 49, 55, 60, 71], "perform": [2, 3, 12, 17, 18, 20, 22, 23, 25, 26, 28, 33, 34, 35, 37, 38, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "specifi": [2, 12, 20, 34, 35, 36, 37, 38, 39, 61, 62, 63, 64, 65, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "histor": 2, "result": [2, 12, 28, 31, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 61, 62, 63, 64, 65, 101, 102, 103, 104, 105], "string": [2, 11, 12, 13, 14, 18, 22, 26, 52, 69, 73, 74, 76, 77, 79, 80, 95, 96], "indic": 2, "being": 2, "type": [2, 3, 6, 7, 8, 9, 11, 12, 13, 14, 17, 18, 20, 22, 23, 25, 26, 28, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 81, 82, 83, 84, 85, 86, 95, 96, 101, 102, 103, 104, 105, 107, 111], "str": [2, 6, 7, 8, 9, 12, 13, 14, 17, 18, 20, 22, 23, 25, 26, 28, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 69, 71, 72, 74, 75, 79, 80, 81, 83, 84, 85, 86, 90, 95, 96, 98, 99, 101, 102, 103, 104, 105, 107, 109], "dictionari": [2, 28, 33, 34, 35, 36, 37, 38, 39, 67, 68, 72, 75, 80, 81, 82, 83, 84, 85, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "contain": [2, 13, 14, 28, 30, 31, 81, 82, 83, 84, 85, 111], "configur": [2, 28, 41, 42, 43, 44, 45, 46, 47], "paramet": [2, 11, 12, 13, 14, 17, 18, 20, 22, 23, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 107], "dict": [2, 17, 25, 28, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 72, 75, 80, 81, 82, 83, 84, 85, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "datafram": [2, 28, 30, 80], "report": [2, 28, 112], "panda": [2, 80], "The": [2, 8, 11, 12, 13, 14, 17, 25, 28, 33, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 81, 83, 84, 85, 101, 104, 112], "maximum": [2, 56], "proport": [2, 61, 62, 63, 64, 65, 82], "improv": 2, "can": [2, 112], "suggest": 2, "method": [2, 3, 6, 7, 8, 9, 11, 12, 13, 14, 17, 18, 20, 22, 23, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 107], "default": [2, 28, 38, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "float": [2, 93, 94, 98, 99], "__init__": [2, 3, 6, 7, 8, 9, 11, 12, 13, 14, 17, 18, 20, 22, 23, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 107], "self": [2, 60], "none": [2, 3, 6, 7, 8, 13, 28, 30, 31, 33, 34, 35, 37, 38, 67, 69, 72, 74, 75, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "initi": [2, 6, 7, 8, 9, 20, 28, 30, 31, 38], "an": [2, 28, 36, 41, 49, 50, 51, 52, 53, 55, 56, 57, 60, 71, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "instanc": [2, 8, 17, 18, 28, 38, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "myclass": 2, "fix": [2, 3], "list": [2, 6, 7, 8, 9, 17, 18, 20, 22, 23, 25, 26, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 83, 84, 85, 86, 95, 96, 101, 102, 103, 104, 105], "sampl": [2, 6, 7, 8, 9, 12, 13, 14, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 81, 83, 84, 85], "prop": 2, "calcul": 2, "test": [2, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 56, 60, 61, 62, 63, 64, 65, 81, 83, 84, 85, 93, 94], "given": [2, 20, 28, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 56, 57, 91], "return": [2, 3, 6, 7, 8, 11, 12, 13, 14, 17, 18, 20, 22, 23, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 80, 81, 82, 83, 84, 85, 86, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 107], "input_path": [2, 28], "output_path": [2, 6, 7, 8, 9, 28], "inplac": [2, 28], "bool": [2, 17, 18, 22, 23, 25, 26, 28, 79, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 109], "fals": [2, 18, 23, 26, 28, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "appli": [2, 50, 51, 52, 53, 69, 70, 73, 74, 76, 77, 104], "perturb": [2, 31, 50, 51, 52, 53, 72, 101, 104], "input": [2, 12, 13, 14, 17, 18, 20, 22, 23, 25, 26, 28, 38, 41, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 81, 83, 84, 85, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "data": [2, 3, 6, 7, 8, 9, 28, 30, 31, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 81, 83, 84, 85, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "recommend": 2, "from": [2, 6, 7, 17, 18, 20, 23, 25, 26, 28, 36, 39, 51, 74, 75, 80, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 112], "har": [2, 112], "path": [2, 6, 7, 8, 9, 17, 18, 20, 22, 23, 25, 26, 28], "file": [2, 6, 7, 8, 9, 28], "save": [2, 6, 7, 8, 9, 28], "option": [2, 12, 18, 22, 23, 25, 26, 28, 38, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 111], "If": [2, 12, 20, 28, 61, 62, 63, 64, 65, 104], "true": [2, 41, 42, 43, 44, 45, 46, 47, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "i": [2, 3, 8, 12, 17, 18, 20, 28, 38, 61, 62, 63, 64, 65, 69, 73, 74, 76, 77, 79, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "modifi": [2, 28], "place": 2, "otherwis": 2, "new": [2, 28, 38, 75, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 112], "ar": [2, 28, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "add": [2, 69, 70, 74, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "ani": [2, 28, 41, 42, 43, 44, 45, 46, 47, 49, 55, 57, 60, 71, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "categori": [2, 39, 101, 102, 103, 104, 105], "includ": [2, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "pass": [2, 12, 28, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "rate": 2, "minimum": [2, 42, 43, 44, 45, 46, 47, 57], "follow": [2, 112], "column": [2, 28, 80], "each": [2, 39, 82, 101], "test_typ": [2, 39, 101, 102, 103, 104, 105], "ratio": 2, "divid": 2, "proportion_increas": 2, "how": [2, 91, 112], "much": 2, "should": [2, 3, 11, 14, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 112], "increas": 2, "reach": 2, "abc": [3, 11, 14, 36, 41, 49, 55, 60, 71], "abstract": [3, 11, 14, 30, 36, 41, 49, 50, 51, 52, 53, 55, 60, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "techniqu": 3, "implement": [3, 11, 14, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "child": 3, "thi": [3, 11, 12, 14, 28, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 111], "oper": [3, 101], "rais": [3, 11, 12, 14, 20, 28, 61, 62, 63, 64, 65, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "notimplementederror": [3, 11, 14], "file_path": [6, 7, 8, 9], "_idataset": [6, 7, 9], "handl": [6, 7, 9], "csv": [6, 11, 12, 13, 14], "dataset": [6, 7, 8, 9, 28, 33, 34, 35, 37, 38, 51, 64], "subclass": [6, 7, 9, 11, 12, 14, 31, 42, 43, 44, 45, 46, 47, 56, 57, 61, 62, 63, 64, 65], "object": [6, 7, 8, 9, 12, 13, 14, 20, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 63, 91, 101, 107, 112], "param": [6, 7, 8, 9, 17, 20, 25, 41, 42, 43, 44, 45, 46, 47, 55, 56, 57, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 73, 76, 77], "evalu": [6, 8, 20, 28, 30, 31, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 81, 83, 84, 85], "attribut": [6, 17, 18, 20, 23, 25, 26, 28, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 107], "export_data": [6, 7, 9], "export": [6, 7, 8, 9], "correspond": [6, 7, 8, 9, 33, 34, 35, 37, 38, 39, 75, 80, 101], "format": [6, 7, 8, 9, 28, 80], "load_data": [6, 7], "load": [6, 7, 8, 17, 18, 20, 22, 23, 25, 26, 28], "sentenc": [6, 7, 50, 51, 52, 53, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 104], "rtype": [6, 7], "conll": [7, 11, 12, 13, 14, 28], "nersampl": 7, "factori": [8, 20, 39, 63], "creat": [8, 39, 41, 42, 43, 44, 45, 46, 47, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 80, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 112], "respons": 8, "correct": [8, 101, 102, 103, 104, 105], "extens": 8, "text": [8, 17, 18, 20, 22, 23, 25, 26, 31, 80, 90, 91, 96, 99, 101, 104, 107], "json": [9, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "defin": [11, 12, 36], "formatt": [11, 13, 14], "static": [11, 12, 13, 14, 17, 18, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 60, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "to_csv": [11, 12, 13, 14], "to_conl": [11, 12, 13, 14], "custom_typ": [11, 14], "convert": [11, 12, 13, 14, 67, 68, 72, 80, 95, 96], "custom": [11, 12, 13, 14, 20], "represent": [11, 13, 14, 37, 81, 82, 83, 84, 85, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "between": 12, "differ": [12, 28, 36, 39], "output": [12, 18, 20, 41, 49, 55, 56, 57, 60, 71], "us": [12, 13, 14, 20, 26, 28, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 104, 112], "baseformatt": [12, 13, 14], "convers": [12, 67, 68, 72], "appropri": 12, "select": 12, "expect": 12, "argument": [12, 13, 14, 22, 25, 26, 28, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "process": [12, 67, 68, 72, 75], "output_format": 12, "arg": [12, 17, 18, 22, 23, 26, 39, 49], "kwarg": [12, 17, 18, 20, 22, 23, 25, 26, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "either": [12, 20, 30, 31], "posit": 12, "keyword": [12, 22, 25, 26, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "nameerror": 12, "neroutput": [13, 17, 20, 22, 25, 104], "repres": [13, 14, 30, 31, 33, 34, 35, 36, 37, 38], "temp_id": 13, "int": [13, 81, 83, 84, 85, 90, 98], "tupl": [13, 30, 104], "temporari": 13, "id": 13, "group": [13, 17, 22, 25, 26], "entiti": [13, 17, 22, 25, 26, 75, 80, 82, 98], "document": 13, "delimit": [13, 14], "charact": [13, 14], "along": [13, 28], "sequenceclassificationoutput": [14, 18, 20, 23, 26], "model": [17, 18, 20, 22, 23, 25, 26, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 107, 112], "nlupipelin": [17, 18], "pretrainedpipelin": [17, 18], "lightpipelin": [17, 18], "pipelinemodel": [17, 18], "_modelhandl": [17, 18, 22, 23, 25, 26], "sparknlp": [17, 18, 30, 31], "infer": [17, 18], "group_ent": [17, 22, 25], "find": [17, 25], "togeth": [17, 25], "adjac": [17, 25], "token": [17, 25, 67], "same": [17, 25, 101], "predict": [17, 18, 20, 22, 23, 25, 26, 31, 41, 42, 43, 44, 45, 46, 47, 80, 95, 96, 101, 104, 107], "inspir": [17, 25], "adapt": [17, 25], "huggingfac": [17, 25], "transform": [17, 25, 26, 30, 31, 101, 102, 103, 104, 105, 111, 112], "pipelin": [17, 22, 23, 25, 26], "is_ner_annot": 17, "model_inst": [17, 18], "check": [17, 18, 50, 51, 52, 53, 79], "ner": [17, 18, 22, 25, 26, 95, 104, 112], "support": [17, 18, 20, 101, 111], "classmethod": [17, 18, 20, 22, 23, 25, 26, 28, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "load_model": [17, 18, 20, 22, 23, 25, 26], "pretrain": [17, 18, 22, 23, 25], "local": [17, 18, 20], "nlp": [17, 18, 28], "hub": [17, 18, 20, 28, 112], "name": [17, 22, 25, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 71, 75, 86, 98], "recogn": [17, 22, 25], "predict_raw": [17, 18, 20, 22, 23, 25, 26], "label": [17, 18, 22, 23, 25, 26, 64, 75, 80, 84, 99, 107], "is_classifi": 18, "classifi": [18, 23, 107], "return_all_scor": [18, 23, 26], "score": [18, 23, 42, 43, 44, 45, 46, 47, 56, 57, 98, 99], "all": [18, 23, 28, 31, 33, 34, 35, 37, 38, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 112], "classif": [18, 23, 26, 96, 99], "instanti": 20, "valueerror": [20, 28, 61, 62, 63, 64, 65], "disk": 20, "union": 20, "spaci": [22, 23, 30, 31], "addit": [22, 25, 26, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "form": [22, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "properti": [23, 26, 101, 102, 103, 104, 105], "truncation_strategi": 26, "longest_first": 26, "strategi": [26, 67], "truncat": 26, "too": 26, "long": 26, "sequenc": 26, "gener": [28, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 112], "which": [28, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "modelfactori": [28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "requir": 28, "invalid": 28, "augment": [28, 111], "locat": 28, "whether": [28, 101], "directli": 28, "call": [28, 101], "pass_rat": 28, "minimum_pass_r": 28, "have": [28, 69], "unexpect": 28, "augmentrobust": 28, "exampl": 28, "train": 28, "augmented_train": 28, "testcas": [28, 30, 31], "when": 28, "store": [28, 101], "_testcas": 28, "generated_result": 28, "overal": 28, "everi": 28, "textcas": 28, "labelwis": 28, "metric": 28, "pd": [28, 30], "save_dir": 28, "previous": 28, "folder": 28, "need": [28, 50, 51, 52, 53, 101, 102, 103, 104, 105], "previou": 28, "run": [28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 107, 112], "datafactori": 28, "reus": 28, "later": 28, "after": [28, 33, 34, 35, 37, 38], "load_testcas": [30, 31], "model_handl": [30, 31, 39], "spark": [30, 31], "handler": [30, 31], "baserunn": 31, "robust": [31, 33, 34, 35, 37, 38], "both": [31, 67], "origin": [31, 101, 102, 103, 104, 105], "one": [31, 75, 91, 101, 104], "data_handl": [33, 34, 35, 37, 38], "itest": [33, 34, 35, 37, 38], "accuraci": [33, 55, 93, 94], "available_test": [33, 34, 35, 36, 37, 38], "get": [33, 34, 35, 37, 38, 86, 112], "avail": [33, 34, 35, 36, 37, 38, 39], "kei": [33, 34, 35, 37, 38], "valu": [33, 34, 35, 37, 38, 41, 42, 43, 44, 45, 46, 47, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "sample_list": [33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "raw_data": 33, "raw": 33, "bia": 34, "map": [34, 35, 36, 37, 38, 39], "scenario": [34, 35, 36, 37, 38, 39], "fair": 35, "async": [39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "async_run": [39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "samples_list": 39, "test_categori": 39, "test_scenario": 39, "measur": [41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "alias_nam": [41, 42, 43, 44, 45, 46, 47, 49, 55, 56, 57, 60, 61, 62, 63, 64, 65, 71], "identifi": [41, 49, 55, 56, 57, 60, 61, 62, 63, 64, 65, 71], "minscoresampl": [41, 42, 43, 44, 45, 46, 47, 57], "y_true": [41, 42, 43, 44, 45, 46, 47], "y_pred": [41, 42, 43, 44, 45, 46, 47], "baseaccuraci": [42, 43, 44, 45, 46, 47], "precis": [42, 43, 44, 45, 46], "min_precision_scor": [42, 43, 45, 46], "comput": [42, 43, 44, 45, 46, 47, 55, 56, 57, 60, 61, 62, 63, 64, 65], "f1": [42, 43, 44, 45, 47, 56, 57], "recal": 46, "weight": 47, "creation": [49, 50, 51, 52, 53], "asyncio": [49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "basebia": [50, 51, 52, 53], "country_names_to_substitut": 50, "chosen_country_nam": 50, "replac": [50, 51, 52, 53], "countri": [50, 61, 81], "ethnic": [50, 51, 62, 83], "substitut": [50, 51, 52, 53, 86], "names_to_substitut": [51, 53], "chosen_ethnicity_nam": 51, "curat": 51, "unit": 51, "state": [51, 101, 102, 103, 104, 105], "censu": 51, "bureau": 51, "survei": 51, "pronouns_to_substitut": 52, "pronoun_typ": 52, "pronoun": 52, "gender": [52, 56, 58, 63, 107], "male": 52, "femal": 52, "neutral": 52, "chosen_nam": 53, "religion": [53, 65, 85], "function": [54, 78, 86, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 108], "basefair": [56, 57], "maxscoresampl": 56, "max": 56, "min_f1": 57, "split": 58, "baserepresent": [61, 62, 63, 64, 65], "econom": [61, 81], "actual": [61, 62, 63, 64, 65], "sum": [61, 62, 63, 64, 65], "greater": [61, 62, 63, 64, 65], "than": [61, 62, 63, 64, 65], "enthic": 62, "baserobust": [67, 68, 69, 70, 72, 73, 74, 75, 76, 77], "starting_context": 67, "ending_context": 67, "adjust": 67, "where": 67, "context": 67, "ad": [67, 104], "start": [67, 90, 111], "end": [67, 69, 74, 90], "combin": 67, "term": [67, 72], "beg": 67, "randomli": 67, "whitelist": [69, 74], "punctuat": [69, 74], "skip": [69, 74], "typo": 70, "keyboard": 70, "swap": [70, 75], "introduc": 70, "accent_map": 72, "accent": 72, "isn": 74, "t": [74, 101, 102, 103, 104, 105], "strip": 74, "terminologi": [75, 80], "extract": 75, "make": [75, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "chang": [75, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "accord": [75, 104], "word": [75, 79, 80, 90], "name_list": 79, "look": 79, "potenti": 79, "candid": 79, "ner_data": 80, "iter": 80, "over": [80, 90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 111], "iob": 80, "io": 80, "ha": 80, "inform": [81, 82, 83, 84, 85, 91], "entity_represent": 82, "values_list": 86, "helper": [86, 101, 107], "basemodel": [90, 91, 93, 94, 95, 96, 98, 99, 101], "": 90, "slice": 90, "pars": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "valid": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "validationerror": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "cannot": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "construct": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "_fields_set": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "setstr": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "set": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "__dict__": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "__fields_set__": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "trust": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "pre": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "respect": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "other": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "behav": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "extra": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "allow": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "wa": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "sinc": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "copi": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "abstractsetintstr": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "mappingintstrani": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "exclud": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "updat": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "dictstrani": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "deep": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "duplic": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "choos": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "field": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "take": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "preced": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "note": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "befor": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "you": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 112], "by_alia": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "skip_default": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "exclude_unset": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "exclude_default": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "exclude_non": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "encod": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "callabl": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "models_as_dict": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "dumps_kwarg": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "unicod": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "per": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "suppli": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "dump": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "update_forward_ref": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "localn": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "try": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "forwardref": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "globaln": [90, 91, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105], "original_span": 91, "span": [91, 98, 104], "new_span": 91, "ignor": [91, 101, 102, 103, 104, 105], "keep": 91, "track": 91, "alter": 91, "piec": [91, 107], "It": 91, "hold": 91, "about": 91, "anoth": 91, "max_scor": 93, "min_scor": 94, "nerpredict": [95, 104], "to_str_list": [95, 96], "sequencelabel": 96, "entity_group": 98, "doc_id": 98, "doc_nam": 98, "pos_tag": 98, "chunk_tag": 98, "singl": [98, 99], "obtain": [98, 99], "recognit": 98, "test_cas": [101, 102, 103, 104, 105], "expected_result": [101, 102, 103, 104, 105], "actual_result": [101, 102, 103, 104, 105], "them": 101, "specif": 101, "here": 101, "agnost": 101, "onli": 101, "access": 101, "is_pass": 101, "assess": 101, "regardless": 101, "downstream": 101, "py": 101, "wai": 101, "xxxoutput": 101, "overload": 101, "__eq__": 101, "variabl": 101, "irrelevant_transform": [101, 102, 103, 104, 105], "retriev": [101, 102, 103, 104, 105], "do": [101, 102, 103, 104, 105], "taken": [101, 102, 103, 104, 105], "account": [101, 102, 103, 104, 105], "realign": [101, 102, 103, 104, 105], "relevant_transform": [101, 102, 103, 104, 105], "shouldn": [101, 102, 103, 104, 105], "sort_transform": [101, 102, 103, 104, 105], "v": [101, 102, 103, 104, 105], "ensur": [101, 102, 103, 104, 105], "order": [101, 102, 103, 104, 105], "to_dict": [101, 102, 103, 104, 105], "version": [101, 102, 103, 104, 105], "basesampl": [102, 103, 104, 105], "get_aligned_span_pair": 104, "align": 104, "achiev": 104, "couldn": 104, "ignored_predict": 104, "becaus": 104, "realigned_span": 104, "charg": 104, "shift": 104, "were": 104, "we": [104, 112], "dure": 104, "through": 107, "lib": 109, "page": 111, "technic": 111, "librari": 111, "For": 111, "depth": 111, "explan": 111, "around": 111, "usag": 111, "pleas": 111, "head": 111, "nlptest": [111, 112], "org": 111, "quick": 111, "altern": 111, "instal": 111, "api": 111, "refer": [111, 112], "datahandl": 111, "modelhandl": 111, "testrunn": 111, "util": 111, "up": 112, "pypi": 112, "pip": 112, "import": 112, "h": 112, "dslim": 112, "bert": 112, "your": 112, "case": 112, "python": 112, "virtualenv": 112, "python3": 112, "8": 112, "sourc": 112, "bin": 112, "activ": 112, "jupyt": 112, "now": 112, "readi": 112, "notebook": 112, "also": 112, "conda": 112, "environ": 112, "manag": 112, "depend": 112, "Then": 112, "packag": 112, "n": 112, "3": 112, "y": 112, "c": 112}, "objects": {"": [[0, 0, 0, "-", "nlptest"]], "nlptest": [[1, 0, 0, "-", "augmentation"], [4, 0, 0, "-", "datahandler"], [15, 0, 0, "-", "modelhandler"], [27, 0, 0, "-", "nlptest"], [29, 0, 0, "-", "testrunner"], [32, 0, 0, "-", "transform"], [87, 0, 0, "-", "utils"]], "nlptest.augmentation": [[2, 1, 1, "", "AugmentRobustness"], [3, 1, 1, "", "BaseAugmentaion"]], "nlptest.augmentation.AugmentRobustness": [[2, 2, 1, "id0", "__init__"], [2, 3, 1, "", "config"], [2, 2, 1, "id1", "fix"], [2, 3, 1, "", "h_report"], [2, 3, 1, "", "max_prop"], [2, 2, 1, "id2", "suggestions"], [2, 3, 1, "", "task"]], "nlptest.augmentation.BaseAugmentaion": [[3, 3, 1, "", "None"], [3, 2, 1, "", "__init__"], [3, 2, 1, "id0", "fix"]], "nlptest.datahandler": [[5, 0, 0, "-", "datasource"], [10, 0, 0, "-", "format"]], "nlptest.datahandler.datasource": [[6, 1, 1, "", "CSVDataset"], [7, 1, 1, "", "ConllDataset"], [8, 1, 1, "", "DataFactory"], [9, 1, 1, "", "JSONDataset"]], "nlptest.datahandler.datasource.CSVDataset": [[6, 2, 1, "", "__init__"], [6, 2, 1, "", "export_data"], [6, 2, 1, "", "load_data"]], "nlptest.datahandler.datasource.ConllDataset": [[7, 2, 1, "", "__init__"], [7, 2, 1, "", "export_data"], [7, 2, 1, "", "load_data"]], "nlptest.datahandler.datasource.DataFactory": [[8, 2, 1, "", "__init__"], [8, 2, 1, "", "export"], [8, 2, 1, "", "load"]], "nlptest.datahandler.datasource.JSONDataset": [[9, 2, 1, "", "__init__"], [9, 2, 1, "", "export_data"]], "nlptest.datahandler.format": [[11, 1, 1, "", "BaseFormatter"], [12, 1, 1, "", "Formatter"], [13, 1, 1, "", "NEROutputFormatter"], [14, 1, 1, "", "SequenceClassificationOutputFormatter"]], "nlptest.datahandler.format.BaseFormatter": [[11, 2, 1, "", "__init__"], [11, 2, 1, "", "to_conll"], [11, 2, 1, "", "to_csv"]], "nlptest.datahandler.format.Formatter": [[12, 2, 1, "", "__init__"], [12, 2, 1, "", "process"]], "nlptest.datahandler.format.NEROutputFormatter": [[13, 2, 1, "", "__init__"], [13, 2, 1, "", "to_conll"], [13, 2, 1, "", "to_csv"]], "nlptest.datahandler.format.SequenceClassificationOutputFormatter": [[14, 2, 1, "", "__init__"], [14, 2, 1, "", "to_conll"], [14, 2, 1, "", "to_csv"]], "nlptest.modelhandler": [[16, 0, 0, "-", "jsl_modelhandler"], [19, 0, 0, "-", "modelhandler"], [21, 0, 0, "-", "spacy_modelhandler"], [24, 0, 0, "-", "transformers_modelhandler"]], "nlptest.modelhandler.jsl_modelhandler": [[17, 1, 1, "", "PretrainedModelForNER"], [18, 1, 1, "", "PretrainedModelForTextClassification"]], "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForNER": [[17, 2, 1, "", "__init__"], [17, 2, 1, "", "group_entities"], [17, 2, 1, "", "is_ner_annotator"], [17, 2, 1, "", "load_model"], [17, 3, 1, "id0", "model"], [17, 2, 1, "", "predict"], [17, 2, 1, "", "predict_raw"]], "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification": [[18, 2, 1, "", "__init__"], [18, 2, 1, "", "is_classifier"], [18, 2, 1, "", "load_model"], [18, 3, 1, "id0", "model"], [18, 2, 1, "", "predict"], [18, 2, 1, "", "predict_raw"]], "nlptest.modelhandler.modelhandler": [[20, 1, 1, "", "ModelFactory"]], "nlptest.modelhandler.modelhandler.ModelFactory": [[20, 2, 1, "", "__init__"], [20, 2, 1, "", "load_model"], [20, 2, 1, "", "predict"], [20, 2, 1, "", "predict_raw"]], "nlptest.modelhandler.spacy_modelhandler": [[22, 1, 1, "", "PretrainedModelForNER"], [23, 1, 1, "", "PretrainedModelForTextClassification"]], "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForNER": [[22, 2, 1, "", "__init__"], [22, 2, 1, "", "load_model"], [22, 2, 1, "", "predict"], [22, 2, 1, "", "predict_raw"]], "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification": [[23, 2, 1, "", "__init__"], [23, 4, 1, "", "labels"], [23, 2, 1, "", "load_model"], [23, 2, 1, "", "predict"], [23, 2, 1, "", "predict_raw"]], "nlptest.modelhandler.transformers_modelhandler": [[25, 1, 1, "", "PretrainedModelForNER"], [26, 1, 1, "", "PretrainedModelForTextClassification"], [24, 3, 1, "", "model"]], "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForNER": [[25, 2, 1, "", "__init__"], [25, 2, 1, "", "group_entities"], [25, 2, 1, "", "load_model"], [25, 3, 1, "id0", "model"], [25, 2, 1, "", "predict"], [25, 2, 1, "", "predict_raw"]], "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification": [[26, 2, 1, "", "__init__"], [26, 4, 1, "", "labels"], [26, 2, 1, "", "load_model"], [26, 3, 1, "", "model"], [26, 2, 1, "", "predict"], [26, 2, 1, "", "predict_raw"]], "nlptest.nlptest": [[28, 1, 1, "", "Harness"]], "nlptest.nlptest.Harness": [[28, 2, 1, "", "__init__"], [28, 2, 1, "", "augment"], [28, 2, 1, "", "configure"], [28, 2, 1, "", "generate"], [28, 2, 1, "", "generated_results"], [28, 2, 1, "", "load"], [28, 2, 1, "", "report"], [28, 2, 1, "", "run"], [28, 2, 1, "", "save"], [28, 2, 1, "", "testcases"]], "nlptest.testrunner": [[30, 1, 1, "", "BaseRunner"], [31, 1, 1, "", "TestRunner"]], "nlptest.testrunner.BaseRunner": [[30, 2, 1, "", "__init__"], [30, 2, 1, "", "evaluate"]], "nlptest.testrunner.TestRunner": [[31, 2, 1, "", "__init__"], [31, 2, 1, "", "evaluate"]], "nlptest.transform": [[33, 1, 1, "", "AccuracyTestFactory"], [34, 1, 1, "", "BiasTestFactory"], [35, 1, 1, "", "FairnessTestFactory"], [36, 1, 1, "", "ITests"], [37, 1, 1, "", "RepresentationTestFactory"], [38, 1, 1, "", "RobustnessTestFactory"], [39, 1, 1, "", "TestFactory"], [40, 0, 0, "-", "accuracy"], [48, 0, 0, "-", "bias"], [54, 0, 0, "-", "fairness"], [59, 0, 0, "-", "representation"], [66, 0, 0, "-", "robustness"], [78, 0, 0, "-", "utils"]], "nlptest.transform.AccuracyTestFactory": [[33, 2, 1, "", "__init__"], [33, 2, 1, "", "available_tests"], [33, 2, 1, "", "run"], [33, 2, 1, "", "transform"]], "nlptest.transform.BiasTestFactory": [[34, 2, 1, "", "__init__"], [34, 2, 1, "", "available_tests"], [34, 2, 1, "", "run"], [34, 2, 1, "", "transform"]], "nlptest.transform.FairnessTestFactory": [[35, 2, 1, "", "__init__"], [35, 2, 1, "", "available_tests"], [35, 2, 1, "", "run"], [35, 2, 1, "", "transform"]], "nlptest.transform.ITests": [[36, 2, 1, "", "__init__"], [36, 2, 1, "", "available_tests"], [36, 2, 1, "", "run"], [36, 2, 1, "", "transform"]], "nlptest.transform.RepresentationTestFactory": [[37, 2, 1, "", "__init__"], [37, 2, 1, "", "available_tests"], [37, 2, 1, "", "run"], [37, 2, 1, "", "transform"]], "nlptest.transform.RobustnessTestFactory": [[38, 2, 1, "", "__init__"], [38, 2, 1, "", "available_tests"], [38, 2, 1, "", "run"], [38, 2, 1, "", "transform"]], "nlptest.transform.TestFactory": [[39, 2, 1, "", "__init__"], [39, 2, 1, "", "async_run"], [39, 2, 1, "", "run"], [39, 2, 1, "", "test_categories"], [39, 2, 1, "", "test_scenarios"], [39, 2, 1, "", "transform"]], "nlptest.transform.accuracy": [[41, 1, 1, "", "BaseAccuracy"], [42, 1, 1, "", "MinF1Score"], [43, 1, 1, "", "MinMacroF1Score"], [44, 1, 1, "", "MinMicroF1Score"], [45, 1, 1, "", "MinPrecisionScore"], [46, 1, 1, "", "MinRecallScore"], [47, 1, 1, "", "MinWeightedF1Score"]], "nlptest.transform.accuracy.BaseAccuracy": [[41, 2, 1, "", "__init__"], [41, 3, 1, "", "alias_name"], [41, 2, 1, "", "async_run"], [41, 2, 1, "", "transform"]], "nlptest.transform.accuracy.MinF1Score": [[42, 2, 1, "", "__init__"], [42, 3, 1, "", "alias_name"], [42, 2, 1, "", "async_run"], [42, 2, 1, "", "run"], [42, 2, 1, "id0", "transform"]], "nlptest.transform.accuracy.MinMacroF1Score": [[43, 2, 1, "", "__init__"], [43, 3, 1, "", "alias_name"], [43, 2, 1, "", "async_run"], [43, 2, 1, "", "run"], [43, 2, 1, "id0", "transform"]], "nlptest.transform.accuracy.MinMicroF1Score": [[44, 2, 1, "", "__init__"], [44, 3, 1, "", "alias_name"], [44, 2, 1, "", "async_run"], [44, 2, 1, "", "run"], [44, 2, 1, "id0", "transform"]], "nlptest.transform.accuracy.MinPrecisionScore": [[45, 2, 1, "", "__init__"], [45, 3, 1, "", "alias_name"], [45, 2, 1, "", "async_run"], [45, 2, 1, "", "run"], [45, 2, 1, "id0", "transform"]], "nlptest.transform.accuracy.MinRecallScore": [[46, 2, 1, "", "__init__"], [46, 3, 1, "", "alias_name"], [46, 2, 1, "", "async_run"], [46, 2, 1, "", "run"], [46, 2, 1, "id0", "transform"]], "nlptest.transform.accuracy.MinWeightedF1Score": [[47, 2, 1, "", "__init__"], [47, 3, 1, "", "alias_name"], [47, 2, 1, "", "async_run"], [47, 2, 1, "", "run"], [47, 2, 1, "id0", "transform"]], "nlptest.transform.bias": [[49, 1, 1, "", "BaseBias"], [50, 1, 1, "", "CountryEconomicBias"], [51, 1, 1, "", "EthnicityNameBias"], [52, 1, 1, "", "GenderPronounBias"], [53, 1, 1, "", "ReligionBias"]], "nlptest.transform.bias.BaseBias": [[49, 2, 1, "", "__init__"], [49, 3, 1, "", "alias_name"], [49, 2, 1, "", "async_run"], [49, 2, 1, "", "run"], [49, 2, 1, "", "transform"]], "nlptest.transform.bias.CountryEconomicBias": [[50, 2, 1, "", "__init__"], [50, 2, 1, "", "async_run"], [50, 2, 1, "", "run"], [50, 2, 1, "", "transform"]], "nlptest.transform.bias.EthnicityNameBias": [[51, 2, 1, "", "__init__"], [51, 2, 1, "", "async_run"], [51, 2, 1, "", "run"], [51, 2, 1, "", "transform"]], "nlptest.transform.bias.GenderPronounBias": [[52, 2, 1, "", "__init__"], [52, 2, 1, "", "async_run"], [52, 2, 1, "", "run"], [52, 2, 1, "", "transform"]], "nlptest.transform.bias.ReligionBias": [[53, 2, 1, "", "__init__"], [53, 2, 1, "", "async_run"], [53, 2, 1, "", "run"], [53, 2, 1, "", "transform"]], "nlptest.transform.fairness": [[55, 1, 1, "", "BaseFairness"], [56, 1, 1, "", "MaxGenderF1Score"], [57, 1, 1, "", "MinGenderF1Score"], [58, 5, 1, "", "get_gendered_data"]], "nlptest.transform.fairness.BaseFairness": [[55, 2, 1, "", "__init__"], [55, 3, 1, "", "alias_name"], [55, 2, 1, "", "async_run"], [55, 2, 1, "", "transform"]], "nlptest.transform.fairness.MaxGenderF1Score": [[56, 2, 1, "", "__init__"], [56, 3, 1, "", "alias_name"], [56, 2, 1, "", "async_run"], [56, 2, 1, "", "run"], [56, 2, 1, "", "transform"]], "nlptest.transform.fairness.MinGenderF1Score": [[57, 2, 1, "", "__init__"], [57, 3, 1, "", "alias_name"], [57, 2, 1, "", "async_run"], [57, 2, 1, "", "run"], [57, 2, 1, "", "transform"]], "nlptest.transform.representation": [[60, 1, 1, "", "BaseRepresentation"], [61, 1, 1, "", "CountryEconomicRepresentation"], [62, 1, 1, "", "EthnicityRepresentation"], [63, 1, 1, "", "GenderRepresentation"], [64, 1, 1, "", "LabelRepresentation"], [65, 1, 1, "", "ReligionRepresentation"]], "nlptest.transform.representation.BaseRepresentation": [[60, 2, 1, "", "__init__"], [60, 3, 1, "", "alias_name"], [60, 2, 1, "", "async_run"], [60, 2, 1, "", "transform"]], "nlptest.transform.representation.CountryEconomicRepresentation": [[61, 2, 1, "", "__init__"], [61, 3, 1, "", "alias_name"], [61, 2, 1, "", "async_run"], [61, 2, 1, "", "run"], [61, 2, 1, "", "transform"]], "nlptest.transform.representation.EthnicityRepresentation": [[62, 2, 1, "", "__init__"], [62, 3, 1, "", "alias_name"], [62, 2, 1, "", "async_run"], [62, 2, 1, "", "run"], [62, 2, 1, "", "transform"]], "nlptest.transform.representation.GenderRepresentation": [[63, 2, 1, "", "__init__"], [63, 3, 1, "", "alias_name"], [63, 2, 1, "", "async_run"], [63, 2, 1, "", "run"], [63, 2, 1, "", "transform"]], "nlptest.transform.representation.LabelRepresentation": [[64, 2, 1, "", "__init__"], [64, 3, 1, "", "alias_name"], [64, 2, 1, "", "async_run"], [64, 2, 1, "", "run"], [64, 2, 1, "", "transform"]], "nlptest.transform.representation.ReligionRepresentation": [[65, 2, 1, "", "__init__"], [65, 3, 1, "", "alias_name"], [65, 2, 1, "", "async_run"], [65, 2, 1, "", "run"], [65, 2, 1, "", "transform"]], "nlptest.transform.robustness": [[67, 1, 1, "", "AddContext"], [68, 1, 1, "", "AddContraction"], [69, 1, 1, "", "AddPunctuation"], [70, 1, 1, "", "AddTypo"], [71, 1, 1, "", "BaseRobustness"], [72, 1, 1, "", "ConvertAccent"], [73, 1, 1, "", "LowerCase"], [74, 1, 1, "", "StripPunctuation"], [75, 1, 1, "", "SwapEntities"], [76, 1, 1, "", "TitleCase"], [77, 1, 1, "", "UpperCase"]], "nlptest.transform.robustness.AddContext": [[67, 2, 1, "", "__init__"], [67, 2, 1, "", "async_run"], [67, 2, 1, "", "run"], [67, 2, 1, "", "transform"]], "nlptest.transform.robustness.AddContraction": [[68, 2, 1, "", "__init__"], [68, 2, 1, "", "async_run"], [68, 2, 1, "", "run"], [68, 2, 1, "", "transform"]], "nlptest.transform.robustness.AddPunctuation": [[69, 2, 1, "", "__init__"], [69, 2, 1, "", "async_run"], [69, 2, 1, "", "run"], [69, 2, 1, "", "transform"]], "nlptest.transform.robustness.AddTypo": [[70, 2, 1, "", "__init__"], [70, 2, 1, "", "async_run"], [70, 2, 1, "", "run"], [70, 2, 1, "", "transform"]], "nlptest.transform.robustness.BaseRobustness": [[71, 2, 1, "", "__init__"], [71, 3, 1, "", "alias_name"], [71, 2, 1, "", "async_run"], [71, 2, 1, "", "run"], [71, 2, 1, "", "transform"]], "nlptest.transform.robustness.ConvertAccent": [[72, 2, 1, "", "__init__"], [72, 2, 1, "", "async_run"], [72, 2, 1, "", "run"], [72, 2, 1, "", "transform"]], "nlptest.transform.robustness.LowerCase": [[73, 2, 1, "", "__init__"], [73, 2, 1, "", "async_run"], [73, 2, 1, "", "run"], [73, 2, 1, "", "transform"]], "nlptest.transform.robustness.StripPunctuation": [[74, 2, 1, "", "__init__"], [74, 2, 1, "", "async_run"], [74, 2, 1, "", "run"], [74, 2, 1, "", "transform"]], "nlptest.transform.robustness.SwapEntities": [[75, 2, 1, "", "__init__"], [75, 2, 1, "", "async_run"], [75, 2, 1, "", "run"], [75, 2, 1, "", "transform"]], "nlptest.transform.robustness.TitleCase": [[76, 2, 1, "", "__init__"], [76, 2, 1, "", "async_run"], [76, 2, 1, "", "run"], [76, 2, 1, "", "transform"]], "nlptest.transform.robustness.UpperCase": [[77, 2, 1, "", "__init__"], [77, 2, 1, "", "async_run"], [77, 2, 1, "", "run"], [77, 2, 1, "", "transform"]], "nlptest.transform.utils": [[79, 5, 1, "", "check_name"], [80, 5, 1, "", "create_terminology"], [81, 5, 1, "", "get_country_economic_representation_dict"], [82, 5, 1, "", "get_entity_representation_proportions"], [83, 5, 1, "", "get_ethnicity_representation_dict"], [84, 5, 1, "", "get_label_representation_dict"], [85, 5, 1, "", "get_religion_name_representation_dict"], [86, 5, 1, "", "get_substitution_names"]], "nlptest.utils": [[88, 0, 0, "-", "custom_types"], [106, 0, 0, "-", "gender_classifier"], [108, 0, 0, "-", "lib_manager"]], "nlptest.utils.custom_types": [[89, 0, 0, "-", "helpers"], [92, 0, 0, "-", "output"], [97, 0, 0, "-", "predictions"], [100, 0, 0, "-", "sample"]], "nlptest.utils.custom_types.helpers": [[90, 1, 1, "", "Span"], [91, 1, 1, "", "Transformation"]], "nlptest.utils.custom_types.helpers.Span": [[90, 2, 1, "", "__init__"], [90, 2, 1, "", "construct"], [90, 2, 1, "", "copy"], [90, 2, 1, "", "dict"], [90, 2, 1, "", "json"], [90, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.helpers.Transformation": [[91, 2, 1, "", "__init__"], [91, 2, 1, "", "construct"], [91, 2, 1, "", "copy"], [91, 2, 1, "", "dict"], [91, 2, 1, "", "json"], [91, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.output": [[93, 1, 1, "", "MaxScoreOutput"], [94, 1, 1, "", "MinScoreOutput"], [95, 1, 1, "", "NEROutput"], [96, 1, 1, "", "SequenceClassificationOutput"]], "nlptest.utils.custom_types.output.MaxScoreOutput": [[93, 2, 1, "", "__init__"], [93, 2, 1, "", "construct"], [93, 2, 1, "", "copy"], [93, 2, 1, "", "dict"], [93, 2, 1, "", "json"], [93, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.output.MinScoreOutput": [[94, 2, 1, "", "__init__"], [94, 2, 1, "", "construct"], [94, 2, 1, "", "copy"], [94, 2, 1, "", "dict"], [94, 2, 1, "", "json"], [94, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.output.NEROutput": [[95, 2, 1, "", "__init__"], [95, 2, 1, "", "construct"], [95, 2, 1, "", "copy"], [95, 2, 1, "", "dict"], [95, 2, 1, "", "json"], [95, 2, 1, "", "to_str_list"], [95, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.output.SequenceClassificationOutput": [[96, 2, 1, "", "__init__"], [96, 2, 1, "", "construct"], [96, 2, 1, "", "copy"], [96, 2, 1, "", "dict"], [96, 2, 1, "", "json"], [96, 2, 1, "", "to_str_list"], [96, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.predictions": [[98, 1, 1, "", "NERPrediction"], [99, 1, 1, "", "SequenceLabel"]], "nlptest.utils.custom_types.predictions.NERPrediction": [[98, 2, 1, "", "__init__"], [98, 2, 1, "", "construct"], [98, 2, 1, "", "copy"], [98, 2, 1, "", "dict"], [98, 2, 1, "", "json"], [98, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.predictions.SequenceLabel": [[99, 2, 1, "", "__init__"], [99, 2, 1, "", "construct"], [99, 2, 1, "", "copy"], [99, 2, 1, "", "dict"], [99, 2, 1, "", "json"], [99, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.sample": [[101, 1, 1, "", "BaseSample"], [102, 1, 1, "", "MaxScoreSample"], [103, 1, 1, "", "MinScoreSample"], [104, 1, 1, "", "NERSample"], [105, 1, 1, "", "SequenceClassificationSample"]], "nlptest.utils.custom_types.sample.BaseSample": [[101, 2, 1, "", "__init__"], [101, 2, 1, "", "construct"], [101, 2, 1, "", "copy"], [101, 2, 1, "", "dict"], [101, 4, 1, "", "irrelevant_transformations"], [101, 2, 1, "", "json"], [101, 4, 1, "", "relevant_transformations"], [101, 2, 1, "", "sort_transformations"], [101, 2, 1, "", "to_dict"], [101, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.sample.MaxScoreSample": [[102, 2, 1, "", "__init__"], [102, 2, 1, "", "construct"], [102, 2, 1, "", "copy"], [102, 2, 1, "", "dict"], [102, 4, 1, "", "irrelevant_transformations"], [102, 2, 1, "", "json"], [102, 4, 1, "", "relevant_transformations"], [102, 2, 1, "", "sort_transformations"], [102, 2, 1, "", "to_dict"], [102, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.sample.MinScoreSample": [[103, 2, 1, "", "__init__"], [103, 2, 1, "", "construct"], [103, 2, 1, "", "copy"], [103, 2, 1, "", "dict"], [103, 4, 1, "", "irrelevant_transformations"], [103, 2, 1, "", "json"], [103, 4, 1, "", "relevant_transformations"], [103, 2, 1, "", "sort_transformations"], [103, 2, 1, "", "to_dict"], [103, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.sample.NERSample": [[104, 2, 1, "", "__init__"], [104, 2, 1, "", "construct"], [104, 2, 1, "", "copy"], [104, 2, 1, "", "dict"], [104, 2, 1, "", "get_aligned_span_pairs"], [104, 4, 1, "", "ignored_predictions"], [104, 4, 1, "", "irrelevant_transformations"], [104, 2, 1, "", "json"], [104, 4, 1, "", "realigned_spans"], [104, 4, 1, "", "relevant_transformations"], [104, 2, 1, "", "sort_transformations"], [104, 2, 1, "", "to_dict"], [104, 2, 1, "", "update_forward_refs"]], "nlptest.utils.custom_types.sample.SequenceClassificationSample": [[105, 2, 1, "", "__init__"], [105, 2, 1, "", "construct"], [105, 2, 1, "", "copy"], [105, 2, 1, "", "dict"], [105, 4, 1, "", "irrelevant_transformations"], [105, 2, 1, "", "json"], [105, 4, 1, "", "relevant_transformations"], [105, 2, 1, "", "sort_transformations"], [105, 2, 1, "", "to_dict"], [105, 2, 1, "", "update_forward_refs"]], "nlptest.utils.gender_classifier": [[107, 1, 1, "", "GenderClassifier"]], "nlptest.utils.gender_classifier.GenderClassifier": [[107, 2, 1, "", "__init__"], [107, 2, 1, "", "predict"]], "nlptest.utils.lib_manager": [[109, 5, 1, "", "try_import_lib"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:property", "5": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "property", "Python property"], "5": ["py", "function", "Python function"]}, "titleterms": {"nlptest": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109], "augment": [1, 2, 3], "augmentrobust": 2, "baseaugmentaion": 3, "datahandl": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "datasourc": [5, 6, 7, 8, 9], "csvdataset": 6, "conlldataset": 7, "datafactori": 8, "jsondataset": 9, "format": [10, 11, 12, 13, 14], "baseformatt": 11, "formatt": 12, "neroutputformatt": 13, "sequenceclassificationoutputformatt": 14, "modelhandl": [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "jsl_modelhandl": [16, 17, 18], "pretrainedmodelforn": [17, 22, 25], "pretrainedmodelfortextclassif": [18, 23, 26], "modelfactori": 20, "spacy_modelhandl": [21, 22, 23], "transformers_modelhandl": [24, 25, 26], "har": 28, "testrunn": [29, 30, 31], "baserunn": 30, "transform": [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 91], "accuracytestfactori": 33, "biastestfactori": 34, "fairnesstestfactori": 35, "itest": 36, "representationtestfactori": 37, "robustnesstestfactori": 38, "testfactori": 39, "accuraci": [40, 41, 42, 43, 44, 45, 46, 47], "baseaccuraci": 41, "minf1scor": 42, "minmacrof1scor": 43, "minmicrof1scor": 44, "minprecisionscor": 45, "minrecallscor": 46, "minweightedf1scor": 47, "bia": [48, 49, 50, 51, 52, 53], "basebia": 49, "countryeconomicbia": 50, "ethnicitynamebia": 51, "genderpronounbia": 52, "religionbia": 53, "fair": [54, 55, 56, 57, 58], "basefair": 55, "maxgenderf1scor": 56, "mingenderf1scor": 57, "get_gendered_data": 58, "represent": [59, 60, 61, 62, 63, 64, 65], "baserepresent": 60, "countryeconomicrepresent": 61, "ethnicityrepresent": 62, "genderrepresent": 63, "labelrepresent": 64, "religionrepresent": 65, "robust": [66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "addcontext": 67, "addcontract": 68, "addpunctu": 69, "addtypo": 70, "baserobust": 71, "convertacc": 72, "lowercas": 73, "strippunctu": 74, "swapent": 75, "titlecas": 76, "uppercas": 77, "util": [78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109], "check_nam": 79, "create_terminologi": 80, "get_country_economic_representation_dict": 81, "get_entity_representation_proport": 82, "get_ethnicity_representation_dict": 83, "get_label_representation_dict": 84, "get_religion_name_representation_dict": 85, "get_substitution_nam": 86, "custom_typ": [88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "helper": [89, 90, 91], "span": 90, "output": [92, 93, 94, 95, 96], "maxscoreoutput": 93, "minscoreoutput": 94, "neroutput": 95, "sequenceclassificationoutput": 96, "predict": [97, 98, 99], "nerpredict": 98, "sequencelabel": 99, "sampl": [100, 101, 102, 103, 104, 105], "basesampl": 101, "maxscoresampl": 102, "minscoresampl": 103, "nersampl": 104, "sequenceclassificationsampl": 105, "gender_classifi": [106, 107], "genderclassifi": 107, "lib_manag": [108, 109], "try_import_lib": 109, "nlp": [111, 112], "test": [111, 112], "document": 111, "quick": 112, "start": 112, "altern": 112, "instal": 112, "option": 112}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"nlptest": [[0, "module-nlptest"]], "nlptest.augmentation": [[1, "module-nlptest.augmentation"]], "nlptest.augmentation.AugmentRobustness": [[2, "nlptest-augmentation-augmentrobustness"]], "nlptest.augmentation.BaseAugmentaion": [[3, "nlptest-augmentation-baseaugmentaion"]], "nlptest.datahandler": [[4, "module-nlptest.datahandler"]], "nlptest.datahandler.datasource": [[5, "module-nlptest.datahandler.datasource"]], "nlptest.datahandler.datasource.CSVDataset": [[6, "nlptest-datahandler-datasource-csvdataset"]], "nlptest.datahandler.datasource.ConllDataset": [[7, "nlptest-datahandler-datasource-conlldataset"]], "nlptest.datahandler.datasource.DataFactory": [[8, "nlptest-datahandler-datasource-datafactory"]], "nlptest.datahandler.datasource.JSONDataset": [[9, "nlptest-datahandler-datasource-jsondataset"]], "nlptest.datahandler.format": [[10, "module-nlptest.datahandler.format"]], "nlptest.datahandler.format.BaseFormatter": [[11, "nlptest-datahandler-format-baseformatter"]], "nlptest.datahandler.format.Formatter": [[12, "nlptest-datahandler-format-formatter"]], "nlptest.datahandler.format.NEROutputFormatter": [[13, "nlptest-datahandler-format-neroutputformatter"]], "nlptest.datahandler.format.SequenceClassificationOutputFormatter": [[14, "nlptest-datahandler-format-sequenceclassificationoutputformatter"]], "nlptest.modelhandler": [[15, "module-nlptest.modelhandler"]], "nlptest.modelhandler.jsl_modelhandler": [[16, "module-nlptest.modelhandler.jsl_modelhandler"]], "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForNER": [[17, "nlptest-modelhandler-jsl-modelhandler-pretrainedmodelforner"]], "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification": [[18, "nlptest-modelhandler-jsl-modelhandler-pretrainedmodelfortextclassification"]], "nlptest.modelhandler.modelhandler": [[19, "module-nlptest.modelhandler.modelhandler"]], "nlptest.modelhandler.modelhandler.ModelFactory": [[20, "nlptest-modelhandler-modelhandler-modelfactory"]], "nlptest.modelhandler.spacy_modelhandler": [[21, "module-nlptest.modelhandler.spacy_modelhandler"]], "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForNER": [[22, "nlptest-modelhandler-spacy-modelhandler-pretrainedmodelforner"]], "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification": [[23, "nlptest-modelhandler-spacy-modelhandler-pretrainedmodelfortextclassification"]], "nlptest.modelhandler.transformers_modelhandler": [[24, "module-nlptest.modelhandler.transformers_modelhandler"]], "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForNER": [[25, "nlptest-modelhandler-transformers-modelhandler-pretrainedmodelforner"]], "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification": [[26, "nlptest-modelhandler-transformers-modelhandler-pretrainedmodelfortextclassification"]], "nlptest.nlptest": [[27, "module-nlptest.nlptest"]], "nlptest.nlptest.Harness": [[28, "nlptest-nlptest-harness"]], "nlptest.testrunner": [[29, "module-nlptest.testrunner"]], "nlptest.testrunner.BaseRunner": [[30, "nlptest-testrunner-baserunner"]], "nlptest.testrunner.TestRunner": [[31, "nlptest-testrunner-testrunner"]], "nlptest.transform": [[32, "module-nlptest.transform"]], "nlptest.transform.AccuracyTestFactory": [[33, "nlptest-transform-accuracytestfactory"]], "nlptest.transform.BiasTestFactory": [[34, "nlptest-transform-biastestfactory"]], "nlptest.transform.FairnessTestFactory": [[35, "nlptest-transform-fairnesstestfactory"]], "nlptest.transform.ITests": [[36, "nlptest-transform-itests"]], "nlptest.transform.RepresentationTestFactory": [[37, "nlptest-transform-representationtestfactory"]], "nlptest.transform.RobustnessTestFactory": [[38, "nlptest-transform-robustnesstestfactory"]], "nlptest.transform.TestFactory": [[39, "nlptest-transform-testfactory"]], "nlptest.transform.accuracy": [[40, "module-nlptest.transform.accuracy"]], "nlptest.transform.accuracy.BaseAccuracy": [[41, "nlptest-transform-accuracy-baseaccuracy"]], "nlptest.transform.accuracy.MinF1Score": [[42, "nlptest-transform-accuracy-minf1score"]], "nlptest.transform.accuracy.MinMacroF1Score": [[43, "nlptest-transform-accuracy-minmacrof1score"]], "nlptest.transform.accuracy.MinMicroF1Score": [[44, "nlptest-transform-accuracy-minmicrof1score"]], "nlptest.transform.accuracy.MinPrecisionScore": [[45, "nlptest-transform-accuracy-minprecisionscore"]], "nlptest.transform.accuracy.MinRecallScore": [[46, "nlptest-transform-accuracy-minrecallscore"]], "nlptest.transform.accuracy.MinWeightedF1Score": [[47, "nlptest-transform-accuracy-minweightedf1score"]], "nlptest.transform.bias": [[48, "module-nlptest.transform.bias"]], "nlptest.transform.bias.BaseBias": [[49, "nlptest-transform-bias-basebias"]], "nlptest.transform.bias.CountryEconomicBias": [[50, "nlptest-transform-bias-countryeconomicbias"]], "nlptest.transform.bias.EthnicityNameBias": [[51, "nlptest-transform-bias-ethnicitynamebias"]], "nlptest.transform.bias.GenderPronounBias": [[52, "nlptest-transform-bias-genderpronounbias"]], "nlptest.transform.bias.ReligionBias": [[53, "nlptest-transform-bias-religionbias"]], "nlptest.transform.fairness": [[54, "module-nlptest.transform.fairness"]], "nlptest.transform.fairness.BaseFairness": [[55, "nlptest-transform-fairness-basefairness"]], "nlptest.transform.fairness.MaxGenderF1Score": [[56, "nlptest-transform-fairness-maxgenderf1score"]], "nlptest.transform.fairness.MinGenderF1Score": [[57, "nlptest-transform-fairness-mingenderf1score"]], "nlptest.transform.fairness.get_gendered_data": [[58, "nlptest-transform-fairness-get-gendered-data"]], "nlptest.transform.representation": [[59, "module-nlptest.transform.representation"]], "nlptest.transform.representation.BaseRepresentation": [[60, "nlptest-transform-representation-baserepresentation"]], "nlptest.transform.representation.CountryEconomicRepresentation": [[61, "nlptest-transform-representation-countryeconomicrepresentation"]], "nlptest.transform.representation.EthnicityRepresentation": [[62, "nlptest-transform-representation-ethnicityrepresentation"]], "nlptest.transform.representation.GenderRepresentation": [[63, "nlptest-transform-representation-genderrepresentation"]], "nlptest.transform.representation.LabelRepresentation": [[64, "nlptest-transform-representation-labelrepresentation"]], "nlptest.transform.representation.ReligionRepresentation": [[65, "nlptest-transform-representation-religionrepresentation"]], "nlptest.transform.robustness": [[66, "module-nlptest.transform.robustness"]], "nlptest.transform.robustness.AddContext": [[67, "nlptest-transform-robustness-addcontext"]], "nlptest.transform.robustness.AddContraction": [[68, "nlptest-transform-robustness-addcontraction"]], "nlptest.transform.robustness.AddPunctuation": [[69, "nlptest-transform-robustness-addpunctuation"]], "nlptest.transform.robustness.AddTypo": [[70, "nlptest-transform-robustness-addtypo"]], "nlptest.transform.robustness.BaseRobustness": [[71, "nlptest-transform-robustness-baserobustness"]], "nlptest.transform.robustness.ConvertAccent": [[72, "nlptest-transform-robustness-convertaccent"]], "nlptest.transform.robustness.LowerCase": [[73, "nlptest-transform-robustness-lowercase"]], "nlptest.transform.robustness.StripPunctuation": [[74, "nlptest-transform-robustness-strippunctuation"]], "nlptest.transform.robustness.SwapEntities": [[75, "nlptest-transform-robustness-swapentities"]], "nlptest.transform.robustness.TitleCase": [[76, "nlptest-transform-robustness-titlecase"]], "nlptest.transform.robustness.UpperCase": [[77, "nlptest-transform-robustness-uppercase"]], "nlptest.transform.utils": [[78, "module-nlptest.transform.utils"]], "nlptest.transform.utils.check_name": [[79, "nlptest-transform-utils-check-name"]], "nlptest.transform.utils.create_terminology": [[80, "nlptest-transform-utils-create-terminology"]], "nlptest.transform.utils.get_country_economic_representation_dict": [[81, "nlptest-transform-utils-get-country-economic-representation-dict"]], "nlptest.transform.utils.get_entity_representation_proportions": [[82, "nlptest-transform-utils-get-entity-representation-proportions"]], "nlptest.transform.utils.get_ethnicity_representation_dict": [[83, "nlptest-transform-utils-get-ethnicity-representation-dict"]], "nlptest.transform.utils.get_label_representation_dict": [[84, "nlptest-transform-utils-get-label-representation-dict"]], "nlptest.transform.utils.get_religion_name_representation_dict": [[85, "nlptest-transform-utils-get-religion-name-representation-dict"]], "nlptest.transform.utils.get_substitution_names": [[86, "nlptest-transform-utils-get-substitution-names"]], "nlptest.utils": [[87, "module-nlptest.utils"]], "nlptest.utils.custom_types": [[88, "module-nlptest.utils.custom_types"]], "nlptest.utils.custom_types.helpers": [[89, "module-nlptest.utils.custom_types.helpers"]], "nlptest.utils.custom_types.helpers.Span": [[90, "nlptest-utils-custom-types-helpers-span"]], "nlptest.utils.custom_types.helpers.Transformation": [[91, "nlptest-utils-custom-types-helpers-transformation"]], "nlptest.utils.custom_types.output": [[92, "module-nlptest.utils.custom_types.output"]], "nlptest.utils.custom_types.output.MaxScoreOutput": [[93, "nlptest-utils-custom-types-output-maxscoreoutput"]], "nlptest.utils.custom_types.output.MinScoreOutput": [[94, "nlptest-utils-custom-types-output-minscoreoutput"]], "nlptest.utils.custom_types.output.NEROutput": [[95, "nlptest-utils-custom-types-output-neroutput"]], "nlptest.utils.custom_types.output.SequenceClassificationOutput": [[96, "nlptest-utils-custom-types-output-sequenceclassificationoutput"]], "nlptest.utils.custom_types.predictions": [[97, "module-nlptest.utils.custom_types.predictions"]], "nlptest.utils.custom_types.predictions.NERPrediction": [[98, "nlptest-utils-custom-types-predictions-nerprediction"]], "nlptest.utils.custom_types.predictions.SequenceLabel": [[99, "nlptest-utils-custom-types-predictions-sequencelabel"]], "nlptest.utils.custom_types.sample": [[100, "module-nlptest.utils.custom_types.sample"]], "nlptest.utils.custom_types.sample.BaseSample": [[101, "nlptest-utils-custom-types-sample-basesample"]], "nlptest.utils.custom_types.sample.MaxScoreSample": [[102, "nlptest-utils-custom-types-sample-maxscoresample"]], "nlptest.utils.custom_types.sample.MinScoreSample": [[103, "nlptest-utils-custom-types-sample-minscoresample"]], "nlptest.utils.custom_types.sample.NERSample": [[104, "nlptest-utils-custom-types-sample-nersample"]], "nlptest.utils.custom_types.sample.SequenceClassificationSample": [[105, "nlptest-utils-custom-types-sample-sequenceclassificationsample"]], "nlptest.utils.gender_classifier": [[106, "module-nlptest.utils.gender_classifier"]], "nlptest.utils.gender_classifier.GenderClassifier": [[107, "nlptest-utils-gender-classifier-genderclassifier"]], "nlptest.utils.lib_manager": [[108, "module-nlptest.utils.lib_manager"]], "nlptest.utils.lib_manager.try_import_lib": [[109, "nlptest-utils-lib-manager-try-import-lib"]], "NLP Test Documentation": [[111, "nlp-test-documentation"]], "Quick Start": [[112, "quick-start"]], "NLP Test Quick Start": [[112, "nlp-test-quick-start"]], "Alternative Installation Options": [[112, "alternative-installation-options"]]}, "indexentries": {"module": [[0, "module-nlptest"], [1, "module-nlptest.augmentation"], [4, "module-nlptest.datahandler"], [5, "module-nlptest.datahandler.datasource"], [10, "module-nlptest.datahandler.format"], [15, "module-nlptest.modelhandler"], [16, "module-nlptest.modelhandler.jsl_modelhandler"], [19, "module-nlptest.modelhandler.modelhandler"], [21, "module-nlptest.modelhandler.spacy_modelhandler"], [24, "module-nlptest.modelhandler.transformers_modelhandler"], [27, "module-nlptest.nlptest"], [29, "module-nlptest.testrunner"], [32, "module-nlptest.transform"], [40, "module-nlptest.transform.accuracy"], [48, "module-nlptest.transform.bias"], [54, "module-nlptest.transform.fairness"], [59, "module-nlptest.transform.representation"], [66, "module-nlptest.transform.robustness"], [78, "module-nlptest.transform.utils"], [87, "module-nlptest.utils"], [88, "module-nlptest.utils.custom_types"], [89, "module-nlptest.utils.custom_types.helpers"], [92, "module-nlptest.utils.custom_types.output"], [97, "module-nlptest.utils.custom_types.predictions"], [100, "module-nlptest.utils.custom_types.sample"], [106, "module-nlptest.utils.gender_classifier"], [108, "module-nlptest.utils.lib_manager"]], "nlptest": [[0, "module-nlptest"]], "nlptest.augmentation": [[1, "module-nlptest.augmentation"]], "augmentrobustness (class in nlptest.augmentation)": [[2, "nlptest.augmentation.AugmentRobustness"]], "__init__() (augmentrobustness method)": [[2, "id0"], [2, "nlptest.augmentation.AugmentRobustness.__init__"]], "config (augmentrobustness attribute)": [[2, "nlptest.augmentation.AugmentRobustness.config"]], "fix() (augmentrobustness method)": [[2, "id1"], [2, "nlptest.augmentation.AugmentRobustness.fix"]], "h_report (augmentrobustness attribute)": [[2, "nlptest.augmentation.AugmentRobustness.h_report"]], "max_prop (augmentrobustness attribute)": [[2, "nlptest.augmentation.AugmentRobustness.max_prop"]], "suggestions() (augmentrobustness method)": [[2, "id2"], [2, "nlptest.augmentation.AugmentRobustness.suggestions"]], "task (augmentrobustness attribute)": [[2, "nlptest.augmentation.AugmentRobustness.task"]], "baseaugmentaion (class in nlptest.augmentation)": [[3, "nlptest.augmentation.BaseAugmentaion"]], "none (baseaugmentaion attribute)": [[3, "nlptest.augmentation.BaseAugmentaion.None"]], "__init__() (baseaugmentaion method)": [[3, "nlptest.augmentation.BaseAugmentaion.__init__"]], "fix() (baseaugmentaion method)": [[3, "id0"], [3, "nlptest.augmentation.BaseAugmentaion.fix"]], "nlptest.datahandler": [[4, "module-nlptest.datahandler"]], "nlptest.datahandler.datasource": [[5, "module-nlptest.datahandler.datasource"]], "csvdataset (class in nlptest.datahandler.datasource)": [[6, "nlptest.datahandler.datasource.CSVDataset"]], "__init__() (csvdataset method)": [[6, "nlptest.datahandler.datasource.CSVDataset.__init__"]], "export_data() (csvdataset method)": [[6, "nlptest.datahandler.datasource.CSVDataset.export_data"]], "load_data() (csvdataset method)": [[6, "nlptest.datahandler.datasource.CSVDataset.load_data"]], "conlldataset (class in nlptest.datahandler.datasource)": [[7, "nlptest.datahandler.datasource.ConllDataset"]], "__init__() (conlldataset method)": [[7, "nlptest.datahandler.datasource.ConllDataset.__init__"]], "export_data() (conlldataset method)": [[7, "nlptest.datahandler.datasource.ConllDataset.export_data"]], "load_data() (conlldataset method)": [[7, "nlptest.datahandler.datasource.ConllDataset.load_data"]], "datafactory (class in nlptest.datahandler.datasource)": [[8, "nlptest.datahandler.datasource.DataFactory"]], "__init__() (datafactory method)": [[8, "nlptest.datahandler.datasource.DataFactory.__init__"]], "export() (datafactory method)": [[8, "nlptest.datahandler.datasource.DataFactory.export"]], "load() (datafactory method)": [[8, "nlptest.datahandler.datasource.DataFactory.load"]], "jsondataset (class in nlptest.datahandler.datasource)": [[9, "nlptest.datahandler.datasource.JSONDataset"]], "__init__() (jsondataset method)": [[9, "nlptest.datahandler.datasource.JSONDataset.__init__"]], "export_data() (jsondataset method)": [[9, "nlptest.datahandler.datasource.JSONDataset.export_data"]], "nlptest.datahandler.format": [[10, "module-nlptest.datahandler.format"]], "baseformatter (class in nlptest.datahandler.format)": [[11, "nlptest.datahandler.format.BaseFormatter"]], "__init__() (baseformatter method)": [[11, "nlptest.datahandler.format.BaseFormatter.__init__"]], "to_conll() (baseformatter static method)": [[11, "nlptest.datahandler.format.BaseFormatter.to_conll"]], "to_csv() (baseformatter static method)": [[11, "nlptest.datahandler.format.BaseFormatter.to_csv"]], "formatter (class in nlptest.datahandler.format)": [[12, "nlptest.datahandler.format.Formatter"]], "__init__() (formatter method)": [[12, "nlptest.datahandler.format.Formatter.__init__"]], "process() (formatter static method)": [[12, "nlptest.datahandler.format.Formatter.process"]], "neroutputformatter (class in nlptest.datahandler.format)": [[13, "nlptest.datahandler.format.NEROutputFormatter"]], "__init__() (neroutputformatter method)": [[13, "nlptest.datahandler.format.NEROutputFormatter.__init__"]], "to_conll() (neroutputformatter static method)": [[13, "nlptest.datahandler.format.NEROutputFormatter.to_conll"]], "to_csv() (neroutputformatter static method)": [[13, "nlptest.datahandler.format.NEROutputFormatter.to_csv"]], "sequenceclassificationoutputformatter (class in nlptest.datahandler.format)": [[14, "nlptest.datahandler.format.SequenceClassificationOutputFormatter"]], "__init__() (sequenceclassificationoutputformatter method)": [[14, "nlptest.datahandler.format.SequenceClassificationOutputFormatter.__init__"]], "to_conll() (sequenceclassificationoutputformatter static method)": [[14, "nlptest.datahandler.format.SequenceClassificationOutputFormatter.to_conll"]], "to_csv() (sequenceclassificationoutputformatter static method)": [[14, "nlptest.datahandler.format.SequenceClassificationOutputFormatter.to_csv"]], "nlptest.modelhandler": [[15, "module-nlptest.modelhandler"]], "nlptest.modelhandler.jsl_modelhandler": [[16, "module-nlptest.modelhandler.jsl_modelhandler"]], "pretrainedmodelforner (class in nlptest.modelhandler.jsl_modelhandler)": [[17, "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForNER"]], "__init__() (pretrainedmodelforner method)": [[17, "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForNER.__init__"], [22, "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForNER.__init__"], [25, "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForNER.__init__"]], "group_entities() (pretrainedmodelforner method)": [[17, "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForNER.group_entities"], [25, "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForNER.group_entities"]], "is_ner_annotator() (pretrainedmodelforner static method)": [[17, "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForNER.is_ner_annotator"]], "load_model() (pretrainedmodelforner class method)": [[17, "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForNER.load_model"], [22, "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForNER.load_model"], [25, "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForNER.load_model"]], "model (pretrainedmodelforner attribute)": [[17, "id0"], [17, "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForNER.model"], [25, "id0"], [25, "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForNER.model"]], "predict() (pretrainedmodelforner method)": [[17, "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForNER.predict"], [22, "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForNER.predict"], [25, "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForNER.predict"]], "predict_raw() (pretrainedmodelforner method)": [[17, "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForNER.predict_raw"], [22, "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForNER.predict_raw"], [25, "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForNER.predict_raw"]], "pretrainedmodelfortextclassification (class in nlptest.modelhandler.jsl_modelhandler)": [[18, "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification"]], "__init__() (pretrainedmodelfortextclassification method)": [[18, "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification.__init__"], [23, "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification.__init__"], [26, "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification.__init__"]], "is_classifier() (pretrainedmodelfortextclassification static method)": [[18, "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification.is_classifier"]], "load_model() (pretrainedmodelfortextclassification class method)": [[18, "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification.load_model"], [23, "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification.load_model"], [26, "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification.load_model"]], "model (pretrainedmodelfortextclassification attribute)": [[18, "id0"], [18, "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification.model"], [26, "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification.model"]], "predict() (pretrainedmodelfortextclassification method)": [[18, "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification.predict"], [23, "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification.predict"], [26, "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification.predict"]], "predict_raw() (pretrainedmodelfortextclassification method)": [[18, "nlptest.modelhandler.jsl_modelhandler.PretrainedModelForTextClassification.predict_raw"], [23, "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification.predict_raw"], [26, "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification.predict_raw"]], "nlptest.modelhandler.modelhandler": [[19, "module-nlptest.modelhandler.modelhandler"]], "modelfactory (class in nlptest.modelhandler.modelhandler)": [[20, "nlptest.modelhandler.modelhandler.ModelFactory"]], "__init__() (modelfactory method)": [[20, "nlptest.modelhandler.modelhandler.ModelFactory.__init__"]], "load_model() (modelfactory class method)": [[20, "nlptest.modelhandler.modelhandler.ModelFactory.load_model"]], "predict() (modelfactory method)": [[20, "nlptest.modelhandler.modelhandler.ModelFactory.predict"]], "predict_raw() (modelfactory method)": [[20, "nlptest.modelhandler.modelhandler.ModelFactory.predict_raw"]], "nlptest.modelhandler.spacy_modelhandler": [[21, "module-nlptest.modelhandler.spacy_modelhandler"]], "pretrainedmodelforner (class in nlptest.modelhandler.spacy_modelhandler)": [[22, "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForNER"]], "pretrainedmodelfortextclassification (class in nlptest.modelhandler.spacy_modelhandler)": [[23, "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification"]], "labels (pretrainedmodelfortextclassification property)": [[23, "nlptest.modelhandler.spacy_modelhandler.PretrainedModelForTextClassification.labels"], [26, "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification.labels"]], "model (in module nlptest.modelhandler.transformers_modelhandler)": [[24, "nlptest.modelhandler.transformers_modelhandler.model"]], "nlptest.modelhandler.transformers_modelhandler": [[24, "module-nlptest.modelhandler.transformers_modelhandler"]], "pretrainedmodelforner (class in nlptest.modelhandler.transformers_modelhandler)": [[25, "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForNER"]], "pretrainedmodelfortextclassification (class in nlptest.modelhandler.transformers_modelhandler)": [[26, "nlptest.modelhandler.transformers_modelhandler.PretrainedModelForTextClassification"]], "nlptest.nlptest": [[27, "module-nlptest.nlptest"]], "harness (class in nlptest.nlptest)": [[28, "nlptest.nlptest.Harness"]], "__init__() (harness method)": [[28, "nlptest.nlptest.Harness.__init__"]], "augment() (harness method)": [[28, "nlptest.nlptest.Harness.augment"]], "configure() (harness method)": [[28, "nlptest.nlptest.Harness.configure"]], "generate() (harness method)": [[28, "nlptest.nlptest.Harness.generate"]], "generated_results() (harness method)": [[28, "nlptest.nlptest.Harness.generated_results"]], "load() (harness class method)": [[28, "nlptest.nlptest.Harness.load"]], "report() (harness method)": [[28, "nlptest.nlptest.Harness.report"]], "run() (harness method)": [[28, "nlptest.nlptest.Harness.run"]], "save() (harness method)": [[28, "nlptest.nlptest.Harness.save"]], "testcases() (harness method)": [[28, "nlptest.nlptest.Harness.testcases"]], "nlptest.testrunner": [[29, "module-nlptest.testrunner"]], "baserunner (class in nlptest.testrunner)": [[30, "nlptest.testrunner.BaseRunner"]], "__init__() (baserunner method)": [[30, "nlptest.testrunner.BaseRunner.__init__"]], "evaluate() (baserunner method)": [[30, "nlptest.testrunner.BaseRunner.evaluate"]], "testrunner (class in nlptest.testrunner)": [[31, "nlptest.testrunner.TestRunner"]], "__init__() (testrunner method)": [[31, "nlptest.testrunner.TestRunner.__init__"]], "evaluate() (testrunner method)": [[31, "nlptest.testrunner.TestRunner.evaluate"]], "nlptest.transform": [[32, "module-nlptest.transform"]], "accuracytestfactory (class in nlptest.transform)": [[33, "nlptest.transform.AccuracyTestFactory"]], "__init__() (accuracytestfactory method)": [[33, "nlptest.transform.AccuracyTestFactory.__init__"]], "available_tests() (accuracytestfactory class method)": [[33, "nlptest.transform.AccuracyTestFactory.available_tests"]], "run() (accuracytestfactory class method)": [[33, "nlptest.transform.AccuracyTestFactory.run"]], "transform() (accuracytestfactory method)": [[33, "nlptest.transform.AccuracyTestFactory.transform"]], "biastestfactory (class in nlptest.transform)": [[34, "nlptest.transform.BiasTestFactory"]], "__init__() (biastestfactory method)": [[34, "nlptest.transform.BiasTestFactory.__init__"]], "available_tests() (biastestfactory class method)": [[34, "nlptest.transform.BiasTestFactory.available_tests"]], "run() (biastestfactory class method)": [[34, "nlptest.transform.BiasTestFactory.run"]], "transform() (biastestfactory method)": [[34, "nlptest.transform.BiasTestFactory.transform"]], "fairnesstestfactory (class in nlptest.transform)": [[35, "nlptest.transform.FairnessTestFactory"]], "__init__() (fairnesstestfactory method)": [[35, "nlptest.transform.FairnessTestFactory.__init__"]], "available_tests() (fairnesstestfactory class method)": [[35, "nlptest.transform.FairnessTestFactory.available_tests"]], "run() (fairnesstestfactory class method)": [[35, "nlptest.transform.FairnessTestFactory.run"]], "transform() (fairnesstestfactory method)": [[35, "nlptest.transform.FairnessTestFactory.transform"]], "itests (class in nlptest.transform)": [[36, "nlptest.transform.ITests"]], "__init__() (itests method)": [[36, "nlptest.transform.ITests.__init__"]], "available_tests() (itests method)": [[36, "nlptest.transform.ITests.available_tests"]], "run() (itests class method)": [[36, "nlptest.transform.ITests.run"]], "transform() (itests method)": [[36, "nlptest.transform.ITests.transform"]], "representationtestfactory (class in nlptest.transform)": [[37, "nlptest.transform.RepresentationTestFactory"]], "__init__() (representationtestfactory method)": [[37, "nlptest.transform.RepresentationTestFactory.__init__"]], "available_tests() (representationtestfactory class method)": [[37, "nlptest.transform.RepresentationTestFactory.available_tests"]], "run() (representationtestfactory class method)": [[37, "nlptest.transform.RepresentationTestFactory.run"]], "transform() (representationtestfactory method)": [[37, "nlptest.transform.RepresentationTestFactory.transform"]], "robustnesstestfactory (class in nlptest.transform)": [[38, "nlptest.transform.RobustnessTestFactory"]], "__init__() (robustnesstestfactory method)": [[38, "nlptest.transform.RobustnessTestFactory.__init__"]], "available_tests() (robustnesstestfactory class method)": [[38, "nlptest.transform.RobustnessTestFactory.available_tests"]], "run() (robustnesstestfactory class method)": [[38, "nlptest.transform.RobustnessTestFactory.run"]], "transform() (robustnesstestfactory method)": [[38, "nlptest.transform.RobustnessTestFactory.transform"]], "testfactory (class in nlptest.transform)": [[39, "nlptest.transform.TestFactory"]], "__init__() (testfactory method)": [[39, "nlptest.transform.TestFactory.__init__"]], "async_run() (testfactory class method)": [[39, "nlptest.transform.TestFactory.async_run"]], "run() (testfactory static method)": [[39, "nlptest.transform.TestFactory.run"]], "test_categories() (testfactory class method)": [[39, "nlptest.transform.TestFactory.test_categories"]], "test_scenarios() (testfactory class method)": [[39, "nlptest.transform.TestFactory.test_scenarios"]], "transform() (testfactory static method)": [[39, "nlptest.transform.TestFactory.transform"]], "nlptest.transform.accuracy": [[40, "module-nlptest.transform.accuracy"]], "baseaccuracy (class in nlptest.transform.accuracy)": [[41, "nlptest.transform.accuracy.BaseAccuracy"]], "__init__() (baseaccuracy method)": [[41, "nlptest.transform.accuracy.BaseAccuracy.__init__"]], "alias_name (baseaccuracy attribute)": [[41, "nlptest.transform.accuracy.BaseAccuracy.alias_name"]], "async_run() (baseaccuracy class method)": [[41, "nlptest.transform.accuracy.BaseAccuracy.async_run"]], "transform() (baseaccuracy static method)": [[41, "nlptest.transform.accuracy.BaseAccuracy.transform"]], "minf1score (class in nlptest.transform.accuracy)": [[42, "nlptest.transform.accuracy.MinF1Score"]], "__init__() (minf1score method)": [[42, "nlptest.transform.accuracy.MinF1Score.__init__"]], "alias_name (minf1score attribute)": [[42, "nlptest.transform.accuracy.MinF1Score.alias_name"]], "async_run() (minf1score class method)": [[42, "nlptest.transform.accuracy.MinF1Score.async_run"]], "run() (minf1score method)": [[42, "nlptest.transform.accuracy.MinF1Score.run"]], "transform() (minf1score method)": [[42, "nlptest.transform.accuracy.MinF1Score.transform"]], "transform() (minf1score static method)": [[42, "id0"]], "minmacrof1score (class in nlptest.transform.accuracy)": [[43, "nlptest.transform.accuracy.MinMacroF1Score"]], "__init__() (minmacrof1score method)": [[43, "nlptest.transform.accuracy.MinMacroF1Score.__init__"]], "alias_name (minmacrof1score attribute)": [[43, "nlptest.transform.accuracy.MinMacroF1Score.alias_name"]], "async_run() (minmacrof1score class method)": [[43, "nlptest.transform.accuracy.MinMacroF1Score.async_run"]], "run() (minmacrof1score method)": [[43, "nlptest.transform.accuracy.MinMacroF1Score.run"]], "transform() (minmacrof1score method)": [[43, "nlptest.transform.accuracy.MinMacroF1Score.transform"]], "transform() (minmacrof1score static method)": [[43, "id0"]], "minmicrof1score (class in nlptest.transform.accuracy)": [[44, "nlptest.transform.accuracy.MinMicroF1Score"]], "__init__() (minmicrof1score method)": [[44, "nlptest.transform.accuracy.MinMicroF1Score.__init__"]], "alias_name (minmicrof1score attribute)": [[44, "nlptest.transform.accuracy.MinMicroF1Score.alias_name"]], "async_run() (minmicrof1score class method)": [[44, "nlptest.transform.accuracy.MinMicroF1Score.async_run"]], "run() (minmicrof1score method)": [[44, "nlptest.transform.accuracy.MinMicroF1Score.run"]], "transform() (minmicrof1score method)": [[44, "nlptest.transform.accuracy.MinMicroF1Score.transform"]], "transform() (minmicrof1score static method)": [[44, "id0"]], "minprecisionscore (class in nlptest.transform.accuracy)": [[45, "nlptest.transform.accuracy.MinPrecisionScore"]], "__init__() (minprecisionscore method)": [[45, "nlptest.transform.accuracy.MinPrecisionScore.__init__"]], "alias_name (minprecisionscore attribute)": [[45, "nlptest.transform.accuracy.MinPrecisionScore.alias_name"]], "async_run() (minprecisionscore class method)": [[45, "nlptest.transform.accuracy.MinPrecisionScore.async_run"]], "run() (minprecisionscore method)": [[45, "nlptest.transform.accuracy.MinPrecisionScore.run"]], "transform() (minprecisionscore method)": [[45, "nlptest.transform.accuracy.MinPrecisionScore.transform"]], "transform() (minprecisionscore static method)": [[45, "id0"]], "minrecallscore (class in nlptest.transform.accuracy)": [[46, "nlptest.transform.accuracy.MinRecallScore"]], "__init__() (minrecallscore method)": [[46, "nlptest.transform.accuracy.MinRecallScore.__init__"]], "alias_name (minrecallscore attribute)": [[46, "nlptest.transform.accuracy.MinRecallScore.alias_name"]], "async_run() (minrecallscore class method)": [[46, "nlptest.transform.accuracy.MinRecallScore.async_run"]], "run() (minrecallscore method)": [[46, "nlptest.transform.accuracy.MinRecallScore.run"]], "transform() (minrecallscore method)": [[46, "nlptest.transform.accuracy.MinRecallScore.transform"]], "transform() (minrecallscore static method)": [[46, "id0"]], "minweightedf1score (class in nlptest.transform.accuracy)": [[47, "nlptest.transform.accuracy.MinWeightedF1Score"]], "__init__() (minweightedf1score method)": [[47, "nlptest.transform.accuracy.MinWeightedF1Score.__init__"]], "alias_name (minweightedf1score attribute)": [[47, "nlptest.transform.accuracy.MinWeightedF1Score.alias_name"]], "async_run() (minweightedf1score class method)": [[47, "nlptest.transform.accuracy.MinWeightedF1Score.async_run"]], "run() (minweightedf1score method)": [[47, "nlptest.transform.accuracy.MinWeightedF1Score.run"]], "transform() (minweightedf1score method)": [[47, "nlptest.transform.accuracy.MinWeightedF1Score.transform"]], "transform() (minweightedf1score static method)": [[47, "id0"]], "nlptest.transform.bias": [[48, "module-nlptest.transform.bias"]], "basebias (class in nlptest.transform.bias)": [[49, "nlptest.transform.bias.BaseBias"]], "__init__() (basebias method)": [[49, "nlptest.transform.bias.BaseBias.__init__"]], "alias_name (basebias attribute)": [[49, "nlptest.transform.bias.BaseBias.alias_name"]], "async_run() (basebias class method)": [[49, "nlptest.transform.bias.BaseBias.async_run"]], "run() (basebias static method)": [[49, "nlptest.transform.bias.BaseBias.run"]], "transform() (basebias method)": [[49, "nlptest.transform.bias.BaseBias.transform"]], "countryeconomicbias (class in nlptest.transform.bias)": [[50, "nlptest.transform.bias.CountryEconomicBias"]], "__init__() (countryeconomicbias method)": [[50, "nlptest.transform.bias.CountryEconomicBias.__init__"]], "async_run() (countryeconomicbias class method)": [[50, "nlptest.transform.bias.CountryEconomicBias.async_run"]], "run() (countryeconomicbias static method)": [[50, "nlptest.transform.bias.CountryEconomicBias.run"]], "transform() (countryeconomicbias static method)": [[50, "nlptest.transform.bias.CountryEconomicBias.transform"]], "ethnicitynamebias (class in nlptest.transform.bias)": [[51, "nlptest.transform.bias.EthnicityNameBias"]], "__init__() (ethnicitynamebias method)": [[51, "nlptest.transform.bias.EthnicityNameBias.__init__"]], "async_run() (ethnicitynamebias class method)": [[51, "nlptest.transform.bias.EthnicityNameBias.async_run"]], "run() (ethnicitynamebias static method)": [[51, "nlptest.transform.bias.EthnicityNameBias.run"]], "transform() (ethnicitynamebias static method)": [[51, "nlptest.transform.bias.EthnicityNameBias.transform"]], "genderpronounbias (class in nlptest.transform.bias)": [[52, "nlptest.transform.bias.GenderPronounBias"]], "__init__() (genderpronounbias method)": [[52, "nlptest.transform.bias.GenderPronounBias.__init__"]], "async_run() (genderpronounbias class method)": [[52, "nlptest.transform.bias.GenderPronounBias.async_run"]], "run() (genderpronounbias static method)": [[52, "nlptest.transform.bias.GenderPronounBias.run"]], "transform() (genderpronounbias static method)": [[52, "nlptest.transform.bias.GenderPronounBias.transform"]], "religionbias (class in nlptest.transform.bias)": [[53, "nlptest.transform.bias.ReligionBias"]], "__init__() (religionbias method)": [[53, "nlptest.transform.bias.ReligionBias.__init__"]], "async_run() (religionbias class method)": [[53, "nlptest.transform.bias.ReligionBias.async_run"]], "run() (religionbias static method)": [[53, "nlptest.transform.bias.ReligionBias.run"]], "transform() (religionbias static method)": [[53, "nlptest.transform.bias.ReligionBias.transform"]], "nlptest.transform.fairness": [[54, "module-nlptest.transform.fairness"]], "basefairness (class in nlptest.transform.fairness)": [[55, "nlptest.transform.fairness.BaseFairness"]], "__init__() (basefairness method)": [[55, "nlptest.transform.fairness.BaseFairness.__init__"]], "alias_name (basefairness attribute)": [[55, "nlptest.transform.fairness.BaseFairness.alias_name"]], "async_run() (basefairness class method)": [[55, "nlptest.transform.fairness.BaseFairness.async_run"]], "transform() (basefairness static method)": [[55, "nlptest.transform.fairness.BaseFairness.transform"]], "maxgenderf1score (class in nlptest.transform.fairness)": [[56, "nlptest.transform.fairness.MaxGenderF1Score"]], "__init__() (maxgenderf1score method)": [[56, "nlptest.transform.fairness.MaxGenderF1Score.__init__"]], "alias_name (maxgenderf1score attribute)": [[56, "nlptest.transform.fairness.MaxGenderF1Score.alias_name"]], "async_run() (maxgenderf1score class method)": [[56, "nlptest.transform.fairness.MaxGenderF1Score.async_run"]], "run() (maxgenderf1score method)": [[56, "nlptest.transform.fairness.MaxGenderF1Score.run"]], "transform() (maxgenderf1score static method)": [[56, "nlptest.transform.fairness.MaxGenderF1Score.transform"]], "mingenderf1score (class in nlptest.transform.fairness)": [[57, "nlptest.transform.fairness.MinGenderF1Score"]], "__init__() (mingenderf1score method)": [[57, "nlptest.transform.fairness.MinGenderF1Score.__init__"]], "alias_name (mingenderf1score attribute)": [[57, "nlptest.transform.fairness.MinGenderF1Score.alias_name"]], "async_run() (mingenderf1score class method)": [[57, "nlptest.transform.fairness.MinGenderF1Score.async_run"]], "run() (mingenderf1score method)": [[57, "nlptest.transform.fairness.MinGenderF1Score.run"]], "transform() (mingenderf1score static method)": [[57, "nlptest.transform.fairness.MinGenderF1Score.transform"]], "get_gendered_data() (in module nlptest.transform.fairness)": [[58, "nlptest.transform.fairness.get_gendered_data"]], "nlptest.transform.representation": [[59, "module-nlptest.transform.representation"]], "baserepresentation (class in nlptest.transform.representation)": [[60, "nlptest.transform.representation.BaseRepresentation"]], "__init__() (baserepresentation method)": [[60, "nlptest.transform.representation.BaseRepresentation.__init__"]], "alias_name (baserepresentation attribute)": [[60, "nlptest.transform.representation.BaseRepresentation.alias_name"]], "async_run() (baserepresentation class method)": [[60, "nlptest.transform.representation.BaseRepresentation.async_run"]], "transform() (baserepresentation static method)": [[60, "nlptest.transform.representation.BaseRepresentation.transform"]], "countryeconomicrepresentation (class in nlptest.transform.representation)": [[61, "nlptest.transform.representation.CountryEconomicRepresentation"]], "__init__() (countryeconomicrepresentation method)": [[61, "nlptest.transform.representation.CountryEconomicRepresentation.__init__"]], "alias_name (countryeconomicrepresentation attribute)": [[61, "nlptest.transform.representation.CountryEconomicRepresentation.alias_name"]], "async_run() (countryeconomicrepresentation class method)": [[61, "nlptest.transform.representation.CountryEconomicRepresentation.async_run"]], "run() (countryeconomicrepresentation method)": [[61, "nlptest.transform.representation.CountryEconomicRepresentation.run"]], "transform() (countryeconomicrepresentation method)": [[61, "nlptest.transform.representation.CountryEconomicRepresentation.transform"]], "ethnicityrepresentation (class in nlptest.transform.representation)": [[62, "nlptest.transform.representation.EthnicityRepresentation"]], "__init__() (ethnicityrepresentation method)": [[62, "nlptest.transform.representation.EthnicityRepresentation.__init__"]], "alias_name (ethnicityrepresentation attribute)": [[62, "nlptest.transform.representation.EthnicityRepresentation.alias_name"]], "async_run() (ethnicityrepresentation class method)": [[62, "nlptest.transform.representation.EthnicityRepresentation.async_run"]], "run() (ethnicityrepresentation method)": [[62, "nlptest.transform.representation.EthnicityRepresentation.run"]], "transform() (ethnicityrepresentation method)": [[62, "nlptest.transform.representation.EthnicityRepresentation.transform"]], "genderrepresentation (class in nlptest.transform.representation)": [[63, "nlptest.transform.representation.GenderRepresentation"]], "__init__() (genderrepresentation method)": [[63, "nlptest.transform.representation.GenderRepresentation.__init__"]], "alias_name (genderrepresentation attribute)": [[63, "nlptest.transform.representation.GenderRepresentation.alias_name"]], "async_run() (genderrepresentation class method)": [[63, "nlptest.transform.representation.GenderRepresentation.async_run"]], "run() (genderrepresentation method)": [[63, "nlptest.transform.representation.GenderRepresentation.run"]], "transform() (genderrepresentation method)": [[63, "nlptest.transform.representation.GenderRepresentation.transform"]], "labelrepresentation (class in nlptest.transform.representation)": [[64, "nlptest.transform.representation.LabelRepresentation"]], "__init__() (labelrepresentation method)": [[64, "nlptest.transform.representation.LabelRepresentation.__init__"]], "alias_name (labelrepresentation attribute)": [[64, "nlptest.transform.representation.LabelRepresentation.alias_name"]], "async_run() (labelrepresentation class method)": [[64, "nlptest.transform.representation.LabelRepresentation.async_run"]], "run() (labelrepresentation method)": [[64, "nlptest.transform.representation.LabelRepresentation.run"]], "transform() (labelrepresentation method)": [[64, "nlptest.transform.representation.LabelRepresentation.transform"]], "religionrepresentation (class in nlptest.transform.representation)": [[65, "nlptest.transform.representation.ReligionRepresentation"]], "__init__() (religionrepresentation method)": [[65, "nlptest.transform.representation.ReligionRepresentation.__init__"]], "alias_name (religionrepresentation attribute)": [[65, "nlptest.transform.representation.ReligionRepresentation.alias_name"]], "async_run() (religionrepresentation class method)": [[65, "nlptest.transform.representation.ReligionRepresentation.async_run"]], "run() (religionrepresentation method)": [[65, "nlptest.transform.representation.ReligionRepresentation.run"]], "transform() (religionrepresentation method)": [[65, "nlptest.transform.representation.ReligionRepresentation.transform"]], "nlptest.transform.robustness": [[66, "module-nlptest.transform.robustness"]], "addcontext (class in nlptest.transform.robustness)": [[67, "nlptest.transform.robustness.AddContext"]], "__init__() (addcontext method)": [[67, "nlptest.transform.robustness.AddContext.__init__"]], "async_run() (addcontext class method)": [[67, "nlptest.transform.robustness.AddContext.async_run"]], "run() (addcontext static method)": [[67, "nlptest.transform.robustness.AddContext.run"]], "transform() (addcontext static method)": [[67, "nlptest.transform.robustness.AddContext.transform"]], "addcontraction (class in nlptest.transform.robustness)": [[68, "nlptest.transform.robustness.AddContraction"]], "__init__() (addcontraction method)": [[68, "nlptest.transform.robustness.AddContraction.__init__"]], "async_run() (addcontraction class method)": [[68, "nlptest.transform.robustness.AddContraction.async_run"]], "run() (addcontraction static method)": [[68, "nlptest.transform.robustness.AddContraction.run"]], "transform() (addcontraction static method)": [[68, "nlptest.transform.robustness.AddContraction.transform"]], "addpunctuation (class in nlptest.transform.robustness)": [[69, "nlptest.transform.robustness.AddPunctuation"]], "__init__() (addpunctuation method)": [[69, "nlptest.transform.robustness.AddPunctuation.__init__"]], "async_run() (addpunctuation class method)": [[69, "nlptest.transform.robustness.AddPunctuation.async_run"]], "run() (addpunctuation static method)": [[69, "nlptest.transform.robustness.AddPunctuation.run"]], "transform() (addpunctuation static method)": [[69, "nlptest.transform.robustness.AddPunctuation.transform"]], "addtypo (class in nlptest.transform.robustness)": [[70, "nlptest.transform.robustness.AddTypo"]], "__init__() (addtypo method)": [[70, "nlptest.transform.robustness.AddTypo.__init__"]], "async_run() (addtypo class method)": [[70, "nlptest.transform.robustness.AddTypo.async_run"]], "run() (addtypo static method)": [[70, "nlptest.transform.robustness.AddTypo.run"]], "transform() (addtypo static method)": [[70, "nlptest.transform.robustness.AddTypo.transform"]], "baserobustness (class in nlptest.transform.robustness)": [[71, "nlptest.transform.robustness.BaseRobustness"]], "__init__() (baserobustness method)": [[71, "nlptest.transform.robustness.BaseRobustness.__init__"]], "alias_name (baserobustness attribute)": [[71, "nlptest.transform.robustness.BaseRobustness.alias_name"]], "async_run() (baserobustness class method)": [[71, "nlptest.transform.robustness.BaseRobustness.async_run"]], "run() (baserobustness static method)": [[71, "nlptest.transform.robustness.BaseRobustness.run"]], "transform() (baserobustness static method)": [[71, "nlptest.transform.robustness.BaseRobustness.transform"]], "convertaccent (class in nlptest.transform.robustness)": [[72, "nlptest.transform.robustness.ConvertAccent"]], "__init__() (convertaccent method)": [[72, "nlptest.transform.robustness.ConvertAccent.__init__"]], "async_run() (convertaccent class method)": [[72, "nlptest.transform.robustness.ConvertAccent.async_run"]], "run() (convertaccent static method)": [[72, "nlptest.transform.robustness.ConvertAccent.run"]], "transform() (convertaccent static method)": [[72, "nlptest.transform.robustness.ConvertAccent.transform"]], "lowercase (class in nlptest.transform.robustness)": [[73, "nlptest.transform.robustness.LowerCase"]], "__init__() (lowercase method)": [[73, "nlptest.transform.robustness.LowerCase.__init__"]], "async_run() (lowercase class method)": [[73, "nlptest.transform.robustness.LowerCase.async_run"]], "run() (lowercase static method)": [[73, "nlptest.transform.robustness.LowerCase.run"]], "transform() (lowercase static method)": [[73, "nlptest.transform.robustness.LowerCase.transform"]], "strippunctuation (class in nlptest.transform.robustness)": [[74, "nlptest.transform.robustness.StripPunctuation"]], "__init__() (strippunctuation method)": [[74, "nlptest.transform.robustness.StripPunctuation.__init__"]], "async_run() (strippunctuation class method)": [[74, "nlptest.transform.robustness.StripPunctuation.async_run"]], "run() (strippunctuation static method)": [[74, "nlptest.transform.robustness.StripPunctuation.run"]], "transform() (strippunctuation static method)": [[74, "nlptest.transform.robustness.StripPunctuation.transform"]], "swapentities (class in nlptest.transform.robustness)": [[75, "nlptest.transform.robustness.SwapEntities"]], "__init__() (swapentities method)": [[75, "nlptest.transform.robustness.SwapEntities.__init__"]], "async_run() (swapentities class method)": [[75, "nlptest.transform.robustness.SwapEntities.async_run"]], "run() (swapentities static method)": [[75, "nlptest.transform.robustness.SwapEntities.run"]], "transform() (swapentities static method)": [[75, "nlptest.transform.robustness.SwapEntities.transform"]], "titlecase (class in nlptest.transform.robustness)": [[76, "nlptest.transform.robustness.TitleCase"]], "__init__() (titlecase method)": [[76, "nlptest.transform.robustness.TitleCase.__init__"]], "async_run() (titlecase class method)": [[76, "nlptest.transform.robustness.TitleCase.async_run"]], "run() (titlecase static method)": [[76, "nlptest.transform.robustness.TitleCase.run"]], "transform() (titlecase static method)": [[76, "nlptest.transform.robustness.TitleCase.transform"]], "uppercase (class in nlptest.transform.robustness)": [[77, "nlptest.transform.robustness.UpperCase"]], "__init__() (uppercase method)": [[77, "nlptest.transform.robustness.UpperCase.__init__"]], "async_run() (uppercase class method)": [[77, "nlptest.transform.robustness.UpperCase.async_run"]], "run() (uppercase static method)": [[77, "nlptest.transform.robustness.UpperCase.run"]], "transform() (uppercase static method)": [[77, "nlptest.transform.robustness.UpperCase.transform"]], "nlptest.transform.utils": [[78, "module-nlptest.transform.utils"]], "check_name() (in module nlptest.transform.utils)": [[79, "nlptest.transform.utils.check_name"]], "create_terminology() (in module nlptest.transform.utils)": [[80, "nlptest.transform.utils.create_terminology"]], "get_country_economic_representation_dict() (in module nlptest.transform.utils)": [[81, "nlptest.transform.utils.get_country_economic_representation_dict"]], "get_entity_representation_proportions() (in module nlptest.transform.utils)": [[82, "nlptest.transform.utils.get_entity_representation_proportions"]], "get_ethnicity_representation_dict() (in module nlptest.transform.utils)": [[83, "nlptest.transform.utils.get_ethnicity_representation_dict"]], "get_label_representation_dict() (in module nlptest.transform.utils)": [[84, "nlptest.transform.utils.get_label_representation_dict"]], "get_religion_name_representation_dict() (in module nlptest.transform.utils)": [[85, "nlptest.transform.utils.get_religion_name_representation_dict"]], "get_substitution_names() (in module nlptest.transform.utils)": [[86, "nlptest.transform.utils.get_substitution_names"]], "nlptest.utils": [[87, "module-nlptest.utils"]], "nlptest.utils.custom_types": [[88, "module-nlptest.utils.custom_types"]], "nlptest.utils.custom_types.helpers": [[89, "module-nlptest.utils.custom_types.helpers"]], "span (class in nlptest.utils.custom_types.helpers)": [[90, "nlptest.utils.custom_types.helpers.Span"]], "__init__() (span method)": [[90, "nlptest.utils.custom_types.helpers.Span.__init__"]], "construct() (span class method)": [[90, "nlptest.utils.custom_types.helpers.Span.construct"]], "copy() (span method)": [[90, "nlptest.utils.custom_types.helpers.Span.copy"]], "dict() (span method)": [[90, "nlptest.utils.custom_types.helpers.Span.dict"]], "json() (span method)": [[90, "nlptest.utils.custom_types.helpers.Span.json"]], "update_forward_refs() (span class method)": [[90, "nlptest.utils.custom_types.helpers.Span.update_forward_refs"]], "transformation (class in nlptest.utils.custom_types.helpers)": [[91, "nlptest.utils.custom_types.helpers.Transformation"]], "__init__() (transformation method)": [[91, "nlptest.utils.custom_types.helpers.Transformation.__init__"]], "construct() (transformation class method)": [[91, "nlptest.utils.custom_types.helpers.Transformation.construct"]], "copy() (transformation method)": [[91, "nlptest.utils.custom_types.helpers.Transformation.copy"]], "dict() (transformation method)": [[91, "nlptest.utils.custom_types.helpers.Transformation.dict"]], "json() (transformation method)": [[91, "nlptest.utils.custom_types.helpers.Transformation.json"]], "update_forward_refs() (transformation class method)": [[91, "nlptest.utils.custom_types.helpers.Transformation.update_forward_refs"]], "nlptest.utils.custom_types.output": [[92, "module-nlptest.utils.custom_types.output"]], "maxscoreoutput (class in nlptest.utils.custom_types.output)": [[93, "nlptest.utils.custom_types.output.MaxScoreOutput"]], "__init__() (maxscoreoutput method)": [[93, "nlptest.utils.custom_types.output.MaxScoreOutput.__init__"]], "construct() (maxscoreoutput class method)": [[93, "nlptest.utils.custom_types.output.MaxScoreOutput.construct"]], "copy() (maxscoreoutput method)": [[93, "nlptest.utils.custom_types.output.MaxScoreOutput.copy"]], "dict() (maxscoreoutput method)": [[93, "nlptest.utils.custom_types.output.MaxScoreOutput.dict"]], "json() (maxscoreoutput method)": [[93, "nlptest.utils.custom_types.output.MaxScoreOutput.json"]], "update_forward_refs() (maxscoreoutput class method)": [[93, "nlptest.utils.custom_types.output.MaxScoreOutput.update_forward_refs"]], "minscoreoutput (class in nlptest.utils.custom_types.output)": [[94, "nlptest.utils.custom_types.output.MinScoreOutput"]], "__init__() (minscoreoutput method)": [[94, "nlptest.utils.custom_types.output.MinScoreOutput.__init__"]], "construct() (minscoreoutput class method)": [[94, "nlptest.utils.custom_types.output.MinScoreOutput.construct"]], "copy() (minscoreoutput method)": [[94, "nlptest.utils.custom_types.output.MinScoreOutput.copy"]], "dict() (minscoreoutput method)": [[94, "nlptest.utils.custom_types.output.MinScoreOutput.dict"]], "json() (minscoreoutput method)": [[94, "nlptest.utils.custom_types.output.MinScoreOutput.json"]], "update_forward_refs() (minscoreoutput class method)": [[94, "nlptest.utils.custom_types.output.MinScoreOutput.update_forward_refs"]], "neroutput (class in nlptest.utils.custom_types.output)": [[95, "nlptest.utils.custom_types.output.NEROutput"]], "__init__() (neroutput method)": [[95, "nlptest.utils.custom_types.output.NEROutput.__init__"]], "construct() (neroutput class method)": [[95, "nlptest.utils.custom_types.output.NEROutput.construct"]], "copy() (neroutput method)": [[95, "nlptest.utils.custom_types.output.NEROutput.copy"]], "dict() (neroutput method)": [[95, "nlptest.utils.custom_types.output.NEROutput.dict"]], "json() (neroutput method)": [[95, "nlptest.utils.custom_types.output.NEROutput.json"]], "to_str_list() (neroutput method)": [[95, "nlptest.utils.custom_types.output.NEROutput.to_str_list"]], "update_forward_refs() (neroutput class method)": [[95, "nlptest.utils.custom_types.output.NEROutput.update_forward_refs"]], "sequenceclassificationoutput (class in nlptest.utils.custom_types.output)": [[96, "nlptest.utils.custom_types.output.SequenceClassificationOutput"]], "__init__() (sequenceclassificationoutput method)": [[96, "nlptest.utils.custom_types.output.SequenceClassificationOutput.__init__"]], "construct() (sequenceclassificationoutput class method)": [[96, "nlptest.utils.custom_types.output.SequenceClassificationOutput.construct"]], "copy() (sequenceclassificationoutput method)": [[96, "nlptest.utils.custom_types.output.SequenceClassificationOutput.copy"]], "dict() (sequenceclassificationoutput method)": [[96, "nlptest.utils.custom_types.output.SequenceClassificationOutput.dict"]], "json() (sequenceclassificationoutput method)": [[96, "nlptest.utils.custom_types.output.SequenceClassificationOutput.json"]], "to_str_list() (sequenceclassificationoutput method)": [[96, "nlptest.utils.custom_types.output.SequenceClassificationOutput.to_str_list"]], "update_forward_refs() (sequenceclassificationoutput class method)": [[96, "nlptest.utils.custom_types.output.SequenceClassificationOutput.update_forward_refs"]], "nlptest.utils.custom_types.predictions": [[97, "module-nlptest.utils.custom_types.predictions"]], "nerprediction (class in nlptest.utils.custom_types.predictions)": [[98, "nlptest.utils.custom_types.predictions.NERPrediction"]], "__init__() (nerprediction method)": [[98, "nlptest.utils.custom_types.predictions.NERPrediction.__init__"]], "construct() (nerprediction class method)": [[98, "nlptest.utils.custom_types.predictions.NERPrediction.construct"]], "copy() (nerprediction method)": [[98, "nlptest.utils.custom_types.predictions.NERPrediction.copy"]], "dict() (nerprediction method)": [[98, "nlptest.utils.custom_types.predictions.NERPrediction.dict"]], "json() (nerprediction method)": [[98, "nlptest.utils.custom_types.predictions.NERPrediction.json"]], "update_forward_refs() (nerprediction class method)": [[98, "nlptest.utils.custom_types.predictions.NERPrediction.update_forward_refs"]], "sequencelabel (class in nlptest.utils.custom_types.predictions)": [[99, "nlptest.utils.custom_types.predictions.SequenceLabel"]], "__init__() (sequencelabel method)": [[99, "nlptest.utils.custom_types.predictions.SequenceLabel.__init__"]], "construct() (sequencelabel class method)": [[99, "nlptest.utils.custom_types.predictions.SequenceLabel.construct"]], "copy() (sequencelabel method)": [[99, "nlptest.utils.custom_types.predictions.SequenceLabel.copy"]], "dict() (sequencelabel method)": [[99, "nlptest.utils.custom_types.predictions.SequenceLabel.dict"]], "json() (sequencelabel method)": [[99, "nlptest.utils.custom_types.predictions.SequenceLabel.json"]], "update_forward_refs() (sequencelabel class method)": [[99, "nlptest.utils.custom_types.predictions.SequenceLabel.update_forward_refs"]], "nlptest.utils.custom_types.sample": [[100, "module-nlptest.utils.custom_types.sample"]], "basesample (class in nlptest.utils.custom_types.sample)": [[101, "nlptest.utils.custom_types.sample.BaseSample"]], "__init__() (basesample method)": [[101, "nlptest.utils.custom_types.sample.BaseSample.__init__"]], "construct() (basesample class method)": [[101, "nlptest.utils.custom_types.sample.BaseSample.construct"]], "copy() (basesample method)": [[101, "nlptest.utils.custom_types.sample.BaseSample.copy"]], "dict() (basesample method)": [[101, "nlptest.utils.custom_types.sample.BaseSample.dict"]], "irrelevant_transformations (basesample property)": [[101, "nlptest.utils.custom_types.sample.BaseSample.irrelevant_transformations"]], "json() (basesample method)": [[101, "nlptest.utils.custom_types.sample.BaseSample.json"]], "relevant_transformations (basesample property)": [[101, "nlptest.utils.custom_types.sample.BaseSample.relevant_transformations"]], "sort_transformations() (basesample class method)": [[101, "nlptest.utils.custom_types.sample.BaseSample.sort_transformations"]], "to_dict() (basesample method)": [[101, "nlptest.utils.custom_types.sample.BaseSample.to_dict"]], "update_forward_refs() (basesample class method)": [[101, "nlptest.utils.custom_types.sample.BaseSample.update_forward_refs"]], "maxscoresample (class in nlptest.utils.custom_types.sample)": [[102, "nlptest.utils.custom_types.sample.MaxScoreSample"]], "__init__() (maxscoresample method)": [[102, "nlptest.utils.custom_types.sample.MaxScoreSample.__init__"]], "construct() (maxscoresample class method)": [[102, "nlptest.utils.custom_types.sample.MaxScoreSample.construct"]], "copy() (maxscoresample method)": [[102, "nlptest.utils.custom_types.sample.MaxScoreSample.copy"]], "dict() (maxscoresample method)": [[102, "nlptest.utils.custom_types.sample.MaxScoreSample.dict"]], "irrelevant_transformations (maxscoresample property)": [[102, "nlptest.utils.custom_types.sample.MaxScoreSample.irrelevant_transformations"]], "json() (maxscoresample method)": [[102, "nlptest.utils.custom_types.sample.MaxScoreSample.json"]], "relevant_transformations (maxscoresample property)": [[102, "nlptest.utils.custom_types.sample.MaxScoreSample.relevant_transformations"]], "sort_transformations() (maxscoresample class method)": [[102, "nlptest.utils.custom_types.sample.MaxScoreSample.sort_transformations"]], "to_dict() (maxscoresample method)": [[102, "nlptest.utils.custom_types.sample.MaxScoreSample.to_dict"]], "update_forward_refs() (maxscoresample class method)": [[102, "nlptest.utils.custom_types.sample.MaxScoreSample.update_forward_refs"]], "minscoresample (class in nlptest.utils.custom_types.sample)": [[103, "nlptest.utils.custom_types.sample.MinScoreSample"]], "__init__() (minscoresample method)": [[103, "nlptest.utils.custom_types.sample.MinScoreSample.__init__"]], "construct() (minscoresample class method)": [[103, "nlptest.utils.custom_types.sample.MinScoreSample.construct"]], "copy() (minscoresample method)": [[103, "nlptest.utils.custom_types.sample.MinScoreSample.copy"]], "dict() (minscoresample method)": [[103, "nlptest.utils.custom_types.sample.MinScoreSample.dict"]], "irrelevant_transformations (minscoresample property)": [[103, "nlptest.utils.custom_types.sample.MinScoreSample.irrelevant_transformations"]], "json() (minscoresample method)": [[103, "nlptest.utils.custom_types.sample.MinScoreSample.json"]], "relevant_transformations (minscoresample property)": [[103, "nlptest.utils.custom_types.sample.MinScoreSample.relevant_transformations"]], "sort_transformations() (minscoresample class method)": [[103, "nlptest.utils.custom_types.sample.MinScoreSample.sort_transformations"]], "to_dict() (minscoresample method)": [[103, "nlptest.utils.custom_types.sample.MinScoreSample.to_dict"]], "update_forward_refs() (minscoresample class method)": [[103, "nlptest.utils.custom_types.sample.MinScoreSample.update_forward_refs"]], "nersample (class in nlptest.utils.custom_types.sample)": [[104, "nlptest.utils.custom_types.sample.NERSample"]], "__init__() (nersample method)": [[104, "nlptest.utils.custom_types.sample.NERSample.__init__"]], "construct() (nersample class method)": [[104, "nlptest.utils.custom_types.sample.NERSample.construct"]], "copy() (nersample method)": [[104, "nlptest.utils.custom_types.sample.NERSample.copy"]], "dict() (nersample method)": [[104, "nlptest.utils.custom_types.sample.NERSample.dict"]], "get_aligned_span_pairs() (nersample method)": [[104, "nlptest.utils.custom_types.sample.NERSample.get_aligned_span_pairs"]], "ignored_predictions (nersample property)": [[104, "nlptest.utils.custom_types.sample.NERSample.ignored_predictions"]], "irrelevant_transformations (nersample property)": [[104, "nlptest.utils.custom_types.sample.NERSample.irrelevant_transformations"]], "json() (nersample method)": [[104, "nlptest.utils.custom_types.sample.NERSample.json"]], "realigned_spans (nersample property)": [[104, "nlptest.utils.custom_types.sample.NERSample.realigned_spans"]], "relevant_transformations (nersample property)": [[104, "nlptest.utils.custom_types.sample.NERSample.relevant_transformations"]], "sort_transformations() (nersample class method)": [[104, "nlptest.utils.custom_types.sample.NERSample.sort_transformations"]], "to_dict() (nersample method)": [[104, "nlptest.utils.custom_types.sample.NERSample.to_dict"]], "update_forward_refs() (nersample class method)": [[104, "nlptest.utils.custom_types.sample.NERSample.update_forward_refs"]], "sequenceclassificationsample (class in nlptest.utils.custom_types.sample)": [[105, "nlptest.utils.custom_types.sample.SequenceClassificationSample"]], "__init__() (sequenceclassificationsample method)": [[105, "nlptest.utils.custom_types.sample.SequenceClassificationSample.__init__"]], "construct() (sequenceclassificationsample class method)": [[105, "nlptest.utils.custom_types.sample.SequenceClassificationSample.construct"]], "copy() (sequenceclassificationsample method)": [[105, "nlptest.utils.custom_types.sample.SequenceClassificationSample.copy"]], "dict() (sequenceclassificationsample method)": [[105, "nlptest.utils.custom_types.sample.SequenceClassificationSample.dict"]], "irrelevant_transformations (sequenceclassificationsample property)": [[105, "nlptest.utils.custom_types.sample.SequenceClassificationSample.irrelevant_transformations"]], "json() (sequenceclassificationsample method)": [[105, "nlptest.utils.custom_types.sample.SequenceClassificationSample.json"]], "relevant_transformations (sequenceclassificationsample property)": [[105, "nlptest.utils.custom_types.sample.SequenceClassificationSample.relevant_transformations"]], "sort_transformations() (sequenceclassificationsample class method)": [[105, "nlptest.utils.custom_types.sample.SequenceClassificationSample.sort_transformations"]], "to_dict() (sequenceclassificationsample method)": [[105, "nlptest.utils.custom_types.sample.SequenceClassificationSample.to_dict"]], "update_forward_refs() (sequenceclassificationsample class method)": [[105, "nlptest.utils.custom_types.sample.SequenceClassificationSample.update_forward_refs"]], "nlptest.utils.gender_classifier": [[106, "module-nlptest.utils.gender_classifier"]], "genderclassifier (class in nlptest.utils.gender_classifier)": [[107, "nlptest.utils.gender_classifier.GenderClassifier"]], "__init__() (genderclassifier method)": [[107, "nlptest.utils.gender_classifier.GenderClassifier.__init__"]], "predict() (genderclassifier method)": [[107, "nlptest.utils.gender_classifier.GenderClassifier.predict"]], "nlptest.utils.lib_manager": [[108, "module-nlptest.utils.lib_manager"]], "try_import_lib() (in module nlptest.utils.lib_manager)": [[109, "nlptest.utils.lib_manager.try_import_lib"]]}})