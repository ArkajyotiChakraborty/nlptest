{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "iDrsrAZENp1E"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I08sFJYCxR0Z"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwJ-P56kq6FU"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/nlptest/tree/issue-23-robustness-notebook-init/example/Automated_Robustness_Testing_Spark_NLP.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automated Robustness Testing for NLP Models"
      ],
      "metadata": {
        "id": "Ork664gCO-ys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark NLP Setup"
      ],
      "metadata": {
        "id": "v9Yd7KhpZOTF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saeJ8JFqt3Dg"
      },
      "outputs": [],
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.1.2 spark-nlp==4.2.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziwjuhAV7DYH"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml import Pipeline,PipelineModel\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "params = {\"spark.driver.memory\":\"16G\", \n",
        "          \"spark.kryoserializer.buffer.max\":\"2000M\", \n",
        "          \"spark.driver.maxResultSize\":\"2000M\"}\n",
        "\n",
        "spark = sparknlp.start(params=params)\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation: Downloading CoNLL"
      ],
      "metadata": {
        "id": "kzjMM9K491IF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download example train and test CoNLL files from nlptest repo\n",
        "! wget https://raw.githubusercontent.com/JohnSnowLabs/nlptest/main/example/data/train.conll\n",
        "! wget https://raw.githubusercontent.com/JohnSnowLabs/nlptest/main/example/data/test.conll"
      ],
      "metadata": {
        "id": "Dh0JpN1A92lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Robustness\n",
        "\n",
        "Model robustness can be described as the ability of a model to keep similar levels of accuracy, precision and recall when perturbations are made to the data it is predicting on. In the case of NER, the goal is to understand how documents with typos or fully uppercased sentences affect the model's prediction performance compared to documents similar to those in the original training set."
      ],
      "metadata": {
        "id": "5z2Fv7phxZrq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Robustness Testing\n",
        "\n",
        "Testing a NER model's robustness gives us an idea on how our data may need to be modified to make the model more robust."
      ],
      "metadata": {
        "id": "E-qKCx1nm6fn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spark NLP Model for Robustness Test\n",
        "\n",
        "Testing robustness first requires building a pipeline with a NER model that will be tested. This model should ideally not have been trained on the samples in the test set. We are using a pretrained model here for demo purposes, but it is more common to use a locally trained model."
      ],
      "metadata": {
        "id": "mUFXorMWe7Zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "\t\t.setInputCol(\"text\")\\\n",
        "\t\t.setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "\t\t.setInputCols([\"document\"])\\\n",
        "\t\t.setOutputCol(\"token\")\n",
        "\t\n",
        "embeddings = WordEmbeddingsModel.pretrained('glove_100d') \\\n",
        "\t\t.setInputCols([\"document\", 'token']) \\\n",
        "\t\t.setOutputCol(\"embeddings\")\n",
        "\n",
        "ner = NerDLModel.pretrained(\"ner_dl\", 'en') \\\n",
        "\t\t.setInputCols([\"document\", \"token\", \"embeddings\"]) \\\n",
        "\t\t.setOutputCol(\"ner\")\n",
        "\n",
        "ner_pipeline = Pipeline().setStages([\n",
        "\t\t\t\tdocumentAssembler,\n",
        "\t\t\t\ttokenizer,\n",
        "\t\t\t\tembeddings,\n",
        "\t\t\t\tner\n",
        "    ])\n",
        "\n",
        "ner_model_pipeline = ner_pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"text\"))"
      ],
      "metadata": {
        "id": "0u4He_NvLDs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Robustness Test Parameters & Perturbations\n",
        "\n",
        "This function tests the robustness of a NER model by applying different types of perturbations to a list of sentences taken from a test dataset. Metrics are calculated by comparing the model's extractions in the original list of sentences against the extractions carried out in the noisy list of sentences. The original annotated labels are not used at any point, we are simply comparing the model against itself in a 2 settings.\n",
        "<br/>\n",
        "\n",
        "Here is a list of the different parameters that can be passed to the `test_robustness` function:\n",
        "\n",
        "| Parameter  | Description |  |\n",
        "| - | - | - |\n",
        "|**spark**      |An active spark session.|\n",
        "|**pipeline_model** |PipelineModel with document assembler, sentence detector, tokenizer, <br/>word embeddings (if applicable), NER model with _\"ner\"_ output label name, <br/> and NER converter with _\"ner_chunk\"_ output label name.|\n",
        "|**test_file_path**     |Path to test file to test robustness. Can be .txt or .conll file in CoNLL format <br/> or .csv file with just one column (text) with series of test samples.|\n",
        "|**test**      |List of robustness tests to implement. Possible values described in next <br/> section. Defaults to all tests.|\n",
        "|**noise_prob**      |Proportion of samples from test data to apply noise to (between 0 and 1).|\n",
        "|**sample_sentence_count**     |Number of sentence that will be sampled from the test data.|\n",
        "|**metric_type**      |Set \"strict\" to calculate metrics in IOB2 format, \"flex\" to calculate in IO <br/> format. Defaults to 'flex'.|\n",
        "|**metrics_output_format**   |Set \"dictionary\" to get a report in dictionary format, \"dataframe\" to get it in <br/> dataframe format. Defaults to 'dictionary'.|\n",
        "|**log_path**      |Path to log file, False to avoid saving test results. Defaults to <br/>'./robustness_test_results.json'|\n",
        "|**starting_context**     |List of words or phrases to add as context perturbations to the beginning <br/> of sentences when running the `add_context` test.|\n",
        "|**ending_context**     |List of words or phrases to add as context perturbations to the end of <br/> sentences when running the `add_context` test.|\n",
        "\n",
        "<br/>\n",
        "\n",
        "Multiple perturbation methods are available to test the model's robustness. These are meant to be passed in a list to the `test` parameter in the `test_robustness` function:\n",
        "\n",
        "- **`capitalization_upper`**: capitalization of the test set is turned into uppercase\n",
        "\n",
        "- **`capitalization_lower`**: capitalization of the test set is turned into lowercase\n",
        "\n",
        "- **`capitalization_title`**: capitalization of the test set is turned into title case\n",
        "\n",
        "- **`add_punctuation`**: special characters at end of each sentence are replaced by other special characters, if no\n",
        "special character at the end, one is added\n",
        "\n",
        "- **`strip_punctuation`**: special characters are removed from the sentences (except if found in numbers, such as '2.5')\n",
        "\n",
        "- **`introduce_typos`**: typos are introduced in sentences\n",
        "\n",
        "- **`add_contractions`**: contractions are added where possible (e.g. 'do not' contracted into 'don't')\n",
        "\n",
        "- **`add_context`**: tokens are added at the beginning and at the end of the sentences\n",
        "\n",
        "- **`swap_entities`**: named entities replaced with same entity type with same token count from terminology\n",
        "\n",
        "- **`swap_cohyponyms`**: Named entities replaced with co-hyponym from the WordNet database\n",
        "\n",
        "- **`american_to_british`**: American English will be changed to British English\n",
        "\n",
        "- **`british_to_american`**: British English will be changed to American English"
      ],
      "metadata": {
        "id": "u_xFORYrMFvt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Robustness Testing Module\n"
      ],
      "metadata": {
        "id": "hewrglUWmphi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nlptest import test_robustness\n",
        "\n",
        "# Running robustness test on sentences from test set\n",
        "test_results = test_robustness(spark = spark,\n",
        "                               pipeline_model = ner_model_pipeline,\n",
        "                               test_file_path = 'test.conll',\n",
        "                               test = ['capitalization_upper', 'capitalization_lower', \n",
        "                                       'capitalization_title', 'add_punctuation', 'strip_punctuation', \n",
        "                                       'introduce_typos', 'add_contractions', 'american_to_british', \n",
        "                                       'add_context', 'swap_entities', 'swap_cohyponyms'],\n",
        "                               noise_prob = 0.5,\n",
        "                               metric_type = 'flex',\n",
        "                               metrics_output_format = 'dictionary')"
      ],
      "metadata": {
        "id": "2iWmT7Eg2e9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary outputs metrics, a comparison dataframe and written details for each test\n",
        "test_results.keys()"
      ],
      "metadata": {
        "id": "-pkT1hAjgtHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics contains detailed metrics for each test\n",
        "test_results['metrics'].keys()"
      ],
      "metadata": {
        "id": "e8C-GV_QguN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a specific test to view its metrics\n",
        "test_results['metrics']['modify_capitalization_upper']"
      ],
      "metadata": {
        "id": "-qZc9MuFgwTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1-to-1 token comparison of every perturbation applied\n",
        "test_results['comparison_df']"
      ],
      "metadata": {
        "id": "rQxwSEZX1s9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Written details for each test (preview)\n",
        "print(test_results['test_details'][:865])"
      ],
      "metadata": {
        "id": "7A1k2rWTg9MZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Robustness Fixing\n",
        "\n",
        "Once a NER model's robustness has been tested, we can make an informed decision about how to make it more robust to perturbations."
      ],
      "metadata": {
        "id": "R9E6Yy65hmj0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Robustness Fixing Parameters\n",
        "\n",
        "The `augment_robustness` function augments a training set by generating perturbations. The resulting dataset includes both the original samples and the noisy ones. Here is a list of the different parameters that can be passed to the function:\n",
        "\n",
        "| Parameter  | Description |  |\n",
        "| - | - | - |\n",
        "|**spark**      |An active spark session.|\n",
        "|**conll_path**      |Path to CoNLL file to augment with selected perturbations.|\n",
        "|**conll_save_path**    |Path to save augmented CoNLL file.|\n",
        "|**return_spark**      |Return Spark DataFrame instead of CoNLL file.|\n",
        "|**perturbation_map**    |A dictionary of perturbation names and desired proportions <br/> to apply on all entity classes.|\n",
        "|**entity_perturbation_map**  |A dictionary of perturbation names and desired perturbation <br/> proportions defined for each entity class.|\n",
        "|**optimized_inplace**    |Whether you want to apply perturbations inplace or create <br/> duplicate sentences with perturbations applied.|\n",
        "|**starting_context**   |List of words or phrases to add as context perturbations <br/> to the beginning of sentences when running the <br/> `add_context` perturbation.|\n",
        "|**ending_context**      |List of words or phrases to add as context perturbations <br/> to the end of sentences when running the <br/> `add_context` perturbation.|\n",
        "|**print_info**     |Print logs of augmentation process, default is False.|\n",
        "|**ignore_warnings**     |Ignore warnings from augmentation process, default is False.|\n",
        "|**regex_pattern**     |Regex pattern to tokenize context and contractions, <br/> defaults to pattern used in regular tokenizer.|\n",
        "|**random_state**      |Random state to apply perturbations on a consistent sample <br/> of sentences.|\n",
        "\n",
        "<br/>\n",
        "\n",
        "Multiple perturbation methods are available to augment the dataset to attempt to increase the robustness of the model trained on it. These are meant to be passed as keys of the dictionary passed to the `entity_perturbation_map` and `entity_perturbation_map` parameters:\n",
        "\n",
        "- **`capitalization_upper`**: capitalization of the dataset is turned into uppercase\n",
        "\n",
        "- **`capitalization_lower`**: capitalization of the dataset is turned into lowercase\n",
        "\n",
        "- **`capitalization_title`**: capitalization of the dataset is turned into title case\n",
        "\n",
        "- **`add_punctuation`**: special characters at end of each sentence are replaced by other special characters, if no\n",
        "special character at the end, one is added\n",
        "\n",
        "- **`strip_punctuation`**: special characters are removed from the sentences (except if found in numbers, such as '2.5')\n",
        "\n",
        "- **`introduce_typos`**: typos are introduced in sentences\n",
        "\n",
        "- **`add_contractions`**: contractions are added where possible (e.g. 'do not' contracted into 'don't')\n",
        "\n",
        "- **`add_context`**: tokens are added at the beginning and at the end of the sentences\n",
        "\n",
        "- **`swap_entities`**: named entities replaced with same entity type with same token count from terminology\n",
        "\n",
        "- **`swap_cohyponyms`**: Named entities replaced with co-hyponym from the WordNet database\n",
        "\n",
        "- **`american_to_british`**: American English will be changed to British English\n",
        "\n",
        "- **`british_to_american`**: British English will be changed to American English\n"
      ],
      "metadata": {
        "id": "iDrsrAZENp1E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Robustness Fixing Module"
      ],
      "metadata": {
        "id": "nCRDoSH8ihso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nlptest import augment_robustness\n",
        "\n",
        "# using perturbation_map\n",
        "perturbation_map = {\n",
        "   \"capitalization_upper\": 0.05,\n",
        "   \"capitalization_lower\": 0.05,\n",
        "   'capitalization_title': 0.05, \n",
        "   'add_punctuation': 0.05, \n",
        "   'strip_punctuation': 0.05,                  \n",
        "   'introduce_typos': 0.05, \n",
        "   'add_contractions': 0.05, \n",
        "   'american_to_british': 0.05, \n",
        "   'add_context': 0.05, \n",
        "   'swap_entities': 0.05, \n",
        "   'swap_cohyponyms': 0.05\n",
        "}\n",
        "\n",
        "augment_robustness(conll_path = 'train.conll',\n",
        "                   conll_save_path = 'augmented_train.conll',\n",
        "                   perturbation_map = perturbation_map,\n",
        "                   print_info=False,\n",
        "                   ignore_warnings=True,\n",
        "                   random_state=42)"
      ],
      "metadata": {
        "id": "PW9_S1ExNVrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using entity_perturbation_map\n",
        "entity_perturbation_map = {\n",
        "   \"capitalization_upper\": {'PER':0.05, 'ORG':0.02, 'LOC':0.06, 'MISC':0.01},\n",
        "   \"capitalization_lower\": {'PER':0.05, 'ORG':0.02, 'LOC':0.06, 'MISC':0.01},\n",
        "   'capitalization_title': {'PER':0.05, 'ORG':0.02, 'LOC':0.06, 'MISC':0.01}, \n",
        "   'add_punctuation': {'PER':0.05, 'ORG':0.02, 'LOC':0.06, 'MISC':0.01}, \n",
        "   'strip_punctuation': {'PER':0.05, 'ORG':0.02, 'LOC':0.06, 'MISC':0.01},                  \n",
        "   'introduce_typos': {'PER':0.05, 'ORG':0.02, 'LOC':0.06, 'MISC':0.01}, \n",
        "   'add_contractions': {'PER':0.05, 'ORG':0.02, 'LOC':0.06, 'MISC':0.01}, \n",
        "   'american_to_british': {'PER':0.05, 'ORG':0.02, 'LOC':0.06, 'MISC':0.01}, \n",
        "   'add_context': {'PER':0.05, 'ORG':0.02, 'LOC':0.06, 'MISC':0.01}, \n",
        "   'swap_entities': {'PER':0.05, 'ORG':0.02, 'LOC':0.06, 'MISC':0.01}, \n",
        "   'swap_cohyponyms': {'PER':0.05, 'ORG':0.02, 'LOC':0.06, 'MISC':0.01}\n",
        "}\n",
        "\n",
        "augment_robustness(conll_path = 'train.conll',\n",
        "                   conll_save_path = 'augmented_train.conll',\n",
        "                   entity_perturbation_map = entity_perturbation_map,\n",
        "                   print_info=False,\n",
        "                   ignore_warnings=True,\n",
        "                   random_state=42)"
      ],
      "metadata": {
        "id": "-pDZGbvsjprb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Robustness Test and Fix One-Liner"
      ],
      "metadata": {
        "id": "zUMOzfD2NAc5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fully automate robustness testing and fixing, the `nlptest` library proposes a one-liner that allows users to simply pass in the path to a CoNLL file along with the different perturbations they would like to test and fix for. Here is a list of the different parameters that can be passed to the function:\n",
        "\n",
        "| Parameter  | Description |  |\n",
        "| - | - | - |\n",
        "|**spark**      |An active spark session.|\n",
        "|**pipeline_model** |PipelineModel with document assembler, sentence detector, tokenizer, <br/>word embeddings (if applicable), NER model with _\"ner\"_ output label name, <br/> and NER converter with _\"ner_chunk\"_ output label name.|\n",
        "|**test_file_path**      |Path to test file to test and fix robustness. Can be .txt or .conll file <br/> in CoNLL format.|\n",
        "|**conll_path_to_augment**      |Path to CoNLL file to augment with selected perturbations.|\n",
        "|**conll_save_path**    |Path to save augmented CoNLL file.|\n",
        "|**test**      |List of robustness tests to implement. Possible values described in next <br/> section. Defaults to all tests.|\n",
        "|**noise_prob**      |Proportion of samples from test data to apply noise to (between 0 and 1).|\n",
        "|**optimized_inplace**    |Whether you want to apply perturbations inplace or create <br/> duplicate sentences with perturbations applied.|\n",
        "|**sample_sentence_count**     |Number of sentence that will be sampled from the test data.|\n",
        "|**metric_type**      |Set \"strict\" to calculate metrics in IOB2 format, \"flex\" to calculate in IO <br/> format. Defaults to 'flex'.|\n",
        "|**metrics_output_format**   |Set \"dictionary\" to get a report in dictionary format, \"dataframe\" to get it in <br/> dataframe format. Defaults to 'dictionary'.|\n",
        "|**log_path**      |Path to log file, False to avoid saving test results. Defaults to <br/>'./robustness_test_results.json'|\n",
        "|**starting_context**     |List of words or phrases to add as context perturbations to the beginning <br/> of sentences when running the `add_context` test.|\n",
        "|**ending_context**     |List of words or phrases to add as context perturbations to the end of <br/> sentences when running the `add_context` test.|\n",
        "|**print_info**     |Print logs of augmentation process, default is False.|\n",
        "|**ignore_warnings**     |Ignore warnings from augmentation process, default is False.|\n",
        "|**regex_pattern**     |Regex pattern to tokenize context and contractions, <br/> defaults to pattern used in regular tokenizer.|\n",
        "|**random_state**      |Random state to apply perturbations on consistent samples <br/> of sentences.|\n",
        "|**return_spark**      |Return Spark DataFrame instead of CoNLL file.|\n",
        "\n",
        "\n",
        "<br/>\n",
        "\n",
        "Multiple perturbation methods are available to test and augment the dataset to attempt to increase the robustness of the model trained on it. These are meant to be passed as keys of the dictionary passed to the `test` parameter:\n",
        "\n",
        "- **`capitalization_upper`**: capitalization of the dataset is turned into uppercase\n",
        "\n",
        "- **`capitalization_lower`**: capitalization of the dataset is turned into lowercase\n",
        "\n",
        "- **`capitalization_title`**: capitalization of the dataset is turned into title case\n",
        "\n",
        "- **`add_punctuation`**: special characters at end of each sentence are replaced by other special characters, if no\n",
        "special character at the end, one is added\n",
        "\n",
        "- **`strip_punctuation`**: special characters are removed from the sentences (except if found in numbers, such as '2.5')\n",
        "\n",
        "- **`introduce_typos`**: typos are introduced in sentences\n",
        "\n",
        "- **`add_contractions`**: contractions are added where possible (e.g. 'do not' contracted into 'don't')\n",
        "\n",
        "- **`add_context`**: tokens are added at the beginning and at the end of the sentences\n",
        "\n",
        "- **`swap_entities`**: named entities replaced with same entity type with same token count from terminology\n",
        "\n",
        "- **`swap_cohyponyms`**: Named entities replaced with co-hyponym from the WordNet database\n",
        "\n",
        "- **`american_to_british`**: American English will be changed to British English\n",
        "\n",
        "- **`british_to_american`**: British English will be changed to American English"
      ],
      "metadata": {
        "id": "xgQ-_tORkh3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nlptest import test_and_augment_robustness\n",
        "\n",
        "# Running robustness test on sentences from test set\n",
        "test_results = test_and_augment_robustness(spark = spark,\n",
        "                                           pipeline_model = ner_model,\n",
        "                                           test_file_path = 'test.conll',\n",
        "                                           conll_path_to_augment = 'train.conll',\n",
        "                                           conll_save_path = 'augmented_train.conll',\n",
        "                                           test = ['capitalization_upper', 'capitalization_lower', \n",
        "                                                   'add_punctuation', 'introduce_typos', 'add_contractions', \n",
        "                                                   'add_context', 'swap_entities'],\n",
        "                                           noise_prob = 0.5, \n",
        "                                           metric_type = 'flex',\n",
        "                                           metrics_output_format = 'dictionary')"
      ],
      "metadata": {
        "id": "gk7Q-MO7NDwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real-World Project Workflows\n",
        "\n",
        "In this section, we dive into complete workflows for using the model testing module in real-world project settings."
      ],
      "metadata": {
        "id": "4HCQpQTNPQhh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Robustness\n",
        "\n",
        "In this example, we will be testing a model's robustness to changes in capitalization - more specifically, we will be applying 2 tests: uppercasing and lowercasing. The real-world project workflow of the model robustness testing and fixing in this case goes as follows:\n",
        "\n",
        "1. Train NER model on original CoNLL training set\n",
        "\n",
        "2. Test NER model robustness on CoNLL test set\n",
        "\n",
        "3. Augment CoNLL training set based on test results \n",
        "\n",
        "4. Train new NER model on augmented CoNLL training set\n",
        "\n",
        "5. Test new NER model robustness on the CoNLL test set from step 2\n",
        "\n",
        "6. Compare robustness of new NER model against original NER model"
      ],
      "metadata": {
        "id": "sUV1L3e3PT5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1: Train NER Model"
      ],
      "metadata": {
        "id": "gGH6ByB2QWf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.training import CoNLL\n",
        "\n",
        "embeddings = WordEmbeddingsModel.pretrained('glove_100d') \\\n",
        "\t\t.setInputCols([\"document\", 'token']) \\\n",
        "\t\t.setOutputCol(\"embeddings\")\n",
        "\n",
        "nerTagger = NerDLApproach()\\\n",
        "    .setInputCols([\"document\", \"token\", \"embeddings\"])\\\n",
        "    .setLabelColumn(\"label\")\\\n",
        "    .setOutputCol(\"ner\")\\\n",
        "    .setMaxEpochs(20)\\\n",
        "    .setBatchSize(64)\\\n",
        "    .setRandomSeed(0)\\\n",
        "    .setVerbose(1)\\\n",
        "    .setValidationSplit(0)\\\n",
        "    .setEvaluationLogExtended(True) \\\n",
        "    .setEnableOutputLogs(True)\\\n",
        "    .setIncludeConfidence(True)\\\n",
        "    .setOutputLogsPath('ner_logs')\n",
        "\n",
        "training_pipeline = Pipeline(stages=[\n",
        "          embeddings,\n",
        "          nerTagger\n",
        " ])\n",
        "\n",
        "\n",
        "conll_data = CoNLL().readDataset(spark, 'train.conll')\n",
        "\n",
        "ner_model = training_pipeline.fit(conll_data)\n",
        "\n",
        "ner_model.stages[-1].write().overwrite().save('models/first_NER_20epoch')"
      ],
      "metadata": {
        "id": "WvraGtjNPTgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r first_NER_20epoch.zip models/first_NER_20epoch"
      ],
      "metadata": {
        "id": "ZaAGqRc4Xv5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2: Test NER Model Robustness on Capitalization"
      ],
      "metadata": {
        "id": "_q8WDCJlRQhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip first_NER_20epoch.zip"
      ],
      "metadata": {
        "id": "_44gXI-e9Yvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "\t\t.setInputCol(\"text\")\\\n",
        "\t\t.setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "\t\t.setInputCols([\"document\"])\\\n",
        "\t\t.setOutputCol(\"token\")\n",
        "\n",
        "embeddings = WordEmbeddingsModel.pretrained('glove_100d') \\\n",
        "\t\t.setInputCols([\"document\", 'token']) \\\n",
        "\t\t.setOutputCol(\"embeddings\")\n",
        "\n",
        "ner = NerDLModel.load(\"models/first_NER_20epoch\") \\\n",
        "\t\t.setInputCols([\"document\", \"token\", \"embeddings\"]) \\\n",
        "\t\t.setOutputCol(\"ner\")\n",
        "\n",
        "ner_pipeline = Pipeline().setStages([\n",
        "\t\t\t\tdocumentAssembler,\n",
        "\t\t\t\ttokenizer,\n",
        "\t\t\t\tembeddings,\n",
        "\t\t\t\tner\n",
        "    ])\n",
        "\n",
        "ner_model = ner_pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"text\"))"
      ],
      "metadata": {
        "id": "UF6agz8FRUww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nlptest import test_robustness\n",
        "\n",
        "# Running robustness test on test set sentences\n",
        "test_results = test_robustness(spark = spark,\n",
        "                               pipeline_model = ner_model,\n",
        "                               conll_test_path = 'test.conll',\n",
        "                               test = ['capitalization_upper', 'capitalization_lower'],\n",
        "                               noise_prob = 0.5,\n",
        "                               metric_type = 'flex',\n",
        "                               metrics_output_format = 'dataframe')"
      ],
      "metadata": {
        "id": "Wm1NKIFUILwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_results['metrics']"
      ],
      "metadata": {
        "id": "2z8J1pxecmAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_results['metrics'].to_csv('first_ner_robustness_results.csv')"
      ],
      "metadata": {
        "id": "-JFMGyVzblRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3: Augment CoNLL Training Set Based on Robustness Test Results"
      ],
      "metadata": {
        "id": "o04EcHPFUSfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nlptest import augment_robustness\n",
        "\n",
        "# using perturbation_map\n",
        "perturbation_map = {\n",
        "   \"capitalization_upper\": 0.05,\n",
        "   \"capitalization_lower\": 0.05,\n",
        "}\n",
        "\n",
        "augment_robustness(conll_path = 'train.conll',\n",
        "                   conll_save_path = 'augmented_train.conll',\n",
        "                   perturbation_map = perturbation_map,\n",
        "                   print_info=False,\n",
        "                   ignore_warnings=True,\n",
        "                   random_state=42)"
      ],
      "metadata": {
        "id": "R0cWibGaUSfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 4: Train New NER Model on Augmented CoNLL"
      ],
      "metadata": {
        "id": "e-DwOgsrVZm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.training import CoNLL\n",
        "\n",
        "embeddings = WordEmbeddingsModel.pretrained('glove_100d') \\\n",
        "\t\t.setInputCols([\"document\", 'token']) \\\n",
        "\t\t.setOutputCol(\"embeddings\")\n",
        "\n",
        "nerTagger = NerDLApproach()\\\n",
        "    .setInputCols([\"document\", \"token\", \"embeddings\"])\\\n",
        "    .setLabelColumn(\"label\")\\\n",
        "    .setOutputCol(\"ner\")\\\n",
        "    .setMaxEpochs(20)\\\n",
        "    .setBatchSize(64)\\\n",
        "    .setRandomSeed(0)\\\n",
        "    .setVerbose(1)\\\n",
        "    .setValidationSplit(0)\\\n",
        "    .setEvaluationLogExtended(True) \\\n",
        "    .setEnableOutputLogs(True)\\\n",
        "    .setIncludeConfidence(True)\\\n",
        "    .setOutputLogsPath('ner_logs')\n",
        "\n",
        "training_pipeline = Pipeline(stages=[\n",
        "          embeddings,\n",
        "          nerTagger\n",
        " ])\n",
        "\n",
        "\n",
        "conll_data = CoNLL().readDataset(spark, 'augmented_conll.conll')\n",
        "\n",
        "ner_model = training_pipeline.fit(conll_data)\n",
        "\n",
        "ner_model.stages[-1].write().overwrite().save('models/second_NER_20epoch')"
      ],
      "metadata": {
        "id": "ohkE-kl-VfqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r second_NER_20epoch.zip models/second_NER_20epoch"
      ],
      "metadata": {
        "id": "20fzG5S1q7Ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 5: Test New NER Model Robustness on Capitalization"
      ],
      "metadata": {
        "id": "Lclkqdd4Vr-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp_jsl.nlp_test import test_robustness\n",
        "\n",
        "documentAssembler = DocumentAssembler()\\\n",
        "\t\t.setInputCol(\"text\")\\\n",
        "\t\t.setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "\t\t.setInputCols([\"document\"])\\\n",
        "\t\t.setOutputCol(\"token\")\n",
        "\t\n",
        "embeddings = WordEmbeddingsModel.pretrained('glove_100d') \\\n",
        "\t\t.setInputCols([\"document\", 'token']) \\\n",
        "\t\t.setOutputCol(\"embeddings\")\n",
        "\n",
        "ner = MedicalNerModel.load(\"models/second_NER_20epoch\") \\\n",
        "\t\t.setInputCols([\"document\", \"token\", \"embeddings\"]) \\\n",
        "\t\t.setOutputCol(\"ner\")\n",
        "\n",
        "ner_pipeline = Pipeline().setStages([\n",
        "\t\t\t\tdocumentAssembler,\n",
        "\t\t\t\ttokenizer,\n",
        "\t\t\t\tembeddings,\n",
        "\t\t\t\tner\n",
        "    ])\n",
        "\n",
        "ner_model = ner_pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"text\"))"
      ],
      "metadata": {
        "id": "tS19b0m4VtLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nlptest import test_robustness\n",
        "\n",
        "# Running robustness test on test set sentences\n",
        "new_test_results = test_robustness(spark = spark,\n",
        "                                   pipeline_model = ner_model,\n",
        "                                   conll_test_path = 'test.conll',\n",
        "                                   test = ['capitalization_upper', 'capitalization_lower'],\n",
        "                                   noise_prob = 0.5,\n",
        "                                   metric_type = 'flex',\n",
        "                                   metrics_output_format = 'dataframe')"
      ],
      "metadata": {
        "id": "2FA_ezq2JKih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_test_results['metrics']"
      ],
      "metadata": {
        "id": "dmsr1cOAo3VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_test_results['metrics'].to_csv('second_ner_robustness_results.csv')"
      ],
      "metadata": {
        "id": "jEfodIVjo3VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 6: Compare Robustness Reports for First and Second NER Models"
      ],
      "metadata": {
        "id": "rcPBQE0ZpFr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "robustness_comparison = new_test_results['metrics'][['precision', 'recall', 'f1-score']] - test_results['metrics'][['precision', 'recall', 'f1-score']]\n",
        "robustness_comparison[['entity', 'test']] = test_results['metrics'][['entity', 'test']]"
      ],
      "metadata": {
        "id": "UlVJsH9MpOyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "robustness_comparison"
      ],
      "metadata": {
        "id": "8oeaVjEusQLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataframe shows the difference between the model trained on augmented data and the original model. We notice that augmenting our training set by adding uppercase and lowercase sentences increases the NER model's robustness when compared to the original NER model tested on the same test set."
      ],
      "metadata": {
        "id": "a465S4aMs9R8"
      }
    }
  ]
}
